# ui/cockpit.py  â€•  AIOps ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆï¼ˆPhase1 predict_api æ¥ç¶šãƒ»ç«¶åˆæ¤œå‡ºãƒ»ç¢ºä¿¡åº¦å‹•çš„ç®—å‡ºï¼‰
import streamlit as st
import pandas as pd
import json
import time
import hashlib
from typing import Optional, List, Dict, Any

try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False

from registry import get_paths, load_topology, get_display_name
from alarm_generator import generate_alarms_for_scenario, Alarm, get_alarm_summary
from inference_engine import LogicalRCA
from network_ops import (
    generate_analyst_report_streaming,
    generate_remediation_commands_streaming,
    run_remediation_parallel_v2,
    RemediationEnvironment
)
from utils.helpers import get_status_from_alarms, get_status_icon, load_config_by_id
from utils.llm_helper import get_rate_limiter, generate_content_with_retry
from verifier import verify_log_content
from .graph import render_topology_graph

# =====================================================
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# =====================================================
def _hash_text(text: str) -> str:
    return hashlib.sha256((text or "").encode("utf-8")).hexdigest()[:16]


def _pick_first(mapping: dict, keys: list, default: str = "") -> str:
    for k in keys:
        try:
            v = mapping.get(k)
            if v:
                return str(v)
        except:
            pass
    return default


def _build_ci_context_for_chat(topology: dict, target_node_id: str) -> dict:
    """
    ãƒãƒ£ãƒƒãƒˆç”¨CIã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ã€‚
    å¯¾è±¡ãƒãƒ¼ãƒ‰ã®metadataãƒ»config ã«åŠ ãˆã€
    ãƒˆãƒãƒ­ã‚¸ãƒ¼JSONã®è¦ªå­é–¢ä¿‚ãƒ»å†—é•·ã‚°ãƒ«ãƒ¼ãƒ—ãƒ»éš£æ¥ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã‚‚å«ã‚ã‚‹ã€‚
    """
    node = topology.get(target_node_id)
    if node and hasattr(node, 'metadata'):
        md = node.metadata or {}
    elif isinstance(node, dict):
        md = node.get('metadata', {})
    else:
        md = {}

    def _get(obj, attr, default=None):
        if isinstance(obj, dict):
            return obj.get(attr, default)
        return getattr(obj, attr, default)

    # ---- åŸºæœ¬CIæƒ…å ± ----
    ci = {
        "device_id": target_node_id or "",
        "hostname":  _pick_first(md, ["hostname", "host", "name"],            default=(target_node_id or "")),
        "vendor":    _pick_first(md, ["vendor", "manufacturer", "maker", "brand"], default=""),
        "os":        _pick_first(md, ["os", "platform", "os_name"],           default=""),
        "model":     _pick_first(md, ["model", "hw_model", "product"],        default=""),
        "role":      _pick_first(md, ["role", "type", "device_role"],         default=""),
        "layer":     _pick_first(md, ["layer", "level", "network_layer"],     default=""),
        "site":      _pick_first(md, ["site", "dc", "location"],              default=""),
    }

    # ---- ãƒˆãƒãƒ­ã‚¸ãƒ¼JSONã‹ã‚‰è¦ªå­ãƒ»å†—é•·æ§‹æˆã‚’å–å¾— ----
    if node and topology:
        parent_id       = _get(node, 'parent_id')
        redundancy_group = _get(node, 'redundancy_group')
        node_type       = _get(node, 'type', '')
        node_layer      = _get(node, 'layer', '')

        ci["node_type"]        = node_type
        ci["network_layer"]    = node_layer
        ci["redundancy_group"] = redundancy_group or "ãªã—ï¼ˆSPOFï¼‰"

        # è¦ªãƒ‡ãƒã‚¤ã‚¹æƒ…å ±
        if parent_id and parent_id in topology:
            p_node = topology[parent_id]
            p_md = _get(p_node, 'metadata') or {}
            ci["parent_device"] = {
                "id":     parent_id,
                "type":   _get(p_node, 'type', ''),
                "vendor": _pick_first(p_md, ["vendor", "manufacturer"], default=""),
                "os":     _pick_first(p_md, ["os", "platform"], default=""),
            }
        else:
            ci["parent_device"] = None  # ãƒ«ãƒ¼ãƒˆãƒ‡ãƒã‚¤ã‚¹

        # å­ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§ï¼ˆç›´æ¥ã®é…ä¸‹ï¼‰
        children = []
        for nid, n in topology.items():
            if _get(n, 'parent_id') == target_node_id:
                n_md = _get(n, 'metadata') or {}
                children.append({
                    "id":     nid,
                    "type":   _get(n, 'type', ''),
                    "vendor": _pick_first(n_md, ["vendor", "manufacturer"], default=""),
                    "os":     _pick_first(n_md, ["os", "platform"], default=""),
                })
        ci["children_devices"] = children
        ci["children_count"]   = len(children)

        # å†—é•·ãƒšã‚¢ãƒ‡ãƒã‚¤ã‚¹ï¼ˆåŒã˜redundancy_groupã«å±ã™ã‚‹ä»–ã®ãƒ‡ãƒã‚¤ã‚¹ï¼‰
        if redundancy_group:
            peers = []
            for nid, n in topology.items():
                if nid == target_node_id:
                    continue
                if _get(n, 'redundancy_group') == redundancy_group:
                    n_md = _get(n, 'metadata') or {}
                    peers.append({
                        "id":     nid,
                        "type":   _get(n, 'type', ''),
                        "vendor": _pick_first(n_md, ["vendor", "manufacturer"], default=""),
                        "os":     _pick_first(n_md, ["os", "platform"], default=""),
                    })
            ci["redundancy_peers"] = peers
        else:
            ci["redundancy_peers"] = []  # SPOFã§ã‚ã‚‹ã“ã¨ã‚’æ˜ç¤º

        # åŒä¸€ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§ï¼ˆå‚è€ƒæƒ…å ±ï¼‰
        same_layer = [nid for nid, n in topology.items()
                      if _get(n, 'layer') == node_layer and nid != target_node_id]
        ci["same_layer_devices"] = same_layer

    # ---- ã‚³ãƒ³ãƒ•ã‚£ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆconfigsãƒ•ã‚©ãƒ«ãƒ€ï¼‰ ----
    try:
        conf = load_config_by_id(target_node_id) if target_node_id else ""
        if conf:
            ci["config_excerpt"] = conf[:1500]
    except Exception:
        pass

    return ci


def _sanitize_prediction_context(text: str, max_len: int = 800) -> str:
    """
    LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã‚µãƒ‹ã‚¿ã‚¤ã‚º:
    - å€‹äººæƒ…å ±ãƒ»ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ»IPç›´æ›¸ããƒ»åˆ¶å¾¡æ–‡å­—ã‚’é™¤å»
    - max_len ã§åˆ‡ã‚Šè©°ã‚ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè‚¥å¤§åŒ–é˜²æ­¢ â†’ é€Ÿåº¦æ”¹å–„ï¼‰
    """
    import re as _re
    # åˆ¶å¾¡æ–‡å­—é™¤å»
    text = _re.sub(r'[--]', '', text or "")
    # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ»ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆç³»ã‚’é®è”½
    text = _re.sub(r'(?i)(password|passwd|secret|token|api.?key)\s*[=:]\s*\S+', r'=***', text)
    # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆIP ã¯æœ€å¾Œã‚ªã‚¯ãƒ†ãƒƒãƒˆã‚’ãƒã‚¹ã‚¯
    text = _re.sub(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.)\d{1,3}', r'***', text)
    return text[:max_len]


def _build_prediction_report_scenario(cand: dict, signal_count: int = 1) -> str:
    """
    äºˆå…†ç”¨ãƒ¬ãƒãƒ¼ãƒˆã‚·ãƒŠãƒªã‚ªã‚’æ§‹ç¯‰ï¼ˆãƒãƒƒãƒåŒ–: å¿…è¦æœ€å°ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿ï¼‰
    é‹ç”¨è€…è¦–ç‚¹: ã€Œä»Šå¾ŒNæ—¥å¾Œã«ç—‡çŠ¶ãŒé¡•è‘—åŒ–ã€è¡¨ç¾ã§çµ±ä¸€
    """
    dev_id        = cand.get('id', 'ä¸æ˜')
    pred_state    = cand.get('predicted_state') or cand.get('label', '').replace('ğŸ”® [äºˆå…†] ', '') or 'ä¸æ˜'
    pred_affected = int(cand.get('prediction_affected_count', 0))
    early_hours   = int(cand.get('prediction_early_warning_hours', 0))
    ttc_min       = int(cand.get('prediction_time_to_critical_min', 60))
    confidence    = float(cand.get('confidence', cand.get('prob', 0.5)))
    rule_pattern  = cand.get('rule_pattern', '')
    reasons       = cand.get('reasons', [])

    if early_hours >= 24:
        early_future = f"ä»Šå¾Œ{early_hours // 24}æ—¥å¾Œã«ç—‡çŠ¶ãŒé¡•è‘—åŒ–ã™ã‚‹è¦‹è¾¼ã¿"
    elif early_hours > 0:
        early_future = f"ä»Šå¾Œ{early_hours}æ™‚é–“å¾Œã«ç—‡çŠ¶ãŒé¡•è‘—åŒ–ã™ã‚‹è¦‹è¾¼ã¿"
    else:
        early_future = "è¿‘æ—¥ä¸­ã«ç—‡çŠ¶ãŒé¡•è‘—åŒ–ã™ã‚‹å¯èƒ½æ€§"

    reason_summary = "; ".join(
        _sanitize_prediction_context(r, 120) for r in reasons[:3]
    ) if reasons else rule_pattern

    lines = [
        f"[äºˆå…†æ¤œçŸ¥] {dev_id}ã§éšœå®³ã®å‰å…†ã‚’æ¤œå‡ºï¼ˆä¿¡é ¼åº¦{confidence*100:.0f}%ï¼‰ã€‚{signal_count}ä»¶ã®å¾®å¼±ã‚·ã‚°ãƒŠãƒ«ã‚’ç¢ºèªã€‚",
        f"ãƒ»äºˆæ¸¬éšœå®³: {pred_state}",
        f"ãƒ»äºˆå…†é€²è¡Œ: {early_future}",
        f"ãƒ»æ€¥æ€§æœŸ: ç—‡çŠ¶ã®ç™ºç—‡å¾Œ{ttc_min}åˆ†ã§æ·±åˆ»åŒ–ã™ã‚‹æã‚Œ",
        f"ãƒ»å½±éŸ¿ç¯„å›²: é…ä¸‹{pred_affected}å°ã«é€šä¿¡æ–­ãƒªã‚¹ã‚¯",
        f"ãƒ»æ¤œå‡ºã‚·ã‚°ãƒŠãƒ«: {reason_summary}",
        "ä»¥ä¸‹ã‚’ç°¡æ½”ã«æä¾›ã—ã¦ãã ã•ã„ï¼ˆå„é …ç›®3è¡Œä»¥å†…ï¼‰:",
        "1.äºˆå…†ãƒ‘ã‚¿ãƒ¼ãƒ³è§£èª¬ 2.ç¢ºèªã‚³ãƒãƒ³ãƒ‰ 3.åˆ¤å®šåŸºæº– 4.äºˆé˜²æªç½® 5.ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³",
    ]
    return "\n".join(lines)


def _build_prevention_plan_scenario(cand: dict) -> str:
    """äºˆé˜²æªç½®ãƒ—ãƒ©ãƒ³ç”¨ã‚·ãƒŠãƒªã‚ªï¼ˆãƒãƒƒãƒåŒ–ãƒ»ã‚µãƒ‹ã‚¿ã‚¤ã‚ºæ¸ˆã¿ï¼‰"""
    dev_id        = cand.get('id', 'ä¸æ˜')
    pred_state    = cand.get('predicted_state') or cand.get('label', '').replace('ğŸ”® [äºˆå…†] ', '') or 'ä¸æ˜'
    pred_affected = int(cand.get('prediction_affected_count', 0))
    ttc_min       = int(cand.get('prediction_time_to_critical_min', 60))
    early_hours   = int(cand.get('prediction_early_warning_hours', 0))
    rec_actions   = cand.get('recommended_actions', [])

    if early_hours >= 24:
        early_ctx = f"ä»Šå¾Œ{early_hours // 24}æ—¥å¾Œã«é¡•è‘—åŒ–"
    else:
        early_ctx = f"ä»Šå¾Œ{early_hours}æ™‚é–“å¾Œã«é¡•è‘—åŒ–" if early_hours > 0 else "è¿‘æ—¥ä¸­"

    actions_txt = ""
    if rec_actions:
        actions_txt = " æ—¢çŸ¥ã®æ¨å¥¨: " + ", ".join(
            _sanitize_prediction_context(a.get('title',''), 60) for a in rec_actions[:3])

    lines = [
        f"[äºˆé˜²æªç½®] {dev_id}ã®éšœå®³äºˆå…†ã«å¯¾ã™ã‚‹äºˆé˜²æªç½®ãƒ—ãƒ©ãƒ³ã€‚",
        f"ãƒ»äºˆæ¸¬éšœå®³: {pred_state}",
        f"ãƒ»é¡•è‘—åŒ–ã‚¿ã‚¤ãƒŸãƒ³ã‚°: {early_ctx}ã€æ€¥æ€§æœŸã¾ã§{ttc_min}åˆ†",
        f"ãƒ»å½±éŸ¿ç¯„å›²: é…ä¸‹{pred_affected}å°{actions_txt}",
        "ã€Œå¾©æ—§ã€ã§ã¯ãªãã€Œäºˆé˜²æªç½®ãƒ»äº‹å‰å¯¾å¿œã€ã¨ã—ã¦ç°¡æ½”ã«æç¤ºï¼ˆå„æ‰‹é †2è¡Œä»¥å†…ï¼‰:",
        "1.å³æ™‚ç‚¹æ¤œ 2.äºˆé˜²ã‚³ãƒãƒ³ãƒ‰ 3.ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹è¨ˆç”» 4.ç›£è¦–å¼·åŒ– 5.ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¤æ–­åŸºæº–",
    ]
    return "\n".join(lines)


def run_diagnostic_simulation_no_llm(scenario: str, target_node_obj) -> dict:
    """LLMã‚’å‘¼ã°ãªã„ç–‘ä¼¼è¨ºæ–­"""
    device_id = getattr(target_node_obj, "id", "UNKNOWN") if target_node_obj else "UNKNOWN"
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    lines = [
        f"[PROBE] ts={ts}",
        f"[PROBE] scenario={scenario}",
        f"[PROBE] target_device={device_id}",
        "",
    ]

    recovered_devices = st.session_state.get("recovered_devices") or {}
    recovered_map = st.session_state.get("recovered_scenario_map") or {}

    if recovered_devices.get(device_id) and recovered_map.get(device_id) == scenario:
        if "FW" in scenario:
            lines += ["show chassis cluster status", "Redundancy group 0: healthy", "control link: up", "fabric link: up"]
        elif "WAN" in scenario:
            lines += ["show ip interface brief", "GigabitEthernet0/0 up up", "Neighbor 203.0.113.2 Established",
                      "ping 203.0.113.2 repeat 5", "Success rate is 100 percent (5/5)"]
        elif "L2SW" in scenario:
            lines += ["show environment", "Fan: OK", "Temperature: OK", "show interface status", "Uplink: up"]
        else:
            lines += ["show system alarms", "No active alarms", "ping 8.8.8.8 repeat 5", "Success rate is 100 percent (5/5)"]
        return {"status": "SUCCESS", "sanitized_log": "\n".join(lines), "device_id": device_id}

    if "WANå…¨å›ç·šæ–­" in scenario or "[WAN]" in scenario:
        lines += ["show ip interface brief", "GigabitEthernet0/0 down down", "show ip bgp summary",
                  "Neighbor 203.0.113.2 Idle", "ping 203.0.113.2 repeat 5", "Success rate is 0 percent (0/5)"]
    elif "FWç‰‡ç³»éšœå®³" in scenario or "[FW]" in scenario:
        lines += ["show chassis cluster status", "Redundancy group 0: degraded", "control link: down", "fabric link: up"]
    elif "L2SW" in scenario:
        lines += ["show environment", "Fan: FAIL", "Temperature: HIGH", "show interface status", "Uplink: flapping"]
    else:
        lines += ["show system alarms", "No active alarms"]

    return {"status": "SUCCESS", "sanitized_log": "\n".join(lines), "device_id": device_id}


# =====================================================
# ãƒ¡ã‚¤ãƒ³æç”»é–¢æ•°
# =====================================================
def render_incident_cockpit(site_id: str, api_key: Optional[str]):
    display_name = get_display_name(site_id)
    scenario = st.session_state.site_scenarios.get(site_id, "æ­£å¸¸ç¨¼åƒ")

    # ãƒ˜ãƒƒãƒ€ãƒ¼
    col_header = st.columns([4, 1])
    with col_header[0]:
        st.markdown(f"### ğŸ›¡ï¸ AIOps ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆ")
    with col_header[1]:
        if st.button("ğŸ”™ ä¸€è¦§ã«æˆ»ã‚‹", key="back_to_list"):
            st.session_state.active_site = None
            st.rerun()

    # ãƒˆãƒãƒ­ã‚¸ãƒ¼èª­ã¿è¾¼ã¿
    paths = get_paths(site_id)
    topology = load_topology(paths.topology_path)

    if not topology:
        st.error("ãƒˆãƒãƒ­ã‚¸ãƒ¼ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    # ã‚¢ãƒ©ãƒ¼ãƒ ç”Ÿæˆ
    alarms = generate_alarms_for_scenario(topology, scenario)
    status = get_status_from_alarms(scenario, alarms)

    # äºˆå…†ã‚·ã‚°ãƒŠãƒ«æ³¨å…¥
    injected = st.session_state.get("injected_weak_signal")
    if injected and injected["device_id"] in topology:
        messages = injected.get("messages", [injected.get("message", "")])
        for msg in messages:
            if msg:
                alarms.append(Alarm(
                    device_id=injected["device_id"],
                    message=msg,
                    severity="INFO",
                    is_root_cause=False
                ))

    # LogicalRCA ã‚¨ãƒ³ã‚¸ãƒ³
    engine_key = f"engine_{site_id}"
    if engine_key not in st.session_state.logic_engines:
        st.session_state.logic_engines[engine_key] = LogicalRCA(topology)
    engine = st.session_state.logic_engines[engine_key]

    if alarms:
        analysis_results = engine.analyze(alarms)
    else:
        analysis_results = [{
            "id": "SYSTEM",
            "label": "æ­£å¸¸ç¨¼åƒ",
            "prob": 0.0,
            "type": "Normal",
            "tier": 3,
            "reason": "ã‚¢ãƒ©ãƒ¼ãƒ ãªã—"
        }]

    # =====================================================
    # â˜… Phase1: DigitalTwinEngine.predict_api() æ¥ç¶š
    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ³¨å…¥ OR æ­£å¸¸ã‚·ãƒŠãƒªã‚ªã§ dt_engine ã‚’å‘¼ã¶
    # =====================================================
    dt_key     = f"dt_engine_{site_id}"
    dt_err_key = f"dt_engine_error_{site_id}"
    dt_engine  = st.session_state.get(dt_key)
    if dt_engine is None and not st.session_state.get(dt_err_key):
        try:
            from digital_twin_pkg import DigitalTwinEngine as _DTE
            _children_map: dict = {}
            for _nid, _n in topology.items():
                _pid = (_n.get('parent_id') if isinstance(_n, dict)
                        else getattr(_n, 'parent_id', None))
                if _pid:
                    _children_map.setdefault(_pid, []).append(_nid)
            dt_engine = _DTE(topology=topology, children_map=_children_map, tenant_id=site_id)
            st.session_state[dt_key]     = dt_engine
            st.session_state[dt_err_key] = None
        except Exception as _dte_err:
            import traceback as _tb
            st.session_state[dt_err_key] = f"{type(_dte_err).__name__}: {_dte_err}\n{_tb.format_exc()}"
            dt_engine = None

    # æœŸé™åˆ‡ã‚Œäºˆå…†ã‚’å®šæœŸçš„ã«è§£æ¶ˆï¼ˆrate limit: 5åˆ†ã«1å›ï¼‰
    _expire_key = f"dt_expire_ts_{site_id}"
    if dt_engine and (time.time() - st.session_state.get(_expire_key, 0)) > 300:
        dt_engine.forecast_expire_open()
        st.session_state[_expire_key] = time.time()

    # =====================================================
    # â˜… ç«¶åˆæ¤œå‡º: éšœå®³ã‚·ãƒŠãƒªã‚ªã¨äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æ’ä»–åˆ¶å¾¡
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ã€Œäºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ã®æœ¬æ¥ã®æ„å‘³:
    #   æ­£å¸¸ç¨¼åƒä¸­ã«å¼±ã„ã‚·ã‚°ãƒŠãƒ«ã‚’æ³¨å…¥ â†’ DTãŒäºˆå…†ã‚’æ¤œçŸ¥
    # éšœå®³ã‚·ãƒŠãƒªã‚ª active æ™‚ã¯æ„å‘³è«–çš„ã«æ™‚ç³»åˆ—é€†è»¢ã™ã‚‹ãŸã‚æ’ä»–åˆ¶å¾¡
    # =====================================================
    _injected        = st.session_state.get("injected_weak_signal")
    _scenario_active = (scenario != "æ­£å¸¸ç¨¼åƒ")
    _sim_active      = bool(_injected and _injected.get("device_id") in topology)

    # ç«¶åˆçŠ¶æ…‹: éšœå®³ã‚·ãƒŠãƒªã‚ªä¸­ã«äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒæ³¨å…¥ã•ã‚Œã¦ã„ã‚‹
    _conflict = _scenario_active and _sim_active

    if _conflict:
        # ç«¶åˆãƒ‡ãƒã‚¤ã‚¹ãŒå®Ÿéšœå®³ã¨é‡ãªã‚‹ã‹ç¢ºèª
        _sim_device     = _injected.get("device_id", "")
        _critical_set   = {a.device_id for a in alarms if a.severity == "CRITICAL"}
        _warning_set    = {a.device_id for a in alarms if a.severity == "WARNING"}
        _conflict_level = ("CRITICAL" if _sim_device in _critical_set
                           else "WARNING" if _sim_device in _warning_set
                           else "OTHER")

        # ç«¶åˆè­¦å‘Šã‚’UIã«è¡¨ç¤º
        if _conflict_level in ("CRITICAL", "WARNING"):
            st.warning(
                "âš ï¸ **äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç«¶åˆæ¤œå‡º**\n\n"
                f"ç¾åœ¨ã®éšœå®³ã‚·ãƒŠãƒªã‚ªã€Œ**{scenario}**ã€ã«ã‚ˆã‚Š `{_sim_device}` ã¯æ—¢ã« "
                f"**{_conflict_level}** çŠ¶æ…‹ã§ã™ã€‚\n"
                "äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯ **ç„¡åŠ¹åŒ–** ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n"
                "ğŸ’¡ äºˆå…†â†’éšœå®³ã®æµã‚Œã‚’ãƒ‡ãƒ¢ã™ã‚‹ã«ã¯:\n"
                "1. ã‚·ãƒŠãƒªã‚ªã‚’ã€Œæ­£å¸¸ç¨¼åƒã€ã«æˆ»ã™\n"
                "2. äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œï¼ˆã‚¢ãƒ³ãƒãƒ¼è‰²ã§ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼‰\n"
                "3. éšœå®³ã‚·ãƒŠãƒªã‚ªã«åˆ‡ã‚Šæ›¿ãˆã¦ã€Œäºˆå…†ãŒçš„ä¸­ã—ãŸã€ã‚’ç¢ºèª"
            )
        else:
            # ç•°ãªã‚‹ãƒ‡ãƒã‚¤ã‚¹ã¸ã®æ³¨å…¥ã¯è¨±å®¹ã™ã‚‹ãŒæ³¨æ„å–šèµ·
            st.info(
                f"â„¹ï¸ éšœå®³ã‚·ãƒŠãƒªã‚ªã€Œ**{scenario}**ã€å®Ÿè¡Œä¸­ã§ã™ã€‚\n"
                f"`{_sim_device}` ã¸ã®äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯ç¶™ç¶šã—ã¾ã™ãŒã€"
                "forecast_ledger ã®è‡ªå‹• CONFIRMED ç™»éŒ²ã¯ **æŠ‘åˆ¶** ã•ã‚Œã¾ã™ã€‚"
            )

    # æ³¨å…¥ã‚·ã‚°ãƒŠãƒ« OR å®Ÿã‚¢ãƒ©ãƒ¼ãƒ ã‚’ dt_engine ã«é€šã—ã¦äºˆå…†ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ
    dt_predictions: List[dict] = []
    if dt_engine:
        _msg_sources = []

        # A) äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ³¨å…¥ã‚·ã‚°ãƒŠãƒ«
        #    ç«¶åˆã‹ã¤åŒãƒ‡ãƒã‚¤ã‚¹ãŒéšœå®³ä¸­ã®å ´åˆã¯ç„¡åŠ¹åŒ–
        if _sim_active:
            _sim_dev  = _injected.get("device_id", "")
            # _critical_set/_warning_set ã¯ _conflict=True æ™‚ã®ã¿å®šç¾©æ¸ˆã¿
            _alarm_devices = {a.device_id for a in alarms
                              if a.severity in ("CRITICAL", "WARNING")}
            _disabled = (_conflict and _sim_dev in _alarm_devices)
            if not _disabled:
                _msgs = _injected.get("messages", [_injected.get("message", "")])
                for _m in _msgs:
                    if _m:
                        _msg_sources.append((_sim_dev, _m, "simulation"))

        # degradation_level ã‚’ sidebar ã‹ã‚‰å–å¾— + ãƒ‡ãƒã‚¤ã‚¹å¤‰æ›´æ™‚ã®ãƒ¬ãƒãƒ¼ãƒˆãƒªã‚»ãƒƒãƒˆ
        _sim_level = int((_injected or {}).get("level", 1)) if _sim_active else 1
        _prev_sim_dev_key = f"dt_prev_sim_device_{site_id}"
        _cur_sim_dev = (_injected or {}).get("device_id", "")
        if _cur_sim_dev != st.session_state.get(_prev_sim_dev_key, ""):
            for _k in [k for k in list(st.session_state.report_cache.keys())
                       if "analyst" in k and site_id in k]:
                del st.session_state.report_cache[_k]
            st.session_state.generated_report   = None
            st.session_state.remediation_plan   = None
            st.session_state.verification_log   = None
            st.session_state[_prev_sim_dev_key] = _cur_sim_dev

        # B) å®Ÿã‚¢ãƒ©ãƒ¼ãƒ ã® WARNING/INFOï¼ˆéšœå®³ç¢ºå®šå‰ã®å¼±ã„ã‚·ã‚°ãƒŠãƒ«ï¼‰
        for _a in alarms:
            if _a.severity in ("WARNING", "INFO") and not _a.is_root_cause:
                _msg_sources.append((_a.device_id, _a.message, "real"))

        _signal_count = len(_msg_sources)

        for _dev_id, _msg, _src in _msg_sources:
            _resp = dt_engine.predict_api({
                "tenant_id":       site_id,
                "device_id":       _dev_id,
                "msg":             _msg,
                "timestamp":       time.time(),
                "record_forecast": True,
                "attrs":           {
                    "source":            _src,
                    "degradation_level": _sim_level if _src == "simulation" else 1,
                }
            })
            if _resp.get("ok"):
                for _p in _resp.get("predictions", []):
                    _p["id"]     = _dev_id
                    _p["source"] = _src

                    # â”€â”€ å½±éŸ¿ç¯„å›²: topology ã®ç›´ä¸‹å­ãƒãƒ¼ãƒ‰æ•°ã‹ã‚‰ç®—å‡º â”€â”€
                    _p["prediction_affected_count"] = sum(
                        1 for _nid, _n in topology.items()
                        if (_n.get('parent_id') if isinstance(_n, dict)
                            else getattr(_n, 'parent_id', None)) == _dev_id
                    )

                    # â”€â”€ ç¢ºä¿¡åº¦ãƒ»ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ã¦å‹•çš„èª¿æ•´ â”€â”€
                    # base_confidence ã« level ãƒœãƒ¼ãƒŠã‚¹ï¼ˆL1:+4% L5:+20%ï¼‰
                    _base_conf   = float(_p.get("confidence", 0.5))
                    _level_boost = min(0.20, _sim_level * 0.04)
                    _p["confidence"] = round(min(0.99, _base_conf + _level_boost), 2)
                    _p["prob"]       = _p["confidence"]

                    # time_to_critical_min: ãƒ¬ãƒ™ãƒ«â†‘ã»ã©æ€¥æ€§æœŸãŒçŸ­ããªã‚‹ï¼ˆL1=100% L5=52%ï¼‰
                    _base_ttc  = int(_p.get("time_to_critical_min", 60))
                    _ttc_scale = max(0.4, 1.0 - (_sim_level - 1) * 0.12)
                    _p["time_to_critical_min"]            = max(10, int(_base_ttc * _ttc_scale))
                    _p["prediction_time_to_critical_min"] = _p["time_to_critical_min"]
                    _p["prediction_timeline"]             = f"{_p['time_to_critical_min']}åˆ†å¾Œ"

                    # early_warning_hours: ãƒ¬ãƒ™ãƒ«â†‘ã»ã©æ—©æœŸæ¤œçŸ¥ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒç¸®å°
                    _base_ewh = int(_p.get("early_warning_hours", 24))
                    _p["early_warning_hours"]            = max(1, int(_base_ewh * _ttc_scale))
                    _p["prediction_early_warning_hours"] = _p["early_warning_hours"]

                    # signal_countï¼ˆLLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ï¼‰
                    _p["prediction_signal_count"] = _signal_count

                    if not any(d.get("id") == _dev_id for d in dt_predictions):
                        dt_predictions.append(_p)

        # â”€â”€ è‡ªå‹• outcome ç™»éŒ² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Execute æˆåŠŸæ¸ˆã¿ãƒ‡ãƒã‚¤ã‚¹ â†’ MITIGATEDï¼ˆç«¶åˆçŠ¶æ…‹ã«é–¢ã‚ã‚‰ãšæœ‰åŠ¹ï¼‰
        for _rid, _recovered in list(st.session_state.get("recovered_devices", {}).items()):
            if _recovered:
                _auto_key = f"dt_auto_mitigated_{site_id}_{_rid}"
                if not st.session_state.get(_auto_key):
                    dt_engine.forecast_auto_resolve(
                        _rid, "mitigated", note="Execute æˆåŠŸã«ã‚ˆã‚‹è‡ªå‹•è§£æ¶ˆ")
                    st.session_state[_auto_key] = True

        # CRITICAL ã‚¢ãƒ©ãƒ¼ãƒ ç¢ºå®š â†’ CONFIRMED
        # ãŸã ã—ç«¶åˆçŠ¶æ…‹ï¼ˆéšœå®³ã‚·ãƒŠãƒªã‚ª activeï¼‰ã§ã¯æŠ‘åˆ¶ã—ã¦èª¤è‡ªå‹•ç™»éŒ²ã‚’é˜²ã
        if not _conflict:
            _critical_devices = {a.device_id for a in alarms if a.severity == "CRITICAL"}
            for _cd in _critical_devices:
                _auto_key = f"dt_auto_confirmed_{site_id}_{_cd}"
                if not st.session_state.get(_auto_key):
                    dt_engine.forecast_auto_resolve(
                        _cd, "confirmed_incident",
                        note="CRITICAL ã‚¢ãƒ©ãƒ¼ãƒ ã«ã‚ˆã‚‹è‡ªå‹•ç¢ºå®š")
                    st.session_state[_auto_key] = True

    # DTäºˆå…†ã‚’ analysis_results ã«ãƒãƒ¼ã‚¸ï¼ˆæ—¢å­˜ã® is_prediction çµæœã¨é‡è¤‡ã—ãªã„ï¼‰
    existing_pred_ids = {r.get("id") for r in analysis_results if r.get("is_prediction")}
    for _dp in dt_predictions:
        if _dp.get("id") not in existing_pred_ids:
            analysis_results.append(_dp)

    # =====================================================
    # â˜… ãƒ‡ãƒã‚¤ã‚¹å¤‰æ›´æ¤œçŸ¥: äºˆå…†ã‚·ãƒŸãƒ¥å¯¾è±¡ãŒå¤‰ã‚ã£ãŸã‚‰ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ
    # =====================================================
    _sim_device_now = (_injected.get("device_id") if _injected else None)
    _sim_device_key = f"dt_last_sim_device_{site_id}"
    _sim_device_prev = st.session_state.get(_sim_device_key)
    if _sim_device_now != _sim_device_prev:
        st.session_state.generated_report   = None
        st.session_state.remediation_plan   = None
        st.session_state.verification_log   = None
        # ãƒ¬ãƒãƒ¼ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚äºˆå…†ç³»ã®ã‚¨ãƒ³ãƒˆãƒªã ã‘å‰Šé™¤
        _keys_to_del = [k for k in st.session_state.get("report_cache", {})
                        if "analyst" in k or "remediation" in k]
        for _k in _keys_to_del:
            st.session_state.report_cache.pop(_k, None)
        st.session_state[_sim_device_key] = _sim_device_now

    # =====================================================
    # KPIãƒ¡ãƒˆãƒªã‚¯ã‚¹
    # =====================================================
    root_cause_alarms = [a for a in alarms if a.is_root_cause]
    total_alarms = len(alarms)
    noise_reduction = ((total_alarms - len(root_cause_alarms)) / total_alarms * 100) if total_alarms > 0 else 0.0
    action_required = len(set(a.device_id for a in root_cause_alarms))
    prediction_results = [r for r in analysis_results if r.get('is_prediction')]
    prediction_count = len(prediction_results)

    st.markdown("---")
    cols = st.columns(3)
    cols[0].metric("ğŸš¨ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", f"{get_status_icon(status)} {status}")
    cols[1].metric("ğŸ“Š ã‚¢ãƒ©ãƒ¼ãƒ æ•°", f"{total_alarms}ä»¶")
    suspect_count = len([r for r in analysis_results if r.get('prob', 0) > 0.5])
    if prediction_count > 0:
        cols[2].metric("ğŸ¯ è¢«ç–‘ç®‡æ‰€", f"{suspect_count}ä»¶",
                       delta=f"ã†ã¡ğŸ”®äºˆå…† {prediction_count}ä»¶", delta_color="off")
    else:
        cols[2].metric("ğŸ¯ è¢«ç–‘ç®‡æ‰€", f"{suspect_count}ä»¶")

    kpi_cols = st.columns(3)
    with kpi_cols[0]:
        delta_text = "â†‘ é«˜åŠ¹ç‡ç¨¼åƒä¸­" if noise_reduction > 90 else ("â†’ é€šå¸¸ç¨¼åƒ" if noise_reduction > 50 else "â†“ è¦ç¢ºèª")
        delta_color = "normal" if noise_reduction > 90 else ("off" if noise_reduction > 50 else "inverse")
        kpi_cols[0].metric("ğŸ“‰ ãƒã‚¤ã‚ºå‰Šæ¸›ç‡", f"{noise_reduction:.1f}%", delta=delta_text, delta_color=delta_color)
    with kpi_cols[1]:
        kpi_cols[1].metric("ğŸ”® äºˆå…†æ¤œçŸ¥", f"{prediction_count}ä»¶",
                           delta="âš¡ è¦æ³¨æ„" if prediction_count > 0 else "å•é¡Œãªã—",
                           delta_color="inverse" if prediction_count > 0 else "normal")
    with kpi_cols[2]:
        kpi_cols[2].metric("ğŸš¨ è¦å¯¾å¿œã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ", f"{action_required}ä»¶",
                           delta="â†‘ å¯¾å‡¦ãŒå¿…è¦" if action_required > 0 else "å•é¡Œãªã—",
                           delta_color="inverse" if action_required > 0 else "normal")

    st.markdown("---")

    # =====================================================
    # æ ¹æœ¬åŸå› å€™è£œã¨ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®åˆ†é›¢
    # =====================================================
    root_cause_device_ids = set(a.device_id for a in alarms if a.is_root_cause)
    downstream_device_ids = set(a.device_id for a in alarms if not a.is_root_cause)

    root_cause_candidates = []
    downstream_devices = []

    for cand in analysis_results:
        device_id = cand.get('id', '')
        if cand.get('is_prediction'):
            root_cause_candidates.append(cand)
        elif device_id in root_cause_device_ids:
            root_cause_candidates.append(cand)
        elif device_id in downstream_device_ids:
            downstream_devices.append(cand)
        elif cand.get('prob', 0) > 0.5:
            root_cause_candidates.append(cand)

    if not root_cause_candidates and not alarms:
        root_cause_candidates = [{
            "id": "SYSTEM", "label": "æ­£å¸¸ç¨¼åƒ", "prob": 0.0,
            "type": "Normal", "tier": 3, "reason": "ã‚¢ãƒ©ãƒ¼ãƒ ãªã—"
        }]

    if root_cause_candidates and downstream_devices:
        st.info(f"ğŸ“ **æ ¹æœ¬åŸå› **: {root_cause_candidates[0]['id']} â†’ å½±éŸ¿ç¯„å›²: é…ä¸‹ {len(downstream_devices)} æ©Ÿå™¨")

    # =====================================================
    # ğŸ”® AIOps Future Radarï¼ˆäºˆå…†å°‚ç”¨è¡¨ç¤ºã‚¨ãƒªã‚¢ï¼‰
    # =====================================================
    prediction_candidates = [c for c in root_cause_candidates if c.get('is_prediction')]

    if prediction_candidates:
        st.markdown("### ğŸ”® AIOps Future Radar")
        with st.container(border=True):
            injected_info = st.session_state.get("injected_weak_signal")
            if injected_info:
                level = injected_info.get("level", 0)
                scenario_name = injected_info.get("scenario", "")
                st.info(
                    f"âš ï¸ **äºˆå…†æ¤œçŸ¥**: ç¾åœ¨ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çŠ¶æ…‹ã¯ã€Œæ­£å¸¸ã€ã§ã™ãŒã€"
                    f"AIãŒå¾®ç´°ãªã‚·ã‚°ãƒŠãƒ«ã‹ã‚‰å°†æ¥ã®éšœå®³ãƒªã‚¹ã‚¯ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚"
                    f"ï¼ˆåŠ£åŒ–ã‚·ãƒŠãƒªã‚ª: {scenario_name} / ãƒ¬ãƒ™ãƒ«: {level}/5ï¼‰"
                )
            else:
                st.info("âš ï¸ **äºˆå…†æ¤œçŸ¥**: AIãŒå°†æ¥ã®éšœå®³ãƒªã‚¹ã‚¯ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")

            radar_cols = st.columns(min(len(prediction_candidates), 3))
            for idx, pred_item in enumerate(prediction_candidates[:3]):
                with radar_cols[idx]:
                    prob_pct        = f"{pred_item.get('prob', 0)*100:.0f}%"
                    confidence      = pred_item.get('confidence', pred_item.get('prob', 0))
                    pred_timeline   = pred_item.get('prediction_timeline', 'ä¸æ˜')
                    ttc_min         = pred_item.get('prediction_time_to_critical_min',
                                       pred_item.get('time_to_critical_min', 0))
                    pred_affected   = pred_item.get('prediction_affected_count', 0)
                    pred_label      = (pred_item.get('predicted_state')
                                       or pred_item.get('label', '').replace('ğŸ”® [äºˆå…†] ', '')
                                       or 'ä¸æ˜')
                    pred_early_hours = pred_item.get('prediction_early_warning_hours',
                                        pred_item.get('early_warning_hours', 0))
                    rule_pattern    = pred_item.get('rule_pattern', '')
                    criticality     = pred_item.get('criticality', 'standard')
                    reasons         = pred_item.get('reasons', [])
                    rec_actions     = pred_item.get('recommended_actions', [])
                    source          = pred_item.get('source', 'real')

                    # â”€â”€ ãƒ˜ãƒƒãƒ€ãƒ¼: æ©Ÿå™¨å + äºˆå…†ç¨®åˆ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    _crit_badge = "ğŸ”´ CRITICAL" if criticality == "critical" else "ğŸŸ  STANDARD"
                    _src_badge  = "ğŸ”¬ ã‚·ãƒŸãƒ¥" if source == "simulation" else "ğŸ“¡ å®Ÿæ¸¬"
                    st.markdown(
                        f"<div style='background:#FFF8E1;border-left:4px solid #FFB300;"
                        f"padding:8px 12px;border-radius:4px;margin-bottom:8px;'>"
                        f"<b>ğŸ“ {pred_item['id']}</b>"
                        f"<span style='float:right;font-size:11px;color:#BF360C;'>"
                        f"{_crit_badge} {_src_badge}</span></div>",
                        unsafe_allow_html=True
                    )

                    # â”€â”€ ç¢ºä¿¡åº¦ + ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    st.markdown(
                        f"<div style='text-align:center;padding:8px 0;'>"
                        f"<span style='font-size:40px;font-weight:bold;color:#E65100;'>"
                        f"{prob_pct}</span>"
                        f"<br><span style='color:#666;font-size:13px;'>"
                        f"éšœå®³ç™ºç”Ÿç¢ºä¿¡åº¦</span></div>",
                        unsafe_allow_html=True
                    )

                    # â”€â”€ äºˆå…†è©³ç´°ã‚«ãƒ¼ãƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    st.markdown(
                        f"<div style='background:#FFF3E0;border-radius:6px;"
                        f"padding:10px 12px;margin:6px 0;font-size:13px;'>"
                        f"<b>ğŸ”® äºˆæ¸¬éšœå®³:</b> {pred_label}<br>"
                        f"<b>â±ï¸ æ€¥æ€§æœŸã¾ã§:</b> "
                        + (f"<span style='color:#d32f2f;font-weight:bold;'>{ttc_min}åˆ†</span>"
                           if ttc_min > 0 else "<span style='color:#d32f2f'>ä¸æ˜</span>")
                        + f"<br><b>ğŸ‘ï¸ æ—©æœŸæ¤œçŸ¥:</b> "
                        + (f"ä»Šå¾Œ{pred_early_hours // 24}æ—¥å¾Œã«é¡•è‘—åŒ–" if pred_early_hours >= 24
                           else (f"ä»Šå¾Œ{pred_early_hours}æ™‚é–“å¾Œã«é¡•è‘—åŒ–" if pred_early_hours > 0 else "ä¸æ˜"))
                        + (f"<br><b>ğŸ“¡ å½±éŸ¿ç¯„å›²:</b> é…ä¸‹ <b>{pred_affected}å°</b> é€šä¿¡æ–­ãƒªã‚¹ã‚¯"
                           if pred_affected > 0 else "")
                        + f"</div>",
                        unsafe_allow_html=True
                    )

                    # â”€â”€ æ¤œçŸ¥ã‚·ã‚°ãƒŠãƒ« â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    if reasons:
                        with st.expander("ğŸ” æ¤œçŸ¥ã‚·ã‚°ãƒŠãƒ«è©³ç´°", expanded=False):
                            for _r in reasons:
                                st.caption(f"â€¢ {_r}")
                            if rule_pattern:
                                st.caption(f"é©ç”¨ãƒ«ãƒ¼ãƒ«: `{rule_pattern}`")

                    # â”€â”€ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    if rec_actions:
                        with st.expander("ğŸ› ï¸ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³", expanded=True):
                            for _act in rec_actions:
                                _title  = _act.get('title', '')
                                _effect = _act.get('effect', '')
                                st.markdown(
                                    f"<div style='background:#E8F5E9;padding:6px 10px;"
                                    f"border-radius:4px;margin:4px 0;font-size:12px;'>"
                                    f"âœ… <b>{_title}</b>"
                                    + (f"<br><span style='color:#2e7d32;'>{_effect}</span>"
                                       if _effect else "")
                                    + "</div>",
                                    unsafe_allow_html=True
                                )
                    else:
                        st.caption("æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãªã—")
        st.markdown("---")

    # =====================================================
    # ğŸ¯ æ ¹æœ¬åŸå› å€™è£œãƒ†ãƒ¼ãƒ–ãƒ«
    # â˜…â˜…â˜… ä¿®æ­£â‘ : alarm_info_mapã‚’ä½¿ã£ãŸseverityåŸºæº–ã®åˆ¤å®šã«æˆ»ã™ â˜…â˜…â˜…
    # =====================================================
    selected_incident_candidate = None
    target_device_id = None

    if root_cause_candidates:
        # ã‚¢ãƒ©ãƒ¼ãƒ ã®severityã¨silentãƒ•ãƒ©ã‚°ã‚’ãƒ‡ãƒã‚¤ã‚¹IDã§ãƒãƒƒãƒ”ãƒ³ã‚°
        alarm_info_map = {}
        for a in alarms:
            if a.device_id not in alarm_info_map:
                alarm_info_map[a.device_id] = {'severity': 'INFO', 'is_silent': False}
            if a.severity == 'CRITICAL':
                alarm_info_map[a.device_id]['severity'] = 'CRITICAL'
            elif a.severity == 'WARNING' and alarm_info_map[a.device_id]['severity'] != 'CRITICAL':
                alarm_info_map[a.device_id]['severity'] = 'WARNING'
            if hasattr(a, 'is_silent_suspect') and a.is_silent_suspect:
                alarm_info_map[a.device_id]['is_silent'] = True

        df_data = []
        for rank, cand in enumerate(root_cause_candidates, 1):
            prob = cand.get('prob', 0)
            cand_type = cand.get('type', 'UNKNOWN')
            device_id = cand['id']
            alarm_info = alarm_info_map.get(device_id, {'severity': 'INFO', 'is_silent': False})

            # â˜… æ—§app.pyã¨åŒã˜åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆseverityåŸºæº–ï¼‰
            if cand.get('is_prediction'):
                status_text = "ğŸ”® äºˆå…†æ¤œçŸ¥"
                timeline = cand.get('prediction_timeline', '')
                affected = cand.get('prediction_affected_count', 0)
                early_hours = cand.get('prediction_early_warning_hours', 0)
                early_str = (f"(äºˆå…†: {early_hours // 24}æ—¥å‰ã€œ)" if early_hours >= 24
                             else (f"(äºˆå…†: {early_hours}æ™‚é–“å‰ã€œ)" if early_hours > 0 else ""))
                if timeline and affected:
                    action = f"âš¡ æ€¥æ€§æœŸ{timeline}ä»¥å†… {early_str} ({affected}å°å½±éŸ¿)"
                else:
                    action = f"âš¡ äºˆé˜²çš„å¯¾å‡¦ã‚’æ¨å¥¨ {early_str}"
            elif alarm_info['is_silent'] or "Silent" in cand_type:
                status_text = "ğŸŸ£ ã‚µã‚¤ãƒ¬ãƒ³ãƒˆç–‘ã„"
                action = "ğŸ” ä¸Šä½ç¢ºèª"
            elif alarm_info['severity'] == 'CRITICAL':
                # â˜… ã“ã“ãŒä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ: probé–¾å€¤ã§ã¯ãªãCRITICAL severity ã§åˆ¤å®š
                status_text = "ğŸ”´ å±é™º (æ ¹æœ¬åŸå› )"
                action = "ğŸš€ è‡ªå‹•ä¿®å¾©ãŒå¯èƒ½"
            elif alarm_info['severity'] == 'WARNING':
                status_text = "ğŸŸ¡ è­¦å‘Š"
                action = "ğŸ” è©³ç´°èª¿æŸ»"
            elif prob > 0.6:
                status_text = "ğŸŸ¡ è¢«ç–‘ç®‡æ‰€"
                action = "ğŸ” è©³ç´°èª¿æŸ»"
            else:
                status_text = "âšª ç›£è¦–ä¸­"
                action = "ğŸ‘ï¸ é™è¦³"

            df_data.append({
                "é †ä½": rank,
                "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": status_text,
                "ãƒ‡ãƒã‚¤ã‚¹": device_id,
                "åŸå› ": cand.get('label', ''),
                "ç¢ºä¿¡åº¦": f"{prob*100:.0f}%",
                "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³": action,
                "_id": device_id,
                "_prob": prob
            })

        df = pd.DataFrame(df_data)

        st.markdown("#### ğŸ¯ æ ¹æœ¬åŸå› å€™è£œ")
        event = st.dataframe(
            df[["é †ä½", "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "ãƒ‡ãƒã‚¤ã‚¹", "åŸå› ", "ç¢ºä¿¡åº¦", "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"]],
            use_container_width=True,
            hide_index=True,
            selection_mode="single-row",
            on_select="rerun"
        )

        if event.selection and len(event.selection.rows) > 0:
            sel_row = df.iloc[event.selection.rows[0]]
            for cand in root_cause_candidates:
                if cand['id'] == sel_row['_id']:
                    selected_incident_candidate = cand
                    target_device_id = cand['id']
                    break
        elif root_cause_candidates:
            selected_incident_candidate = root_cause_candidates[0]
            target_device_id = root_cause_candidates[0]['id']

        # å½±éŸ¿ãƒ‡ãƒã‚¤ã‚¹ï¼ˆä¸‹æµï¼‰ä¸€è¦§
        if downstream_devices:
            with st.expander(f"â–¼ å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹æ©Ÿå™¨ ({len(downstream_devices)}å°) - ä¸Šæµå¾©æ—§å¾…ã¡", expanded=False):
                dd_df = pd.DataFrame([
                    {"No": i+1, "ãƒ‡ãƒã‚¤ã‚¹": d['id'], "çŠ¶æ…‹": "âš« å¿œç­”ãªã—", "å‚™è€ƒ": "ä¸Šæµå¾©æ—§å¾…ã¡"}
                    for i, d in enumerate(downstream_devices)
                ])
                if len(downstream_devices) >= 10:
                    with st.container(height=300):
                        st.dataframe(dd_df, use_container_width=True, hide_index=True)
                else:
                    st.dataframe(dd_df, use_container_width=True, hide_index=True)

    # =====================================================
    # 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    # =====================================================
    col_map, col_chat = st.columns([1.2, 1])

    # === å·¦ã‚«ãƒ©ãƒ : ãƒˆãƒãƒ­ã‚¸ãƒ¼ & Auto-Diagnostics ===
    with col_map:
        st.subheader("ğŸŒ Network Topology")
        graph = render_topology_graph(topology, alarms, analysis_results)
        st.graphviz_chart(graph, use_container_width=True)

        st.markdown("---")
        st.subheader("ğŸ› ï¸ Auto-Diagnostics")

        if st.button("ğŸš€ è¨ºæ–­å®Ÿè¡Œ (Run Diagnostics)", type="primary"):
            if not api_key:
                st.error("API Key Required")
            else:
                with st.status("Agent Operating...", expanded=True) as status_widget:
                    st.write("ğŸ”Œ Connecting to device...")
                    target_node_obj = topology.get(target_device_id) if target_device_id else None
                    res = run_diagnostic_simulation_no_llm(scenario, target_node_obj)
                    st.session_state.live_result = res
                    if res["status"] == "SUCCESS":
                        st.write("âœ… Log Acquired & Sanitized.")
                        status_widget.update(label="Diagnostics Complete!", state="complete", expanded=False)
                        log_content = res.get('sanitized_log', "")
                        st.session_state.verification_result = verify_log_content(log_content)
                        st.session_state.trigger_analysis = True
                    else:
                        st.write("âŒ Connection Failed.")
                        status_widget.update(label="Diagnostics Failed", state="error")
                st.rerun()

        if st.session_state.live_result:
            res = st.session_state.live_result
            if res["status"] == "SUCCESS":
                st.markdown("#### ğŸ“„ Diagnostic Results")
                with st.container(border=True):
                    if st.session_state.verification_result:
                        v = st.session_state.verification_result
                        c1, c2, c3 = st.columns(3)
                        c1.metric("Ping Status", v.get('ping_status'))
                        c2.metric("Interface", v.get('interface_status'))
                        c3.metric("Hardware", v.get('hardware_status'))
                    st.divider()
                    st.caption("ğŸ”’ Raw Logs (Sanitized)")
                    st.code(res["sanitized_log"], language="text")

    # =====================================================
    # === å³ã‚«ãƒ©ãƒ : AI Analyst Report & Remediation & Chat ===
    # old_app.py ã®æ§‹é€ ã‚’å®Œå…¨å¾©å…ƒ
    # =====================================================
    with col_chat:

        # ============================================
        # A. AI Analyst Report
        # ============================================
        st.subheader("ğŸ“ AI Analyst Report")

        if selected_incident_candidate:
            cand = selected_incident_candidate

            if st.session_state.generated_report is None:
                st.info(f"ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆé¸æŠä¸­: **{cand['id']}** ({cand.get('label', '')})")

                if api_key and (scenario != "æ­£å¸¸ç¨¼åƒ" or cand.get('is_prediction')):
                    is_pred = cand.get('is_prediction')
                    btn_label = ("ğŸ”® äºˆå…†ã®ç¢ºèªæ‰‹é †ã‚’ç”Ÿæˆ (Predictive Analysis)"
                                 if is_pred else "ğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ (Generate Report)")

                    if st.button(btn_label):
                        report_container = st.empty()
                        target_conf = load_config_by_id(cand['id'])
                        verification_context = cand.get("verification_log", "ç‰¹ã«ãªã—")

                        t_node = topology.get(cand["id"])
                        t_node_dict = {
                            "id":       getattr(t_node, "id",       None) if t_node else None,
                            "type":     getattr(t_node, "type",     None) if t_node else None,
                            "layer":    getattr(t_node, "layer",    None) if t_node else None,
                            "metadata": (getattr(t_node, "metadata", {}) or {}) if t_node else {},
                        }
                        parent_id = t_node.parent_id if t_node and hasattr(t_node, 'parent_id') else None
                        children_ids = [
                            nid for nid, n in topology.items()
                            if (getattr(n, "parent_id", None) if hasattr(n, 'parent_id')
                                else n.get('parent_id')) == cand["id"]
                        ]
                        topology_context = {
                            "node": t_node_dict,
                            "parent_id": parent_id,
                            "children_ids": children_ids
                        }

                        # äºˆå…†ã®å ´åˆ: ãƒãƒƒãƒåŒ–ãƒ»ã‚µãƒ‹ã‚¿ã‚¤ã‚ºæ¸ˆã¿ãƒ˜ãƒ«ãƒ‘ãƒ¼ã§æ§‹ç¯‰ï¼ˆé€Ÿåº¦æ”¹å–„ï¼‰
                        report_scenario = scenario
                        if is_pred:
                            _sig_count      = cand.get('prediction_signal_count', 1)
                            report_scenario = _build_prediction_report_scenario(cand, _sig_count)

                        cache_key_analyst = "|".join([
                            "analyst", site_id, scenario,
                            str(cand.get("id")),
                            _hash_text(json.dumps(topology_context, ensure_ascii=False, sort_keys=True)),
                        ])

                        if cache_key_analyst in st.session_state.report_cache:
                            full_text = st.session_state.report_cache[cache_key_analyst]
                            report_container.markdown(full_text)
                        else:
                            try:
                                report_container.write("ğŸ¤– AI åˆ†æä¸­...")
                                placeholder = report_container.empty()
                                full_text = ""

                                # â˜… æ­£ã—ã„ã‚·ã‚°ãƒãƒãƒ£: topology_context= ã‚’ä½¿ç”¨
                                for chunk in generate_analyst_report_streaming(
                                    scenario=report_scenario,
                                    target_node=t_node,
                                    topology_context=topology_context,
                                    target_conf=target_conf or "ãªã—",
                                    verification_context=verification_context,
                                    api_key=api_key,
                                    max_retries=2,
                                    backoff=3
                                ):
                                    full_text += chunk
                                    placeholder.markdown(full_text)

                                if not full_text or full_text.startswith("Error"):
                                    full_text = f"âš ï¸ åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {full_text}"
                                    placeholder.markdown(full_text)

                                st.session_state.report_cache[cache_key_analyst] = full_text
                            except Exception as e:
                                full_text = f"âš ï¸ åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {type(e).__name__}: {e}"
                                report_container.markdown(full_text)

                        st.session_state.generated_report = full_text
            else:
                # ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºï¼ˆheight=400ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚³ãƒ³ãƒ†ãƒŠï¼‰
                with st.container(height=400, border=True):
                    st.markdown(st.session_state.generated_report)
                if st.button("ğŸ”„ ãƒ¬ãƒãƒ¼ãƒˆå†ä½œæˆ"):
                    st.session_state.generated_report = None
                    st.rerun()

        # ============================================
        # B. Remediation & Chat
        #    â˜… Generate Fix / Execute / Cancel ã¯ã™ã¹ã¦ã“ã“ã«é…ç½®
        # ============================================
        st.markdown("---")
        st.subheader("ğŸ¤– Remediation & Chat")

        if selected_incident_candidate and selected_incident_candidate["prob"] > 0.6:
            is_pred_rem = selected_incident_candidate.get('is_prediction')

            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒŠãƒ¼
            if is_pred_rem:
                timeline    = selected_incident_candidate.get('prediction_timeline', 'ä¸æ˜')
                affected    = selected_incident_candidate.get('prediction_affected_count', 0)
                early_hours = selected_incident_candidate.get('prediction_early_warning_hours', 0)
                early_display = (f"ä»Šå¾Œ <b>{early_hours // 24}æ—¥å¾Œ</b> ã«ç—‡çŠ¶ãŒé¡•è‘—åŒ–" if early_hours >= 24
                                 else (f"ä»Šå¾Œ <b>{early_hours}æ™‚é–“å¾Œ</b> ã«ç—‡çŠ¶ãŒé¡•è‘—åŒ–" if early_hours > 0
                                       else "ä¸æ˜"))
                st.markdown(f"""
                <div style="background-color:#fff3e0;padding:10px;border-radius:5px;border:1px solid #ff9800;color:#e65100;margin-bottom:10px;">
                    <strong>ğŸ”® Digital Twin æœªæ¥äºˆæ¸¬ (Predictive Maintenance)</strong><br>
                    <b>{selected_incident_candidate['id']}</b> ã§éšœå®³ã®å…†å€™ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚<br>
                    ãƒ»æ—©æœŸäºˆå…†: {early_display}<br>
                    ãƒ»æ€¥æ€§æœŸé€²è¡Œ: ç™ºç—‡å¾Œ <b>{timeline}</b> ã«æ·±åˆ»åŒ–ã®æã‚Œ<br>
                    ãƒ»å½±éŸ¿ç¯„å›²: <b>{affected}å°</b> ã®ãƒ‡ãƒã‚¤ã‚¹ã«å½±éŸ¿ã®å¯èƒ½æ€§<br>
                    ãƒ»æ¨å¥¨: ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã®äºˆé˜²äº¤æ›/å¯¾å¿œ<br>
                    (ä¿¡é ¼åº¦: <span style="font-size:1.2em;font-weight:bold;">{selected_incident_candidate['prob']*100:.0f}%</span>)
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div style="background-color:#e8f5e9;padding:10px;border-radius:5px;border:1px solid #4caf50;color:#2e7d32;margin-bottom:10px;">
                    <strong>âœ… AI Analysis Completed</strong><br>
                    ç‰¹å®šã•ã‚ŒãŸåŸå›  <b>{selected_incident_candidate['id']}</b> ã«å¯¾ã™ã‚‹å¾©æ—§æ‰‹é †ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚<br>
                    (ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: <span style="font-size:1.2em;font-weight:bold;">{selected_incident_candidate['prob']*100:.0f}</span>)
                </div>
                """, unsafe_allow_html=True)

            # â˜… Generate Fix ãƒœã‚¿ãƒ³ï¼ˆremediation_plan æœªç”Ÿæˆæ™‚ã®ã¿è¡¨ç¤ºï¼‰
            if st.session_state.remediation_plan is None:
                fix_label    = "ğŸ”® äºˆé˜²æªç½®ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆ" if is_pred_rem else "âœ¨ ä¿®å¾©ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆ (Generate Fix)"
                report_prereq = "ã€ŒğŸ”® äºˆå…†ã®ç¢ºèªæ‰‹é †ã‚’ç”Ÿæˆã€" if is_pred_rem else "ã€ŒğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ (Generate Report)ã€"

                if st.button(fix_label):
                    if st.session_state.generated_report is None:
                        st.warning(f"å…ˆã«{report_prereq}ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                    else:
                        remediation_container = st.empty()
                        t_node = topology.get(selected_incident_candidate["id"])

                        rem_scenario = scenario
                        if is_pred_rem:
                            rem_scenario = _build_prevention_plan_scenario(selected_incident_candidate)

                        cache_key_rem = "|".join([
                            "remediation", site_id, scenario,
                            str(selected_incident_candidate.get("id")),
                            _hash_text(st.session_state.generated_report or ""),
                        ])

                        if cache_key_rem in st.session_state.report_cache:
                            remediation_text = st.session_state.report_cache[cache_key_rem]
                            remediation_container.markdown(remediation_text)
                        else:
                            try:
                                loading_msg = "ğŸ”® äºˆé˜²æªç½®ãƒ—ãƒ©ãƒ³ç”Ÿæˆä¸­..." if is_pred_rem else "ğŸ¤– å¾©æ—§ãƒ—ãƒ©ãƒ³ç”Ÿæˆä¸­..."
                                remediation_container.write(loading_msg)
                                placeholder = remediation_container.empty()
                                remediation_text = ""

                                for chunk in generate_remediation_commands_streaming(
                                    scenario=rem_scenario,
                                    analysis_result=st.session_state.generated_report or "",
                                    target_node=t_node,
                                    api_key=api_key,
                                    max_retries=2,
                                    backoff=3
                                ):
                                    remediation_text += chunk
                                    placeholder.markdown(remediation_text)

                                if not remediation_text or remediation_text.startswith("Error"):
                                    remediation_text = f"âš ï¸ å¾©æ—§ãƒ—ãƒ©ãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {remediation_text}"
                                    placeholder.markdown(remediation_text)

                                st.session_state.report_cache[cache_key_rem] = remediation_text
                            except Exception as e:
                                remediation_text = f"âš ï¸ å¾©æ—§ãƒ—ãƒ©ãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {type(e).__name__}: {e}"
                                remediation_container.markdown(remediation_text)

                        st.session_state.remediation_plan = remediation_text
                        st.rerun()

            # â˜… å¾©æ—§æ‰‹é †è¡¨ç¤º + Execute / Cancel ãƒœã‚¿ãƒ³ï¼ˆremediation_plan ç”Ÿæˆæ¸ˆã¿æ™‚ï¼‰
            if st.session_state.remediation_plan is not None:
                with st.container(height=400, border=True):
                    st.info("AI Generated Recovery Procedureï¼ˆå¾©æ—§æ‰‹é †ï¼‰")
                    st.markdown(st.session_state.remediation_plan)

                # Execute / Cancel ãƒœã‚¿ãƒ³ï¼ˆå¾©æ—§æ‰‹é †ã‚³ãƒ³ãƒ†ãƒŠã®ç›´ä¸‹ï¼‰
                col_exec1, col_exec2 = st.columns(2)
                exec_clicked   = col_exec1.button("ğŸš€ ä¿®å¾©å®Ÿè¡Œ (Execute)", type="primary")
                cancel_clicked = col_exec2.button("ã‚­ãƒ£ãƒ³ã‚»ãƒ«")

                if cancel_clicked:
                    st.session_state.remediation_plan  = None
                    st.session_state.verification_log  = None
                    st.rerun()

                if exec_clicked:
                    if not api_key:
                        st.error("API Key Required")
                    else:
                        with st.status("ğŸ”§ ä¿®å¾©å‡¦ç†å®Ÿè¡Œä¸­...", expanded=True) as status_widget:
                            target_node_obj = topology.get(selected_incident_candidate["id"])
                            device_info = (target_node_obj.metadata
                                           if target_node_obj and hasattr(target_node_obj, 'metadata')
                                           else {})

                            st.write("ğŸ”„ Executing remediation steps in parallel...")
                            results_rem = run_remediation_parallel_v2(
                                device_id=selected_incident_candidate["id"],
                                device_info=device_info,
                                scenario=scenario,
                                environment=RemediationEnvironment.DEMO,
                                timeout_per_step=30
                            )

                            st.write("ğŸ“‹ Remediation steps result:")
                            all_success = True
                            remediation_summary = []

                            for step_name in ["Backup", "Apply", "Verify"]:
                                result = results_rem.get(step_name)
                                if result:
                                    st.write(str(result))
                                    remediation_summary.append(str(result))
                                    if result.status != "success":
                                        all_success = False

                            verification_log = "\n".join(remediation_summary)
                            st.session_state.verification_log = verification_log

                            if all_success:
                                st.write("âœ… All remediation steps completed successfully.")
                                status_widget.update(label="Process Finished", state="complete", expanded=False)
                                st.session_state.recovered_devices[selected_incident_candidate["id"]] = True
                                st.session_state.recovered_scenario_map[selected_incident_candidate["id"]] = scenario
                                if not st.session_state.balloons_shown:
                                    st.balloons()
                                    st.session_state.balloons_shown = True
                                st.success("âœ… System Recovered Successfully!")
                            else:
                                st.write("âš ï¸ Some remediation steps failed. Please review.")
                                status_widget.update(label="Process Finished - With Errors", state="error", expanded=True)

                if st.session_state.get("verification_log"):
                    st.markdown("#### ğŸ” Post-Fix Verification Logs")
                    st.code(st.session_state.verification_log, language="text")

            # â˜… Phase1: äºˆå…† Outcome æ‰‹å‹•ç™»éŒ²ãƒœã‚¿ãƒ³ï¼ˆä¾‹å¤–ä¿®æ­£ç”¨ï¼‰
            if dt_engine and selected_incident_candidate:
                _oc_device = selected_incident_candidate.get("id", "")
                _open_preds = dt_engine.forecast_list_open(device_id=_oc_device)
                if _open_preds:
                    st.markdown("---")
                    st.markdown("##### ğŸ”® äºˆå…†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç™»éŒ²ï¼ˆæ‰‹å‹•ä¿®æ­£ï¼‰")
                    st.caption(f"å¯¾è±¡æ©Ÿå™¨ `{_oc_device}` ã®æœªè§£æ±ºäºˆå…†: {len(_open_preds)}ä»¶")
                    _oc1, _oc2, _oc3 = st.columns(3)
                    _btn_confirm = _oc1.button("âœ… éšœå®³ç¢ºèªæ¸ˆã¿", key="oc_confirm",
                                               help="äºˆå…†ãŒå®Ÿéš›ã«éšœå®³ã«ç™ºå±•ã—ãŸå ´åˆ")
                    _btn_mitig   = _oc2.button("ğŸ›¡ï¸ æŠ‘ãˆè¾¼ã‚“ã ",  key="oc_mitig",
                                               help="äºˆé˜²å¯¾å¿œã«ã‚ˆã‚Šéšœå®³ã‚’å›é¿ã—ãŸå ´åˆ")
                    _btn_false   = _oc3.button("âŒ èª¤æ¤œçŸ¥",       key="oc_false",
                                               help="äºˆå…†ãŒå¤–ã‚ŒãŸå ´åˆ")
                    for _fp in _open_preds:
                        _fid = _fp.get("forecast_id", "")
                        if _btn_confirm:
                            r = dt_engine.forecast_register_outcome(_fid, "confirmed_incident")
                            if r.get("ok"):
                                st.success(f"ç¢ºèªæ¸ˆã¿ã¨ã—ã¦ç™»éŒ²: {_fid[:12]} "
                                           f"({'æˆåŠŸ' if r.get('success') else 'æœŸé™è¶…é'})")
                        elif _btn_mitig:
                            r = dt_engine.forecast_register_outcome(_fid, "mitigated")
                            if r.get("ok"):
                                st.success(f"æŠ‘ãˆè¾¼ã¿ã¨ã—ã¦ç™»éŒ²: {_fid[:12]}")
                        elif _btn_false:
                            r = dt_engine.forecast_register_outcome(_fid, "false_alarm")
                            if r.get("ok"):
                                st.info(f"èª¤æ¤œçŸ¥ã¨ã—ã¦ç™»éŒ²: {_fid[:12]}")

        else:
            # prob <= 0.6 or no candidate
            if selected_incident_candidate:
                device_id = selected_incident_candidate.get('id', '')
                score = selected_incident_candidate['prob'] * 100
                if device_id == "SYSTEM" and score == 0:
                    st.markdown("""
                    <div style="background-color:#e8f5e9;padding:10px;border-radius:5px;border:1px solid #4caf50;color:#2e7d32;margin-bottom:10px;">
                        <strong>âœ… æ­£å¸¸ç¨¼åƒä¸­</strong><br>
                        ç¾åœ¨ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯æ­£å¸¸ã«ç¨¼åƒã—ã¦ã„ã¾ã™ã€‚å¯¾å¿œãŒå¿…è¦ãªã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                    <div style="background-color:#fff3e0;padding:10px;border-radius:5px;border:1px solid #ff9800;color:#e65100;margin-bottom:10px;">
                        <strong>âš ï¸ ç›£è¦–ä¸­</strong><br>
                        å¯¾è±¡: <b>{device_id}</b><br>
                        (ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: {score:.0f} - 60ä»¥ä¸Šã§è‡ªå‹•ä¿®å¾©ã‚’æ¨å¥¨)
                    </div>
                    """, unsafe_allow_html=True)

        # ============================================
        # C. Chat with AI Agentï¼ˆExpanderå½¢å¼ãƒ»æ—§UIå¾©å…ƒï¼‰
        # ============================================
        with st.expander("ğŸ’¬ Chat with AI Agent", expanded=False):
            _chat_target_id = ""
            if selected_incident_candidate:
                _chat_target_id = selected_incident_candidate.get("id", "") or ""
            if not _chat_target_id and target_device_id:
                _chat_target_id = target_device_id

            _chat_ci = _build_ci_context_for_chat(topology, _chat_target_id) if _chat_target_id else {}
            if _chat_ci:
                _vendor     = _chat_ci.get("vendor", "") or "Unknown"
                _os         = _chat_ci.get("os",     "") or "Unknown"
                _model_name = _chat_ci.get("model",  "") or "Unknown"
                st.caption(f"å¯¾è±¡æ©Ÿå™¨: {_chat_target_id}   Vendor: {_vendor}   OS: {_os}   Model: {_model_name}")

            # ã‚¯ã‚¤ãƒƒã‚¯è³ªå•ãƒœã‚¿ãƒ³
            q1, q2, q3 = st.columns(3)
            with q1:
                if st.button("è¨­å®šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—", use_container_width=True):
                    st.session_state.chat_quick_text = "ã“ã®æ©Ÿå™¨ã§ã€ç¾åœ¨ã®è¨­å®šã‚’å®‰å…¨ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã™ã‚‹æ‰‹é †ã¨ã‚³ãƒãƒ³ãƒ‰ä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
            with q2:
                if st.button("ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯", use_container_width=True):
                    st.session_state.chat_quick_text = "ã“ã®æ©Ÿå™¨ã§ã€å¤‰æ›´ã‚’ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹ä»£è¡¨çš„ãªæ‰‹é †ï¼ˆå€™è£œï¼‰ã¨æ³¨æ„ç‚¹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
            with q3:
                if st.button("ç¢ºèªã‚³ãƒãƒ³ãƒ‰", use_container_width=True):
                    st.session_state.chat_quick_text = "ä»Šå›ã®ç—‡çŠ¶ã‚’åˆ‡ã‚Šåˆ†ã‘ã‚‹ãŸã‚ã«ã€ã¾ãšå®Ÿè¡Œã™ã¹ãç¢ºèªã‚³ãƒãƒ³ãƒ‰ï¼ˆshow/diagnosticï¼‰ã‚’å„ªå…ˆåº¦é †ã«æ•™ãˆã¦ãã ã•ã„ã€‚"

            if st.session_state.chat_quick_text:
                st.info("ã‚¯ã‚¤ãƒƒã‚¯è³ªå•ï¼ˆã‚³ãƒ”ãƒ¼ã—ã¦è²¼ã‚Šä»˜ã‘ï¼‰")
                st.code(st.session_state.chat_quick_text)

            if st.session_state.chat_session is None and api_key and GENAI_AVAILABLE:
                genai.configure(api_key=api_key)
                model_obj = genai.GenerativeModel("gemma-3-12b-it")
                st.session_state.chat_session = model_obj.start_chat(history=[])

            tab1, tab2 = st.tabs(["ğŸ’¬ ä¼šè©±", "ğŸ“ å±¥æ­´"])

            with tab1:
                if st.session_state.messages:
                    last_msg = st.session_state.messages[-1]
                    if last_msg["role"] == "assistant":
                        st.info("ğŸ¤– æœ€æ–°ã®å›ç­”")
                        with st.container(height=300):
                            st.markdown(last_msg["content"])

                st.markdown("---")
                prompt = st.text_area(
                    "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
                    height=70,
                    placeholder="Ctrl+Enter ã¾ãŸã¯ é€ä¿¡ãƒœã‚¿ãƒ³ã§é€ä¿¡",
                    key="chat_textarea"
                )

                col1, col2, col3 = st.columns([3, 1, 1])
                with col2:
                    send_button = st.button("é€ä¿¡", type="primary", use_container_width=True)
                with col3:
                    if st.button("ã‚¯ãƒªã‚¢"):
                        st.session_state.messages = []
                        st.rerun()

                if send_button and prompt:
                    st.session_state.messages.append({"role": "user", "content": prompt})
                    if st.session_state.chat_session:
                        ci = _build_ci_context_for_chat(topology, _chat_target_id) if _chat_target_id else {}
                        ci_prompt = f"""ã‚ãªãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é‹ç”¨ï¼ˆNOC/SREï¼‰ã®å®Ÿå‹™è€…ã§ã™ã€‚
æ¬¡ã® CI æƒ…å ±ã¨ Config æŠœç²‹ã‚’å¿…ãšå‚ç…§ã—ã¦ã€å…·ä½“çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚ä¸€èˆ¬è«–ã ã‘ã§çµ‚ã‚ã‚‰ã›ãªã„ã§ãã ã•ã„ã€‚

ã€CI (JSON)ã€‘
{json.dumps(ci, ensure_ascii=False, indent=2)}

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
{prompt}

å›ç­”ãƒ«ãƒ¼ãƒ«:
- CI/Config ã«åŸºã¥ãå…·ä½“æ‰‹é †ãƒ»ã‚³ãƒãƒ³ãƒ‰ä¾‹ã‚’æç¤ºã™ã‚‹
- è¿½åŠ ç¢ºèªãŒå¿…è¦ãªã‚‰ã€è³ªå•ã¯æœ€å°é™ï¼ˆ1ã€œ2ç‚¹ï¼‰ã«çµã‚‹
- ä¸æ˜ãªå‰æã¯æ¨æ¸¬ã›ãšã€ŒCIã«ç„¡ã„ã®ã§ç¢ºèªãŒå¿…è¦ã€ã¨æ˜è¨˜ã™ã‚‹
"""
                        with st.spinner("AI ãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                            try:
                                response = generate_content_with_retry(
                                    st.session_state.chat_session.model, ci_prompt, stream=False
                                )
                                if response:
                                    full_response = response.text if hasattr(response, "text") else str(response)
                                    if not full_response.strip():
                                        full_response = "AIå¿œç­”ãŒç©ºã§ã—ãŸã€‚"
                                    st.session_state.messages.append({"role": "assistant", "content": full_response})
                                else:
                                    st.error("AIã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                            except Exception as e:
                                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    st.rerun()

            with tab2:
                if st.session_state.messages:
                    history_container = st.container(height=400)
                    with history_container:
                        for i, msg in enumerate(st.session_state.messages):
                            icon = "ğŸ¤–" if msg["role"] == "assistant" else "ğŸ‘¤"
                            with st.container(border=True):
                                st.markdown(f"{icon} **{msg['role'].upper()}** (ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ {i+1})")
                                st.markdown(msg["content"])
                else:
                    st.info("ä¼šè©±å±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
