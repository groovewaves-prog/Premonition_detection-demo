import streamlit as st
import pandas as pd
import json
import time
import hashlib
from typing import Optional, List, Dict, Any

try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False

from registry import get_paths, load_topology, get_display_name
from alarm_generator import generate_alarms_for_scenario, Alarm
from inference_engine import LogicalRCA
from network_ops import (
    generate_analyst_report_streaming, 
    generate_remediation_commands_streaming, 
    run_remediation_parallel_v2, 
    RemediationEnvironment
)
from utils.helpers import get_status_from_alarms, get_status_icon, load_config_by_id
from utils.llm_helper import get_rate_limiter, generate_content_with_retry
from verifier import verify_log_content
from .graph import render_topology_graph

# =====================================================
# å¾©å…ƒã•ã‚ŒãŸä»¥å‰ã®ãƒ­ã‚¸ãƒƒã‚¯
# =====================================================
def _hash_text(text: str) -> str:
    return hashlib.sha256((text or "").encode("utf-8")).hexdigest()[:16]

def run_diagnostic_simulation_no_llm(scenario: str, target_node) -> dict:
    dev_id = getattr(target_node, "id", "UNKNOWN") if target_node else "UNKNOWN"
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    lines = [f"[PROBE] ts={ts}", f"[PROBE] scenario={scenario}", f"[PROBE] target_device={dev_id}", ""]
    if "WAN" in scenario: lines += ["show ip interface brief", "GigabitEthernet0/0 down down", "Neighbor 203.0.113.2 Idle"]
    elif "FW" in scenario: lines += ["show chassis cluster status", "Redundancy group 0: degraded", "control link: down"]
    else: lines += ["show system alarms", "No active alarms"]
    return {"status": "SUCCESS", "sanitized_log": "\n".join(lines), "device_id": dev_id}

# =====================================================
# ãƒ¡ã‚¤ãƒ³æç”»é–¢æ•° (image_6c9089.png ã®UXã‚’å®Œå…¨å†ç¾)
# =====================================================
def render_incident_cockpit(site_id: str, api_key: Optional[str]):
    scenario = st.session_state.site_scenarios.get(site_id, "æ­£å¸¸ç¨¼åƒ")
    
    # ä»¥å‰ã®ãƒ˜ãƒƒãƒ€ãƒ¼
    col_h1, col_h2 = st.columns([4, 1])
    with col_h1: st.markdown(f"### ğŸ›¡ï¸ AIOps ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆ")
    with col_h2:
        if st.button("ğŸ”™ ä¸€è¦§ã«æˆ»ã‚‹", key="back_to_list"):
            st.session_state.active_site = None
            st.rerun()

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    paths = get_paths(site_id)
    topology = load_topology(paths.topology_path)
    alarms = generate_alarms_for_scenario(topology, scenario)
    status = get_status_from_alarms(scenario, alarms)
    
    # åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
    engine_key = f"engine_{site_id}"
    if engine_key not in st.session_state.logic_engines:
        st.session_state.logic_engines[engine_key] = LogicalRCA(topology)
    engine = st.session_state.logic_engines[engine_key]
    results = engine.analyze(alarms) if alarms else []

    # KPIãƒ¡ãƒˆãƒªã‚¯ã‚¹ (image_885725.png ã®å®Œå…¨å†ç¾)
    st.markdown("---")
    k1, k2, k3 = st.columns(3)
    k1.metric("ğŸš¨ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", f"{get_status_icon(status)} {status}")
    k2.metric("ğŸ“Š ã‚¢ãƒ©ãƒ¼ãƒ æ•°", f"{len(alarms)}ä»¶")
    k3.metric("ğŸ¯ è¢«ç–‘ç®‡æ‰€", f"{len([r for r in results if r.get('prob', 0) > 0.5])}ä»¶")
    st.markdown("---")

    # =====================================================
    # æ ¹æœ¬åŸå› ã®çµã‚Šè¾¼ã¿ã¨åˆ†é›¢ãƒ­ã‚¸ãƒƒã‚¯ (image_6c9089.png ã®å†ç¾)
    # =====================================================
    root_ids = {a.device_id for a in alarms if a.is_root_cause}
    ds_ids = {a.device_id for a in alarms if not a.is_root_cause}
    
    # 1å°ã®æ ¹æœ¬åŸå› ã¨ã€è¤‡æ•°ã®ä¸‹æµãƒ‡ãƒã‚¤ã‚¹ã‚’å³å¯†ã«åˆ†ã‘ã‚‹
    rc_list = [r for r in results if r['id'] in root_ids]
    ds_list = [r for r in results if r['id'] in ds_ids and r['id'] not in root_ids]

    # é’å¸¯ãƒãƒŠãƒ¼ã®å¾©å…ƒ
    if rc_list and ds_list:
        st.info(f"ğŸ“ **æ ¹æœ¬åŸå› **: {rc_list[0]['id']} â†’ å½±éŸ¿ç¯„å›²: é…ä¸‹ {len(ds_list)} æ©Ÿå™¨")

    # ğŸ¯ æ ¹æœ¬åŸå› å€™è£œãƒ†ãƒ¼ãƒ–ãƒ« (ğŸ”´ å±é™º(æ ¹æœ¬åŸå› )ã‚’è¡¨ç¤º)
    if rc_list:
        st.markdown("#### ğŸ¯ æ ¹æœ¬åŸå› å€™è£œ")
        df_rc = pd.DataFrame([{
            "é †ä½": i+1,
            "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "ğŸ”´ å±é™º (æ ¹æœ¬åŸå› )",
            "ãƒ‡ãƒã‚¤ã‚¹": x['id'],
            "åŸå› ": x.get('label'),
            "ç¢ºä¿¡åº¦": f"{x['prob']*100:.0f}%",
            "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³": "ğŸš€ è‡ªå‹•ä¿®å¾©ãŒå¯èƒ½",
            "_obj": x
        } for i, x in enumerate(rc_list)])
        
        event = st.dataframe(df_rc.drop(columns=["_obj"]), use_container_width=True, hide_index=True, selection_mode="single-row", on_select="rerun")
        if event.selection and len(event.selection.rows) > 0:
            st.session_state.selected_candidate = df_rc.iloc[event.selection.rows[0]]["_obj"]
        elif not st.session_state.get("selected_candidate"):
            st.session_state.selected_candidate = rc_list[0]

    # â–¼ å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹æ©Ÿå™¨ãƒªã‚¹ãƒˆ (image_8840a6.jpg ã®å†ç¾)
    if ds_list:
        with st.expander(f"â–¼ å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹æ©Ÿå™¨ ({len(ds_list)}å°) - ä¸Šæµå¾©æ—§å¾…ã¡", expanded=False):
            st.dataframe(pd.DataFrame([{"No": i+1, "ãƒ‡ãƒã‚¤ã‚¹": d['id'], "çŠ¶æ…‹": "âš« å¿œç­”ãªã—", "å‚™è€ƒ": "ä¸Šæµå¾©æ—§å¾…ã¡"} for i, d in enumerate(ds_list)]), use_container_width=True, hide_index=True)

    # ========================================
    # ä»¥å‰ã®2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ (image_88b505.png)
    # ========================================
    col_l, col_r = st.columns([1.2, 1])
    
    with col_l:
        st.subheader("ğŸŒ Network Topology")
        st.graphviz_chart(render_topology_graph(topology, alarms, results), use_container_width=True)
        st.markdown("---")
        st.subheader("ğŸ› ï¸ Auto-Diagnostics")
        if st.button("ğŸš€ è¨ºæ–­å®Ÿè¡Œ (Run Diagnostics)", type="primary"):
            with st.status("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç¨¼åƒä¸­..."):
                res = run_diagnostic_simulation_no_llm(scenario, st.session_state.get("selected_candidate"))
                st.session_state.live_result = res
                st.session_state.verification_result = verify_log_content(res.get('sanitized_log', ""))
            st.rerun()
        if st.session_state.get("live_result"):
            st.code(st.session_state.live_result.get("sanitized_log"), language="text")

    with col_r:
        st.subheader("ğŸ“ AI Analyst & Chat")
        cand = st.session_state.get("selected_candidate")
        if cand:
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒŠãƒ¼ (image_88b505.png)
            st.info(f"Target: **{cand['id']}** {cand.get('label','')}")
            
            tab_rpt, tab_chat = st.tabs(["ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆ", "ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ"])
            with tab_rpt:
                c1, c2 = st.columns(2)
                if c1.button("ğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ", use_container_width=True):
                    placeholder = st.empty()
                    full_text = ""
                    for chunk in generate_analyst_report_streaming(scenario, topology.get(cand['id']), {"id": cand['id']}, load_config_by_id(cand['id']), "", api_key):
                        full_text += chunk
                        placeholder.markdown(full_text + "â–Œ")
                    st.session_state.generated_report = full_text
                    placeholder.markdown(full_text)
                
                if c2.button("âœ¨ å¾©æ—§ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆ", use_container_width=True):
                    if not st.session_state.get("generated_report"): st.warning("å…ˆã«è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„")
                    else:
                        placeholder = st.empty()
                        full_text = ""
                        for chunk in generate_remediation_commands_streaming(scenario, st.session_state.generated_report, topology.get(cand['id']), api_key):
                            full_text += chunk
                            placeholder.markdown(full_text + "â–Œ")
                        st.session_state.remediation_plan = full_text
                        placeholder.markdown(full_text)

                if st.session_state.generated_report: st.markdown(st.session_state.generated_report)

            with tab_chat:
                if not st.session_state.get("chat_session") and api_key:
                    genai.configure(api_key=api_key)
                    st.session_state.chat_session = genai.GenerativeModel("gemma-3-12b-it").start_chat(history=[])
                # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã¨å…¥åŠ›ãƒ­ã‚¸ãƒƒã‚¯ (ä»¥å‰ã® app.py é€šã‚Š)
                prompt = st.chat_input("AIã«è³ªå•...")
