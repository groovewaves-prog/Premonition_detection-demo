# ui/cockpit.py  â€•  AIOps ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆï¼ˆPhase1 predict_api + RULäºˆæ¸¬è¡¨ç¤ºï¼‰
import streamlit as st
import pandas as pd
import json
import time
import hashlib
from typing import Optional, List, Dict, Any

try:
    from google import genai
    GENAI_AVAILABLE = True
except ImportError:
    try:
        import google.generativeai as genai  # æ—§SDKäº’æ›ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        GENAI_AVAILABLE = True
    except ImportError:
        genai = None
        GENAI_AVAILABLE = False

from registry import get_paths, load_topology, get_display_name
from alarm_generator import generate_alarms_for_scenario, Alarm, get_alarm_summary
from inference_engine import LogicalRCA
from network_ops import (
    generate_analyst_report_streaming,
    generate_remediation_commands_streaming,
    run_remediation_parallel_v2,
    RemediationEnvironment
)
from utils.helpers import get_status_from_alarms, get_status_icon, load_config_by_id
from utils.llm_helper import get_rate_limiter, generate_content_with_retry
from verifier import verify_log_content
from .graph import render_topology_graph

# =====================================================
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# =====================================================
def _hash_text(text: str) -> str:
    return hashlib.sha256((text or "").encode("utf-8")).hexdigest()[:16]


def _pick_first(mapping: dict, keys: list, default: str = "") -> str:
    for k in keys:
        try:
            v = mapping.get(k)
            if v:
                return str(v)
        except:
            pass
    return default


def _build_ci_context_for_chat(topology: dict, target_node_id: str) -> dict:
    """
    ãƒãƒ£ãƒƒãƒˆç”¨CIã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ã€‚
    å¯¾è±¡ãƒãƒ¼ãƒ‰ã®metadataãƒ»config ã«åŠ ãˆã€
    ãƒˆãƒãƒ­ã‚¸ãƒ¼JSONã®è¦ªå­é–¢ä¿‚ãƒ»å†—é•·ã‚°ãƒ«ãƒ¼ãƒ—ãƒ»éš£æ¥ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã‚‚å«ã‚ã‚‹ã€‚
    """
    node = topology.get(target_node_id)
    if node and hasattr(node, 'metadata'):
        md = node.metadata or {}
    elif isinstance(node, dict):
        md = node.get('metadata', {})
    else:
        md = {}

    def _get(obj, attr, default=None):
        if isinstance(obj, dict):
            return obj.get(attr, default)
        return getattr(obj, attr, default)

    # ---- åŸºæœ¬CIæƒ…å ± ----
    ci = {
        "device_id": target_node_id or "",
        "hostname":  _pick_first(md, ["hostname", "host", "name"],            default=(target_node_id or "")),
        "vendor":    _pick_first(md, ["vendor", "manufacturer", "maker", "brand"], default=""),
        "os":        _pick_first(md, ["os", "platform", "os_name"],           default=""),
        "model":     _pick_first(md, ["model", "hw_model", "product"],        default=""),
        "role":      _pick_first(md, ["role", "type", "device_role"],         default=""),
        "layer":     _pick_first(md, ["layer", "level", "network_layer"],     default=""),
        "site":      _pick_first(md, ["site", "dc", "location"],              default=""),
    }

    # ---- ãƒˆãƒãƒ­ã‚¸ãƒ¼JSONã‹ã‚‰è¦ªå­ãƒ»å†—é•·æ§‹æˆã‚’å–å¾— ----
    if node and topology:
        parent_id       = _get(node, 'parent_id')
        redundancy_group = _get(node, 'redundancy_group')
        node_type       = _get(node, 'type', '')
        node_layer      = _get(node, 'layer', '')

        ci["node_type"]        = node_type
        ci["network_layer"]    = node_layer
        ci["redundancy_group"] = redundancy_group or "ãªã—ï¼ˆSPOFï¼‰"

        # è¦ªãƒ‡ãƒã‚¤ã‚¹æƒ…å ±
        if parent_id and parent_id in topology:
            p_node = topology[parent_id]
            p_md = _get(p_node, 'metadata') or {}
            ci["parent_device"] = {
                "id":     parent_id,
                "type":   _get(p_node, 'type', ''),
                "vendor": _pick_first(p_md, ["vendor", "manufacturer"], default=""),
                "os":     _pick_first(p_md, ["os", "platform"], default=""),
            }
        else:
            ci["parent_device"] = None  # ãƒ«ãƒ¼ãƒˆãƒ‡ãƒã‚¤ã‚¹

        # å­ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§ï¼ˆç›´æ¥ã®é…ä¸‹ï¼‰
        children = []
        for nid, n in topology.items():
            if _get(n, 'parent_id') == target_node_id:
                n_md = _get(n, 'metadata') or {}
                children.append({
                    "id":     nid,
                    "type":   _get(n, 'type', ''),
                    "vendor": _pick_first(n_md, ["vendor", "manufacturer"], default=""),
                    "os":     _pick_first(n_md, ["os", "platform"], default=""),
                })
        ci["children_devices"] = children
        ci["children_count"]   = len(children)

        # å†—é•·ãƒšã‚¢ãƒ‡ãƒã‚¤ã‚¹ï¼ˆåŒã˜redundancy_groupã«å±ã™ã‚‹ä»–ã®ãƒ‡ãƒã‚¤ã‚¹ï¼‰
        if redundancy_group:
            peers = []
            for nid, n in topology.items():
                if nid == target_node_id:
                    continue
                if _get(n, 'redundancy_group') == redundancy_group:
                    n_md = _get(n, 'metadata') or {}
                    peers.append({
                        "id":     nid,
                        "type":   _get(n, 'type', ''),
                        "vendor": _pick_first(n_md, ["vendor", "manufacturer"], default=""),
                        "os":     _pick_first(n_md, ["os", "platform"], default=""),
                    })
            ci["redundancy_peers"] = peers
        else:
            ci["redundancy_peers"] = []  # SPOFã§ã‚ã‚‹ã“ã¨ã‚’æ˜ç¤º

        # åŒä¸€ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§ï¼ˆå‚è€ƒæƒ…å ±ï¼‰
        same_layer = [nid for nid, n in topology.items()
                      if _get(n, 'layer') == node_layer and nid != target_node_id]
        ci["same_layer_devices"] = same_layer

    # ---- ã‚³ãƒ³ãƒ•ã‚£ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆconfigsãƒ•ã‚©ãƒ«ãƒ€ï¼‰ ----
    try:
        conf = load_config_by_id(target_node_id) if target_node_id else ""
        if conf:
            ci["config_excerpt"] = conf[:1500]
    except Exception:
        pass

    return ci


def _sanitize_prediction_context(text: str, max_len: int = 800) -> str:
    """
    LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã‚µãƒ‹ã‚¿ã‚¤ã‚º:
    - å€‹äººæƒ…å ±ãƒ»ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ»IPç›´æ›¸ããƒ»åˆ¶å¾¡æ–‡å­—ã‚’é™¤å»
    - max_len ã§åˆ‡ã‚Šè©°ã‚ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè‚¥å¤§åŒ–é˜²æ­¢ â†’ é€Ÿåº¦æ”¹å–„ï¼‰
    """
    import re as _re
    # åˆ¶å¾¡æ–‡å­—é™¤å»ï¼ˆ\x01å«ã‚€å…¨C0åˆ¶å¾¡æ–‡å­—ï¼‰
    text = _re.sub(r'[\x00-\x1f\x7f]', '', text or "")
    # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ»ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆç³»ã‚’é®è”½
    text = _re.sub(r'(?i)(password|passwd|secret|token|api.?key)\s*[=:]\s*\S+', r'\1=[MASKED]', text)
    # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆIP ã¯æœ€å¾Œã‚ªã‚¯ãƒ†ãƒƒãƒˆã‚’ãƒã‚¹ã‚¯
    text = _re.sub(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.)\d{1,3}', r'\1***', text)
    return text[:max_len]


def _build_prediction_report_scenario(cand: dict, signal_count: int = 1) -> str:
    """
    äºˆå…†ç”¨ãƒ¬ãƒãƒ¼ãƒˆã‚·ãƒŠãƒªã‚ªã‚’æ§‹ç¯‰ï¼ˆRULäºˆæ¸¬ãƒ™ãƒ¼ã‚¹ï¼‰
    é‹ç”¨è€…è¦–ç‚¹: ã€Œä»Šå¾ŒNæ—¥å¾Œã«éšœå®³ç™ºç”Ÿã€è¡¨ç¾ã§çµ±ä¸€
    """
    dev_id        = cand.get('id', 'ä¸æ˜')
    pred_state    = cand.get('predicted_state') or cand.get('label', '').replace('ğŸ”® [äºˆå…†] ', '') or 'ä¸æ˜'
    pred_affected = int(cand.get('prediction_affected_count', 0))
    ttf_hours     = int(cand.get('prediction_time_to_failure_hours', 0))
    failure_dt    = cand.get('prediction_failure_datetime', '')
    ttc_min       = int(cand.get('prediction_time_to_critical_min', 60))
    confidence    = float(cand.get('confidence', cand.get('prob', 0.5)))
    rule_pattern  = cand.get('rule_pattern', '')
    reasons       = cand.get('reasons', [])

    # RULè¡¨ç¤º: ä»Šå¾ŒNæ—¥å¾Œã«éšœå®³ç™ºç”Ÿ
    if ttf_hours >= 24:
        ttf_display = f"ä»Šå¾Œ{ttf_hours // 24}æ—¥å¾Œã«éšœå®³ç™ºç”Ÿã®è¦‹è¾¼ã¿"
        if failure_dt:
            ttf_display += f"ï¼ˆ{failure_dt}é ƒï¼‰"
    elif ttf_hours > 0:
        ttf_display = f"ä»Šå¾Œ{ttf_hours}æ™‚é–“å¾Œã«éšœå®³ç™ºç”Ÿã®è¦‹è¾¼ã¿"
        if failure_dt:
            ttf_display += f"ï¼ˆ{failure_dt}é ƒï¼‰"
    else:
        ttf_display = "éšœå®³ãŒåˆ‡è¿«ã—ã¦ã„ã¾ã™"

    reason_summary = "; ".join(
        _sanitize_prediction_context(r, 120) for r in reasons[:3]
    ) if reasons else rule_pattern

    lines = [
        f"[RULäºˆæ¸¬] {dev_id}ã§éšœå®³ã®å‰å…†ã‚’æ¤œå‡ºï¼ˆä¿¡é ¼åº¦{confidence*100:.0f}%ï¼‰ã€‚{signal_count}ä»¶ã®å¾®å¼±ã‚·ã‚°ãƒŠãƒ«ã‚’ç¢ºèªã€‚",
        f"ãƒ»äºˆæ¸¬éšœå®³: {pred_state}",
        f"ãƒ»éšœå®³ç™ºç”Ÿäºˆæ¸¬: {ttf_display}",
        f"ãƒ»æ€¥æ€§æœŸé€²è¡Œ: ç—‡çŠ¶ç™ºç—‡å¾Œ{ttc_min}åˆ†ã§ã‚µãƒ¼ãƒ“ã‚¹æ–­ã«è‡³ã‚‹æã‚Œ",
        f"ãƒ»å½±éŸ¿ç¯„å›²: é…ä¸‹{pred_affected}å°ã«é€šä¿¡æ–­ãƒªã‚¹ã‚¯",
        f"ãƒ»æ¤œå‡ºã‚·ã‚°ãƒŠãƒ«: {reason_summary}",
        "ä»¥ä¸‹ã‚’ç°¡æ½”ã«æä¾›ã—ã¦ãã ã•ã„ï¼ˆå„é …ç›®3è¡Œä»¥å†…ï¼‰:",
        "1.äºˆå…†ãƒ‘ã‚¿ãƒ¼ãƒ³è§£èª¬ 2.ç¢ºèªã‚³ãƒãƒ³ãƒ‰ 3.åˆ¤å®šåŸºæº– 4.äºˆé˜²æªç½® 5.ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³",
    ]
    return "\n".join(lines)


def _build_prevention_plan_scenario(cand: dict) -> str:
    """äºˆé˜²æªç½®ãƒ—ãƒ©ãƒ³ç”¨ã‚·ãƒŠãƒªã‚ªï¼ˆRULäºˆæ¸¬ãƒ™ãƒ¼ã‚¹ï¼‰"""
    dev_id        = cand.get('id', 'ä¸æ˜')
    pred_state    = cand.get('predicted_state') or cand.get('label', '').replace('ğŸ”® [äºˆå…†] ', '') or 'ä¸æ˜'
    pred_affected = int(cand.get('prediction_affected_count', 0))
    ttc_min       = int(cand.get('prediction_time_to_critical_min', 60))
    ttf_hours     = int(cand.get('prediction_time_to_failure_hours', 0))
    failure_dt    = cand.get('prediction_failure_datetime', '')
    rec_actions   = cand.get('recommended_actions', [])

    # RULè¡¨ç¤º
    if ttf_hours >= 24:
        ttf_ctx = f"ä»Šå¾Œ{ttf_hours // 24}æ—¥å¾Œã«éšœå®³ç™ºç”Ÿ"
        if failure_dt:
            ttf_ctx += f"ï¼ˆ{failure_dt}é ƒï¼‰"
    else:
        ttf_ctx = f"ä»Šå¾Œ{ttf_hours}æ™‚é–“å¾Œã«éšœå®³ç™ºç”Ÿ" if ttf_hours > 0 else "éšœå®³ãŒåˆ‡è¿«"

    actions_txt = ""
    if rec_actions:
        actions_txt = " æ—¢çŸ¥ã®æ¨å¥¨: " + ", ".join(
            _sanitize_prediction_context(a.get('title',''), 60) for a in rec_actions[:3])

    lines = [
        f"[äºˆé˜²æªç½®] {dev_id}ã®éšœå®³äºˆå…†ã«å¯¾ã™ã‚‹äºˆé˜²æªç½®ãƒ—ãƒ©ãƒ³ã€‚",
        f"ãƒ»äºˆæ¸¬éšœå®³: {pred_state}",
        f"ãƒ»éšœå®³ç™ºç”Ÿäºˆæ¸¬: {ttf_ctx}",
        f"ãƒ»æ€¥æ€§æœŸé€²è¡Œ: ç—‡çŠ¶ç™ºç—‡å¾Œ{ttc_min}åˆ†ã§ã‚µãƒ¼ãƒ“ã‚¹æ–­",
        f"ãƒ»å½±éŸ¿ç¯„å›²: é…ä¸‹{pred_affected}å°{actions_txt}",
        "ã€Œå¾©æ—§ã€ã§ã¯ãªãã€Œäºˆé˜²æªç½®ãƒ»äº‹å‰å¯¾å¿œã€ã¨ã—ã¦ç°¡æ½”ã«æç¤ºï¼ˆå„æ‰‹é †2è¡Œä»¥å†…ï¼‰:",
        "1.å³æ™‚ç‚¹æ¤œ 2.äºˆé˜²ã‚³ãƒãƒ³ãƒ‰ 3.ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹è¨ˆç”» 4.ç›£è¦–å¼·åŒ– 5.ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¤æ–­åŸºæº–",
    ]
    return "\n".join(lines)
def run_diagnostic_simulation_no_llm(scenario: str, target_node_obj) -> dict:
    """LLMã‚’å‘¼ã°ãªã„ç–‘ä¼¼è¨ºæ–­"""
    device_id = getattr(target_node_obj, "id", "UNKNOWN") if target_node_obj else "UNKNOWN"
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    lines = [
        f"[PROBE] ts={ts}",
        f"[PROBE] scenario={scenario}",
        f"[PROBE] target_device={device_id}",
        "",
    ]

    recovered_devices = st.session_state.get("recovered_devices") or {}
    recovered_map = st.session_state.get("recovered_scenario_map") or {}

    if recovered_devices.get(device_id) and recovered_map.get(device_id) == scenario:
        if "FW" in scenario:
            lines += ["show chassis cluster status", "Redundancy group 0: healthy", "control link: up", "fabric link: up"]
        elif "WAN" in scenario:
            lines += ["show ip interface brief", "GigabitEthernet0/0 up up", "Neighbor 203.0.113.2 Established",
                      "ping 203.0.113.2 repeat 5", "Success rate is 100 percent (5/5)"]
        elif "L2SW" in scenario:
            lines += ["show environment", "Fan: OK", "Temperature: OK", "show interface status", "Uplink: up"]
        else:
            lines += ["show system alarms", "No active alarms", "ping 8.8.8.8 repeat 5", "Success rate is 100 percent (5/5)"]
        return {"status": "SUCCESS", "sanitized_log": "\n".join(lines), "device_id": device_id}

    if "WANå…¨å›ç·šæ–­" in scenario or "[WAN]" in scenario:
        lines += ["show ip interface brief", "GigabitEthernet0/0 down down", "show ip bgp summary",
                  "Neighbor 203.0.113.2 Idle", "ping 203.0.113.2 repeat 5", "Success rate is 0 percent (0/5)"]
    elif "FWç‰‡ç³»éšœå®³" in scenario or "[FW]" in scenario:
        lines += ["show chassis cluster status", "Redundancy group 0: degraded", "control link: down", "fabric link: up"]
    elif "L2SW" in scenario:
        lines += ["show environment", "Fan: FAIL", "Temperature: HIGH", "show interface status", "Uplink: flapping"]
    else:
        lines += ["show system alarms", "No active alarms"]

    return {"status": "SUCCESS", "sanitized_log": "\n".join(lines), "device_id": device_id}


# =====================================================
# ãƒ¡ã‚¤ãƒ³æç”»é–¢æ•°
# =====================================================
def render_incident_cockpit(site_id: str, api_key: Optional[str]):
    display_name = get_display_name(site_id)
    scenario = st.session_state.site_scenarios.get(site_id, "æ­£å¸¸ç¨¼åƒ")

    # ãƒ˜ãƒƒãƒ€ãƒ¼
    col_header = st.columns([4, 1])
    with col_header[0]:
        st.markdown(f"### ğŸ›¡ï¸ AIOps ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆ")
    with col_header[1]:
        if st.button("ğŸ”™ ä¸€è¦§ã«æˆ»ã‚‹", key="back_to_list"):
            st.session_state.active_site = None
            #st.rerun()  # Disabled to prevent white screen

    # ãƒˆãƒãƒ­ã‚¸ãƒ¼èª­ã¿è¾¼ã¿
    paths = get_paths(site_id)
    topology = load_topology(paths.topology_path)

    if not topology:
        st.error("ãƒˆãƒãƒ­ã‚¸ãƒ¼ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    # ã‚¢ãƒ©ãƒ¼ãƒ ç”Ÿæˆ
    alarms = generate_alarms_for_scenario(topology, scenario)
    status = get_status_from_alarms(scenario, alarms)
    
    # â˜… å°†æ¥ã®æ‹¡å¼µ: éšœå®³ç™ºç”Ÿæ™‚ã«äºˆå…†ã‚’è‡ªå‹•ç¢ºèªï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
    # if dt_engine and scenario != "æ­£å¸¸ç¨¼åƒ":
    #     # CRITICAL ã‚¢ãƒ©ãƒ¼ãƒ ãŒç™ºç”Ÿã—ãŸãƒ‡ãƒã‚¤ã‚¹ã®äºˆå…†ã‚’è‡ªå‹•çš„ã« confirmed_incident ã«æ›´æ–°
    #     critical_devices = {a.device_id for a in alarms if a.severity == "CRITICAL"}
    #     for dev_id in critical_devices:
    #         confirmed_count = dt_engine.forecast_auto_confirm_on_incident(
    #             dev_id, scenario=scenario, note="éšœå®³ã‚·ãƒŠãƒªã‚ªç™ºç”Ÿã«ã‚ˆã‚Šè‡ªå‹•ç¢ºèª"
    #         )
    #         if confirmed_count > 0:
    #             logger.info(f"Auto-confirmed {confirmed_count} predictions for {dev_id} on scenario: {scenario}")

    # äºˆå…†ã‚·ã‚°ãƒŠãƒ«æ³¨å…¥
    injected = st.session_state.get("injected_weak_signal")
    if injected and injected["device_id"] in topology:
        messages = injected.get("messages", [injected.get("message", "")])
        for msg in messages:
            if msg:
                alarms.append(Alarm(
                    device_id=injected["device_id"],
                    message=msg,
                    severity="INFO",
                    is_root_cause=False
                ))

    # LogicalRCA ã‚¨ãƒ³ã‚¸ãƒ³
    engine_key = f"engine_{site_id}"
    if engine_key not in st.session_state.logic_engines:
        st.session_state.logic_engines[engine_key] = LogicalRCA(topology)
    engine = st.session_state.logic_engines[engine_key]

    if alarms:
        analysis_results = engine.analyze(alarms)
    else:
        analysis_results = [{
            "id": "SYSTEM",
            "label": "æ­£å¸¸ç¨¼åƒ",
            "prob": 0.0,
            "type": "Normal",
            "tier": 3,
            "reason": "ã‚¢ãƒ©ãƒ¼ãƒ ãªã—"
        }]

    # =====================================================
    # â˜… Phase1: DigitalTwinEngine.predict_api() æ¥ç¶š
    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ³¨å…¥ OR æ­£å¸¸ã‚·ãƒŠãƒªã‚ªã§ dt_engine ã‚’å‘¼ã¶
    # =====================================================
    dt_key     = f"dt_engine_{site_id}"
    dt_err_key = f"dt_engine_error_{site_id}"
    dt_engine  = st.session_state.get(dt_key)

    # â˜… å£Šã‚ŒãŸã‚¨ãƒ³ã‚¸ãƒ³(ãƒ­ãƒƒã‚¯å–å¾—ä¸å¯)ã®æ¤œå‡ºã¨ãƒªã‚»ãƒƒãƒˆ
    if dt_engine is not None:
        try:
            # ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã§_db_lockã®å–å¾—ã‚’è©¦ã¿ã‚‹
            # å–å¾—ã§ããªã„å ´åˆã¯ã‚¨ãƒ³ã‚¸ãƒ³ãŒå£Šã‚Œã¦ã„ã‚‹(ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯çŠ¶æ…‹)
            _lock_acquired = dt_engine.storage._db_lock.acquire(blocking=False)
            if _lock_acquired:
                dt_engine.storage._db_lock.release()
            else:
                # ãƒ­ãƒƒã‚¯å–å¾—å¤±æ•— â†’ ã‚¨ãƒ³ã‚¸ãƒ³ãŒãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯çŠ¶æ…‹ â†’ ãƒªã‚»ãƒƒãƒˆ
                import logging as _logging
                _logging.getLogger(__name__).warning(
                    f"[dt_engine] {site_id}: DB lock deadlock detected. Resetting engine.")
                st.session_state[dt_key] = None
                st.session_state[dt_err_key] = None
                # dt_auto_confirmed / dt_auto_mitigated ã‚‚ã‚¯ãƒªã‚¢ã—ã¦å†ç¢ºèªã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
                for _k in [k for k in list(st.session_state.keys())
                           if k.startswith(f"dt_auto_") and site_id in k]:
                    del st.session_state[_k]
                dt_engine = None
        except Exception:
            pass

    if dt_engine is None and not st.session_state.get(dt_err_key):
        try:
            from digital_twin_pkg import DigitalTwinEngine as _DTE
            _children_map: dict = {}
            for _nid, _n in topology.items():
                _pid = (_n.get('parent_id') if isinstance(_n, dict)
                        else getattr(_n, 'parent_id', None))
                if _pid:
                    _children_map.setdefault(_pid, []).append(_nid)
            dt_engine = _DTE(topology=topology, children_map=_children_map, tenant_id=site_id)
            st.session_state[dt_key]     = dt_engine
            st.session_state[dt_err_key] = None
        except Exception as _dte_err:
            import traceback as _tb
            st.session_state[dt_err_key] = f"{type(_dte_err).__name__}: {_dte_err}\n{_tb.format_exc()}"
            dt_engine = None

    # æœŸé™åˆ‡ã‚Œäºˆå…†ã‚’å®šæœŸçš„ã«è§£æ¶ˆï¼ˆrate limit: 5åˆ†ã«1å›ï¼‰
    _expire_key = f"dt_expire_ts_{site_id}"
    if dt_engine and (time.time() - st.session_state.get(_expire_key, 0)) > 300:
        dt_engine.forecast_expire_open()
        st.session_state[_expire_key] = time.time()

    # =====================================================
    # â˜… ç«¶åˆæ¤œå‡º: éšœå®³ã‚·ãƒŠãƒªã‚ªã¨äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æ’ä»–åˆ¶å¾¡
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ã€Œäºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ã®æœ¬æ¥ã®æ„å‘³:
    #   æ­£å¸¸ç¨¼åƒä¸­ã«å¼±ã„ã‚·ã‚°ãƒŠãƒ«ã‚’æ³¨å…¥ â†’ DTãŒäºˆå…†ã‚’æ¤œçŸ¥
    # éšœå®³ã‚·ãƒŠãƒªã‚ª active æ™‚ã¯æ„å‘³è«–çš„ã«æ™‚ç³»åˆ—é€†è»¢ã™ã‚‹ãŸã‚æ’ä»–åˆ¶å¾¡
    # =====================================================
    _injected        = st.session_state.get("injected_weak_signal")
    _scenario_active = (scenario != "æ­£å¸¸ç¨¼åƒ")
    _sim_active      = bool(_injected and _injected.get("device_id") in topology)

    # ç«¶åˆçŠ¶æ…‹: éšœå®³ã‚·ãƒŠãƒªã‚ªä¸­ã«äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒæ³¨å…¥ã•ã‚Œã¦ã„ã‚‹
    _conflict = _scenario_active and _sim_active

    if _conflict:
        # ç«¶åˆãƒ‡ãƒã‚¤ã‚¹ãŒå®Ÿéšœå®³ã¨é‡ãªã‚‹ã‹ç¢ºèª
        _sim_device     = _injected.get("device_id", "")
        _critical_set   = {a.device_id for a in alarms if a.severity == "CRITICAL"}
        _warning_set    = {a.device_id for a in alarms if a.severity == "WARNING"}
        _conflict_level = ("CRITICAL" if _sim_device in _critical_set
                           else "WARNING" if _sim_device in _warning_set
                           else "OTHER")

        # ç«¶åˆè­¦å‘Šã‚’UIã«è¡¨ç¤º
        if _conflict_level in ("CRITICAL", "WARNING"):
            st.warning(
                "âš ï¸ **äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç«¶åˆæ¤œå‡º**\n\n"
                f"ç¾åœ¨ã®éšœå®³ã‚·ãƒŠãƒªã‚ªã€Œ**{scenario}**ã€ã«ã‚ˆã‚Š `{_sim_device}` ã¯æ—¢ã« "
                f"**{_conflict_level}** çŠ¶æ…‹ã§ã™ã€‚\n"
                "äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯ **ç„¡åŠ¹åŒ–** ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\n"
                "ğŸ’¡ äºˆå…†â†’éšœå®³ã®æµã‚Œã‚’ãƒ‡ãƒ¢ã™ã‚‹ã«ã¯:\n"
                "1. ã‚·ãƒŠãƒªã‚ªã‚’ã€Œæ­£å¸¸ç¨¼åƒã€ã«æˆ»ã™\n"
                "2. äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œï¼ˆã‚¢ãƒ³ãƒãƒ¼è‰²ã§ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼‰\n"
                "3. éšœå®³ã‚·ãƒŠãƒªã‚ªã«åˆ‡ã‚Šæ›¿ãˆã¦ã€Œäºˆå…†ãŒçš„ä¸­ã—ãŸã€ã‚’ç¢ºèª"
            )
        else:
            # ç•°ãªã‚‹ãƒ‡ãƒã‚¤ã‚¹ã¸ã®æ³¨å…¥ã¯è¨±å®¹ã™ã‚‹ãŒæ³¨æ„å–šèµ·
            st.info(
                f"â„¹ï¸ éšœå®³ã‚·ãƒŠãƒªã‚ªã€Œ**{scenario}**ã€å®Ÿè¡Œä¸­ã§ã™ã€‚\n"
                f"`{_sim_device}` ã¸ã®äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯ç¶™ç¶šã—ã¾ã™ãŒã€"
                "forecast_ledger ã®è‡ªå‹• CONFIRMED ç™»éŒ²ã¯ **æŠ‘åˆ¶** ã•ã‚Œã¾ã™ã€‚"
            )

    # æ³¨å…¥ã‚·ã‚°ãƒŠãƒ« OR å®Ÿã‚¢ãƒ©ãƒ¼ãƒ ã‚’ dt_engine ã«é€šã—ã¦äºˆå…†ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ
    dt_predictions: List[dict] = []
    if dt_engine:
        _msg_sources = []

        # A) äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ³¨å…¥ã‚·ã‚°ãƒŠãƒ«
        #    ç«¶åˆã‹ã¤åŒãƒ‡ãƒã‚¤ã‚¹ãŒéšœå®³ä¸­ã®å ´åˆã¯ç„¡åŠ¹åŒ–
        if _sim_active:
            _sim_dev  = _injected.get("device_id", "")
            # _critical_set/_warning_set ã¯ _conflict=True æ™‚ã®ã¿å®šç¾©æ¸ˆã¿
            _alarm_devices = {a.device_id for a in alarms
                              if a.severity in ("CRITICAL", "WARNING")}
            _disabled = (_conflict and _sim_dev in _alarm_devices)
            if not _disabled:
                _msgs = _injected.get("messages", [_injected.get("message", "")])
                for _m in _msgs:
                    if _m:
                        _msg_sources.append((_sim_dev, _m, "simulation"))

        # degradation_level ã‚’ sidebar ã‹ã‚‰å–å¾— + ãƒ‡ãƒã‚¤ã‚¹å¤‰æ›´æ™‚ã®ãƒ¬ãƒãƒ¼ãƒˆãƒªã‚»ãƒƒãƒˆ
        _sim_level = int((_injected or {}).get("level", 1)) if _sim_active else 1
        _prev_sim_dev_key = f"dt_prev_sim_device_{site_id}"
        _cur_sim_dev = (_injected or {}).get("device_id", "")
        if _cur_sim_dev != st.session_state.get(_prev_sim_dev_key, ""):
            for _k in [k for k in list(st.session_state.report_cache.keys())
                       if "analyst" in k and site_id in k]:
                del st.session_state.report_cache[_k]
            st.session_state.generated_report   = None
            st.session_state.remediation_plan   = None
            st.session_state.verification_log   = None
            st.session_state[_prev_sim_dev_key] = _cur_sim_dev

        # B) å®Ÿã‚¢ãƒ©ãƒ¼ãƒ ã® WARNING/INFOï¼ˆéšœå®³ç¢ºå®šå‰ã®å¼±ã„ã‚·ã‚°ãƒŠãƒ«ï¼‰
        for _a in alarms:
            if _a.severity in ("WARNING", "INFO") and not _a.is_root_cause:
                _msg_sources.append((_a.device_id, _a.message, "real"))

        _signal_count = len(_msg_sources)

        # â˜… ãƒ‡ãƒã‚¤ã‚¹IDã”ã¨ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦ã‹ã‚‰ predict_api ã‚’1å›ã ã‘å‘¼ã¶
        # å¾“æ¥: 1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ Ã— Nå› â†’ LLMã«1ä»¶ã—ã‹æ¸¡ã‚‰ãšæ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç²¾åº¦ãŒä½ã‹ã£ãŸ
        # ä¿®æ­£: ãƒ‡ãƒã‚¤ã‚¹å˜ä½ã§å…¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã¾ã¨ã‚ã¦1å› â†’ LLMã«å…¨æ–‡è„ˆã‚’æ¸¡ã™
        #       forecast_ledger ã¸ã®é‡è¤‡ç™»éŒ²ã‚‚é˜²ãï¼ˆ"optical 16ä»¶" å•é¡Œã®è§£æ¶ˆï¼‰
        _dev_msg_map: dict = {}
        for _dev_id, _msg, _src in _msg_sources:
            if _dev_id not in _dev_msg_map:
                _dev_msg_map[_dev_id] = {"messages": [], "src": _src}
            _dev_msg_map[_dev_id]["messages"].append(_msg)
            if _src == "simulation":  # simulation ãŒæ··ã˜ã‚Œã° simulation å„ªå…ˆ
                _dev_msg_map[_dev_id]["src"] = "simulation"

        for _dev_id, _dev_data in _dev_msg_map.items():
            _msgs = _dev_data["messages"]
            _src  = _dev_data["src"]
            _resp = dt_engine.predict_api({
                "tenant_id":       site_id,
                "device_id":       _dev_id,
                "msg":             _msgs[0],    # å¾Œæ–¹äº’æ›: å…ˆé ­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                "messages":        _msgs,        # â˜… å…¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’LLMã«æ¸¡ã™
                "timestamp":       time.time(),
                "record_forecast": True,
                "api_key":         api_key or "",
                "attrs":           {
                    "source":            _src,
                    "degradation_level": _sim_level if _src == "simulation" else 1,
                }
            })
            if _resp.get("ok"):
                for _p in _resp.get("predictions", []):
                    _p["id"]     = _dev_id
                    _p["source"] = _src
                    _p["prediction_signal_count"] = _signal_count

                    # ãƒ‡ãƒã‚¤ã‚¹ã”ã¨ã«1ã‚¨ãƒ³ãƒˆãƒªï¼ˆé‡è¤‡ãªã—ï¼‰
                    _existing_idx = next(
                        (i for i, d in enumerate(dt_predictions) if d.get("id") == _dev_id),
                        None
                    )
                    if _existing_idx is None:
                        dt_predictions.append(_p)
                    else:
                        # æ—¢å­˜ã‚ã‚Š: æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒå¼·åŒ–ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ä¸Šæ›¸ã
                        _existing = dt_predictions[_existing_idx]
                        _new_acts = _p.get("recommended_actions", [])
                        _old_acts = _existing.get("recommended_actions", [])
                        _new_has_high = any(a.get("priority") == "high" for a in _new_acts)
                        _old_has_high = any(a.get("priority") == "high" for a in _old_acts)
                        if (_new_has_high and not _old_has_high) or (len(_new_acts) > len(_old_acts)):
                            dt_predictions[_existing_idx] = _p

        # â”€â”€ è‡ªå‹• outcome ç™»éŒ² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Execute æˆåŠŸæ¸ˆã¿ãƒ‡ãƒã‚¤ã‚¹ â†’ MITIGATEDï¼ˆç«¶åˆçŠ¶æ…‹ã«é–¢ã‚ã‚‰ãšæœ‰åŠ¹ï¼‰
        for _rid, _recovered in list(st.session_state.get("recovered_devices", {}).items()):
            if _recovered:
                _auto_key = f"dt_auto_mitigated_{site_id}_{_rid}"
                if not st.session_state.get(_auto_key):
                    dt_engine.forecast_auto_resolve(
                        _rid, "mitigated", note="Execute æˆåŠŸã«ã‚ˆã‚‹è‡ªå‹•è§£æ¶ˆ")
                    st.session_state[_auto_key] = True

        # CRITICAL ã‚¢ãƒ©ãƒ¼ãƒ ç¢ºå®š â†’ CONFIRMED
        # ãŸã ã—ç«¶åˆçŠ¶æ…‹ï¼ˆéšœå®³ã‚·ãƒŠãƒªã‚ª activeï¼‰ã§ã¯æŠ‘åˆ¶ã—ã¦èª¤è‡ªå‹•ç™»éŒ²ã‚’é˜²ã
        if not _conflict:
            _critical_devices = {a.device_id for a in alarms if a.severity == "CRITICAL"}
            for _cd in _critical_devices:
                _auto_key = f"dt_auto_confirmed_{site_id}_{_cd}"
                if not st.session_state.get(_auto_key):
                    dt_engine.forecast_auto_resolve(
                        _cd, "confirmed_incident",
                        note="CRITICAL ã‚¢ãƒ©ãƒ¼ãƒ ã«ã‚ˆã‚‹è‡ªå‹•ç¢ºå®š")
                    st.session_state[_auto_key] = True

    # DTäºˆå…†ã‚’ analysis_results ã«ãƒãƒ¼ã‚¸ï¼ˆæ—¢å­˜ã® is_prediction çµæœã¨é‡è¤‡ã—ãªã„ï¼‰
    existing_pred_ids = {r.get("id") for r in analysis_results if r.get("is_prediction")}
    for _dp in dt_predictions:
        if _dp.get("id") not in existing_pred_ids:
            analysis_results.append(_dp)

    # =====================================================
    # â˜… ãƒ‡ãƒã‚¤ã‚¹å¤‰æ›´æ¤œçŸ¥: äºˆå…†ã‚·ãƒŸãƒ¥å¯¾è±¡ãŒå¤‰ã‚ã£ãŸã‚‰ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ
    # =====================================================
    _sim_device_now = (_injected.get("device_id") if _injected else None)
    _sim_device_key = f"dt_last_sim_device_{site_id}"
    _sim_device_prev = st.session_state.get(_sim_device_key)
    if _sim_device_now != _sim_device_prev:
        st.session_state.generated_report   = None
        st.session_state.remediation_plan   = None
        st.session_state.verification_log   = None
        # ãƒ¬ãƒãƒ¼ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚äºˆå…†ç³»ã®ã‚¨ãƒ³ãƒˆãƒªã ã‘å‰Šé™¤
        _keys_to_del = [k for k in st.session_state.get("report_cache", {})
                        if "analyst" in k or "remediation" in k]
        for _k in _keys_to_del:
            st.session_state.report_cache.pop(_k, None)
        st.session_state[_sim_device_key] = _sim_device_now

    # =====================================================
    # KPIãƒ¡ãƒˆãƒªã‚¯ã‚¹
    # =====================================================
    root_cause_alarms = [a for a in alarms if a.is_root_cause]
    total_alarms = len(alarms)
    noise_reduction = ((total_alarms - len(root_cause_alarms)) / total_alarms * 100) if total_alarms > 0 else 0.0
    action_required = len(set(a.device_id for a in root_cause_alarms))
    prediction_results = [r for r in analysis_results if r.get('is_prediction')]
    prediction_count = len(prediction_results)

    st.markdown("---")
    cols = st.columns(3)
    cols[0].metric("ğŸš¨ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", f"{get_status_icon(status)} {status}")
    cols[1].metric("ğŸ“Š ã‚¢ãƒ©ãƒ¼ãƒ æ•°", f"{total_alarms}ä»¶")
    suspect_count = len([r for r in analysis_results if r.get('prob', 0) > 0.5])
    if prediction_count > 0:
        cols[2].metric("ğŸ¯ è¢«ç–‘ç®‡æ‰€", f"{suspect_count}ä»¶",
                       delta=f"ã†ã¡ğŸ”®äºˆå…† {prediction_count}ä»¶", delta_color="off")
    else:
        cols[2].metric("ğŸ¯ è¢«ç–‘ç®‡æ‰€", f"{suspect_count}ä»¶")

    kpi_cols = st.columns(3)
    with kpi_cols[0]:
        delta_text = "â†‘ é«˜åŠ¹ç‡ç¨¼åƒä¸­" if noise_reduction > 90 else ("â†’ é€šå¸¸ç¨¼åƒ" if noise_reduction > 50 else "â†“ è¦ç¢ºèª")
        delta_color = "normal" if noise_reduction > 90 else ("off" if noise_reduction > 50 else "inverse")
        kpi_cols[0].metric("ğŸ“‰ ãƒã‚¤ã‚ºå‰Šæ¸›ç‡", f"{noise_reduction:.1f}%", delta=delta_text, delta_color=delta_color)
    with kpi_cols[1]:
        kpi_cols[1].metric("ğŸ”® äºˆå…†æ¤œçŸ¥", f"{prediction_count}ä»¶",
                           delta="âš¡ è¦æ³¨æ„" if prediction_count > 0 else "å•é¡Œãªã—",
                           delta_color="inverse" if prediction_count > 0 else "normal")
    with kpi_cols[2]:
        kpi_cols[2].metric("ğŸš¨ è¦å¯¾å¿œã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ", f"{action_required}ä»¶",
                           delta="â†‘ å¯¾å‡¦ãŒå¿…è¦" if action_required > 0 else "å•é¡Œãªã—",
                           delta_color="inverse" if action_required > 0 else "normal")

    st.markdown("---")

    # =====================================================
    # æ ¹æœ¬åŸå› å€™è£œã¨ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®åˆ†é›¢
    # =====================================================
    root_cause_device_ids = set(a.device_id for a in alarms if a.is_root_cause)
    downstream_device_ids = set(a.device_id for a in alarms if not a.is_root_cause)

    root_cause_candidates = []
    downstream_devices = []

    for cand in analysis_results:
        device_id = cand.get('id', '')
        if cand.get('is_prediction'):
            root_cause_candidates.append(cand)
        elif device_id in root_cause_device_ids:
            root_cause_candidates.append(cand)
        elif device_id in downstream_device_ids:
            downstream_devices.append(cand)
        elif cand.get('prob', 0) > 0.5:
            root_cause_candidates.append(cand)

    if not root_cause_candidates and not alarms:
        root_cause_candidates = [{
            "id": "SYSTEM", "label": "æ­£å¸¸ç¨¼åƒ", "prob": 0.0,
            "type": "Normal", "tier": 3, "reason": "ã‚¢ãƒ©ãƒ¼ãƒ ãªã—"
        }]

    if root_cause_candidates and downstream_devices:
        st.info(f"ğŸ“ **æ ¹æœ¬åŸå› **: {root_cause_candidates[0]['id']} â†’ å½±éŸ¿ç¯„å›²: é…ä¸‹ {len(downstream_devices)} æ©Ÿå™¨")

    # =====================================================
    # ğŸ”® AIOps Future Radarï¼ˆäºˆå…†å°‚ç”¨è¡¨ç¤ºã‚¨ãƒªã‚¢ï¼‰
    # =====================================================
    prediction_candidates = [c for c in root_cause_candidates if c.get('is_prediction')]

    if prediction_candidates:
        st.markdown("### ğŸ”® AIOps Future Radar")
        with st.container(border=True):
            injected_info = st.session_state.get("injected_weak_signal")
            if injected_info:
                level = injected_info.get("level", 0)
                scenario_name = injected_info.get("scenario", "")
                st.info(
                    f"âš ï¸ **äºˆå…†æ¤œçŸ¥**: ç¾åœ¨ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çŠ¶æ…‹ã¯ã€Œæ­£å¸¸ã€ã§ã™ãŒã€"
                    f"AIãŒå¾®ç´°ãªã‚·ã‚°ãƒŠãƒ«ã‹ã‚‰å°†æ¥ã®éšœå®³ãƒªã‚¹ã‚¯ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚"
                    f"ï¼ˆåŠ£åŒ–ã‚·ãƒŠãƒªã‚ª: {scenario_name} / ãƒ¬ãƒ™ãƒ«: {level}/5ï¼‰"
                )
            else:
                st.info("âš ï¸ **äºˆå…†æ¤œçŸ¥**: AIãŒå°†æ¥ã®éšœå®³ãƒªã‚¹ã‚¯ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")

            radar_cols = st.columns(min(len(prediction_candidates), 3))
            for idx, pred_item in enumerate(prediction_candidates[:3]):
                with radar_cols[idx]:
                    prob_pct        = f"{pred_item.get('prob', 0)*100:.0f}%"
                    confidence      = pred_item.get('confidence', pred_item.get('prob', 0))
                    pred_timeline   = pred_item.get('prediction_timeline', 'ä¸æ˜')
                    ttc_min         = pred_item.get('prediction_time_to_critical_min',
                                       pred_item.get('time_to_critical_min', 0))
                    pred_affected   = pred_item.get('prediction_affected_count', 0)
                    pred_label      = (pred_item.get('predicted_state')
                                       or pred_item.get('label', '').replace('ğŸ”® [äºˆå…†] ', '')
                                       or 'ä¸æ˜')
                    ttf_hours       = pred_item.get('prediction_time_to_failure_hours', 0)
                    failure_dt      = pred_item.get('prediction_failure_datetime', '')
                    rule_pattern    = pred_item.get('rule_pattern', '')
                    criticality     = pred_item.get('criticality', 'standard')
                    reasons         = pred_item.get('reasons', [])
                    rec_actions     = pred_item.get('recommended_actions', [])
                    source          = pred_item.get('source', 'real')

                    # â”€â”€ ãƒ˜ãƒƒãƒ€ãƒ¼: æ©Ÿå™¨å + äºˆå…†ç¨®åˆ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    _crit_badge = "ğŸ”´ CRITICAL" if criticality == "critical" else "ğŸŸ  STANDARD"
                    _src_badge  = "ğŸ”¬ ã‚·ãƒŸãƒ¥" if source == "simulation" else "ğŸ“¡ å®Ÿæ¸¬"
                    st.markdown(
                        f"<div style='background:#FFF8E1;border-left:4px solid #FFB300;"
                        f"padding:8px 12px;border-radius:4px;margin-bottom:8px;'>"
                        f"<b>ğŸ“ {pred_item['id']}</b>"
                        f"<span style='float:right;font-size:11px;color:#BF360C;'>"
                        f"{_crit_badge} {_src_badge}</span></div>",
                        unsafe_allow_html=True
                    )

                    # â”€â”€ ç¢ºä¿¡åº¦ + ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    st.markdown(
                        f"<div style='text-align:center;padding:8px 0;'>"
                        f"<span style='font-size:40px;font-weight:bold;color:#E65100;'>"
                        f"{prob_pct}</span>"
                        f"<br><span style='color:#666;font-size:13px;'>"
                        f"éšœå®³ç™ºç”Ÿç¢ºä¿¡åº¦</span></div>",
                        unsafe_allow_html=True
                    )

                    # â”€â”€ RULäºˆæ¸¬è©³ç´°ã‚«ãƒ¼ãƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    # éšœå®³ç™ºç”Ÿäºˆæ¸¬æ™‚åˆ»ã®è¡¨ç¤º
                    if ttf_hours >= 24:
                        ttf_display = f"ä»Šå¾Œ <b>{ttf_hours // 24}æ—¥å¾Œ</b>"
                        if failure_dt:
                            ttf_display += f" ({failure_dt}é ƒ)"
                    elif ttf_hours > 0:
                        ttf_display = f"ä»Šå¾Œ <b>{ttf_hours}æ™‚é–“å¾Œ</b>"
                        if failure_dt:
                            ttf_display += f" ({failure_dt}é ƒ)"
                    else:
                        ttf_display = "<span style='color:#d32f2f'>éšœå®³ãŒåˆ‡è¿«</span>"
                    
                    st.markdown(
                        f"<div style='background:#FFF3E0;border-radius:6px;"
                        f"padding:10px 12px;margin:6px 0;font-size:13px;'>"
                        f"<b>ğŸ”® äºˆæ¸¬éšœå®³:</b> {pred_label}<br>"
                        f"<b>ğŸ“… éšœå®³ç™ºç”Ÿäºˆæ¸¬:</b> {ttf_display}<br>"
                        f"<b>â±ï¸ æ€¥æ€§æœŸé€²è¡Œ:</b> "
                        + (f"ç—‡çŠ¶ç™ºç—‡å¾Œ <span style='color:#d32f2f;font-weight:bold;'>{ttc_min}åˆ†</span> ã§ã‚µãƒ¼ãƒ“ã‚¹æ–­"
                           if ttc_min > 0 else "<span style='color:#d32f2f'>ä¸æ˜</span>")
                        + (f"<br><b>ğŸ“¡ å½±éŸ¿ç¯„å›²:</b> é…ä¸‹ <b>{pred_affected}å°</b> é€šä¿¡æ–­ãƒªã‚¹ã‚¯"
                           if pred_affected > 0 else "")
                        + f"</div>",
                        unsafe_allow_html=True
                    )

                    # â”€â”€ æ¤œçŸ¥ã‚·ã‚°ãƒŠãƒ« â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    if reasons:
                        with st.expander("ğŸ” æ¤œçŸ¥ã‚·ã‚°ãƒŠãƒ«è©³ç´°", expanded=False):
                            for _r in reasons:
                                st.caption(f"â€¢ {_r}")
                            if rule_pattern:
                                st.caption(f"é©ç”¨ãƒ«ãƒ¼ãƒ«: `{rule_pattern}`")

                    # â”€â”€ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    if rec_actions:
                        with st.expander("ğŸ› ï¸ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³", expanded=True):
                            for idx, _act in enumerate(rec_actions, 1):
                                _title = _act.get('title', '')
                                _effect = _act.get('effect', '')
                                _priority = _act.get('priority', 'medium')
                                _rationale = _act.get('rationale', '')
                                _steps = _act.get('steps', '')
                                
                                # å„ªå…ˆåº¦ã«å¿œã˜ãŸè‰²ã¨ã‚¢ã‚¤ã‚³ãƒ³
                                if _priority == 'high':
                                    _bg_color = '#FFEBEE'  # è–„ã„èµ¤
                                    _border_color = '#D32F2F'  # æ¿ƒã„èµ¤
                                    _icon = 'ğŸ”´'
                                    _priority_label = 'æœ€å„ªå…ˆ'
                                elif _priority == 'medium':
                                    _bg_color = '#FFF3E0'  # è–„ã„ã‚ªãƒ¬ãƒ³ã‚¸
                                    _border_color = '#FF6F00'  # æ¿ƒã„ã‚ªãƒ¬ãƒ³ã‚¸
                                    _icon = 'ğŸŸ '
                                    _priority_label = 'æ¨å¥¨'
                                else:  # low
                                    _bg_color = '#E8F5E9'  # è–„ã„ç·‘
                                    _border_color = '#2E7D32'  # æ¿ƒã„ç·‘
                                    _icon = 'ğŸŸ¢'
                                    _priority_label = 'è£œåŠ©'
                                
                                st.markdown(
                                    f"<div style='background:{_bg_color};padding:10px 12px;"
                                    f"border-left:4px solid {_border_color};border-radius:4px;"
                                    f"margin:8px 0;font-size:13px;'>"
                                    f"<div style='margin-bottom:4px;'>"
                                    f"<b>{_icon} {idx}. {_title}</b>"
                                    f"<span style='float:right;background:{_border_color};color:white;"
                                    f"padding:2px 8px;border-radius:3px;font-size:11px;'>{_priority_label}</span>"
                                    f"</div>"
                                    + (f"<div style='color:#424242;margin:4px 0;font-size:12px;'>"
                                       f"ğŸ’¡ åŠ¹æœ: {_effect}</div>" if _effect else "")
                                    + (f"<div style='color:#616161;margin:4px 0;font-size:11px;'>"
                                       f"ğŸ“Œ æ ¹æ‹ : {_rationale}</div>" if _rationale else "")
                                    + (f"<div style='background:white;padding:6px;border-radius:3px;"
                                       f"margin-top:6px;font-size:11px;color:#424242;white-space:pre-wrap;'>"
                                       f"<b>ğŸ“‹ æ‰‹é †:</b><br>{_steps}</div>" if _steps else "")
                                    + "</div>",
                                    unsafe_allow_html=True
                                )
                    else:
                        st.caption("æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãªã—")
        st.markdown("---")

    # =====================================================
    # ğŸ¯ æ ¹æœ¬åŸå› å€™è£œãƒ†ãƒ¼ãƒ–ãƒ«
    # â˜…â˜…â˜… ä¿®æ­£â‘ : alarm_info_mapã‚’ä½¿ã£ãŸseverityåŸºæº–ã®åˆ¤å®šã«æˆ»ã™ â˜…â˜…â˜…
    # =====================================================
    selected_incident_candidate = None
    target_device_id = None

    if root_cause_candidates:
        # ã‚¢ãƒ©ãƒ¼ãƒ ã®severityã¨silentãƒ•ãƒ©ã‚°ã‚’ãƒ‡ãƒã‚¤ã‚¹IDã§ãƒãƒƒãƒ”ãƒ³ã‚°
        alarm_info_map = {}
        for a in alarms:
            if a.device_id not in alarm_info_map:
                alarm_info_map[a.device_id] = {'severity': 'INFO', 'is_silent': False}
            if a.severity == 'CRITICAL':
                alarm_info_map[a.device_id]['severity'] = 'CRITICAL'
            elif a.severity == 'WARNING' and alarm_info_map[a.device_id]['severity'] != 'CRITICAL':
                alarm_info_map[a.device_id]['severity'] = 'WARNING'
            if hasattr(a, 'is_silent_suspect') and a.is_silent_suspect:
                alarm_info_map[a.device_id]['is_silent'] = True

        df_data = []
        for rank, cand in enumerate(root_cause_candidates, 1):
            prob = cand.get('prob', 0)
            cand_type = cand.get('type', 'UNKNOWN')
            device_id = cand['id']
            alarm_info = alarm_info_map.get(device_id, {'severity': 'INFO', 'is_silent': False})

            # â˜… æ—§app.pyã¨åŒã˜åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆseverityåŸºæº–ï¼‰
            if cand.get('is_prediction'):
                status_text = "ğŸ”® äºˆå…†æ¤œçŸ¥"
                timeline = cand.get('prediction_timeline', '')
                affected = cand.get('prediction_affected_count', 0)
                early_hours = cand.get('prediction_early_warning_hours', 0)
                early_str = (f"(äºˆå…†: {early_hours // 24}æ—¥å‰ã€œ)" if early_hours >= 24
                             else (f"(äºˆå…†: {early_hours}æ™‚é–“å‰ã€œ)" if early_hours > 0 else ""))
                if timeline and affected:
                    action = f"âš¡ æ€¥æ€§æœŸ{timeline}ä»¥å†… {early_str} ({affected}å°å½±éŸ¿)"
                else:
                    action = f"âš¡ äºˆé˜²çš„å¯¾å‡¦ã‚’æ¨å¥¨ {early_str}"
            elif alarm_info['is_silent'] or "Silent" in cand_type:
                status_text = "ğŸŸ£ ã‚µã‚¤ãƒ¬ãƒ³ãƒˆç–‘ã„"
                action = "ğŸ” ä¸Šä½ç¢ºèª"
            elif alarm_info['severity'] == 'CRITICAL':
                # â˜… ã“ã“ãŒä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ: probé–¾å€¤ã§ã¯ãªãCRITICAL severity ã§åˆ¤å®š
                status_text = "ğŸ”´ å±é™º (æ ¹æœ¬åŸå› )"
                action = "ğŸš€ è‡ªå‹•ä¿®å¾©ãŒå¯èƒ½"
            elif alarm_info['severity'] == 'WARNING':
                status_text = "ğŸŸ¡ è­¦å‘Š"
                action = "ğŸ” è©³ç´°èª¿æŸ»"
            elif prob > 0.6:
                status_text = "ğŸŸ¡ è¢«ç–‘ç®‡æ‰€"
                action = "ğŸ” è©³ç´°èª¿æŸ»"
            else:
                status_text = "âšª ç›£è¦–ä¸­"
                action = "ğŸ‘ï¸ é™è¦³"

            df_data.append({
                "é †ä½": rank,
                "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": status_text,
                "ãƒ‡ãƒã‚¤ã‚¹": device_id,
                "åŸå› ": cand.get('label', ''),
                "ç¢ºä¿¡åº¦": f"{prob*100:.0f}%",
                "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³": action,
                "_id": device_id,
                "_prob": prob
            })

        df = pd.DataFrame(df_data)

        st.markdown("#### ğŸ¯ æ ¹æœ¬åŸå› å€™è£œ")
        event = st.dataframe(
            df[["é †ä½", "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "ãƒ‡ãƒã‚¤ã‚¹", "åŸå› ", "ç¢ºä¿¡åº¦", "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"]],
            use_container_width=True,
            hide_index=True,
            selection_mode="single-row",
            on_select="rerun"
        )

        if event.selection and len(event.selection.rows) > 0:
            sel_row = df.iloc[event.selection.rows[0]]
            for cand in root_cause_candidates:
                if cand['id'] == sel_row['_id']:
                    selected_incident_candidate = cand
                    target_device_id = cand['id']
                    break
        elif root_cause_candidates:
            selected_incident_candidate = root_cause_candidates[0]
            target_device_id = root_cause_candidates[0]['id']

        # å½±éŸ¿ãƒ‡ãƒã‚¤ã‚¹ï¼ˆä¸‹æµï¼‰ä¸€è¦§
        if downstream_devices:
            with st.expander(f"â–¼ å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹æ©Ÿå™¨ ({len(downstream_devices)}å°) - ä¸Šæµå¾©æ—§å¾…ã¡", expanded=False):
                dd_df = pd.DataFrame([
                    {"No": i+1, "ãƒ‡ãƒã‚¤ã‚¹": d['id'], "çŠ¶æ…‹": "âš« å¿œç­”ãªã—", "å‚™è€ƒ": "ä¸Šæµå¾©æ—§å¾…ã¡"}
                    for i, d in enumerate(downstream_devices)
                ])
                if len(downstream_devices) >= 10:
                    with st.container(height=300):
                        st.dataframe(dd_df, use_container_width=True, hide_index=True)
                else:
                    st.dataframe(dd_df, use_container_width=True, hide_index=True)

    # =====================================================
    # 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    # =====================================================
    col_map, col_chat = st.columns([1.2, 1])

    # === å·¦ã‚«ãƒ©ãƒ : ãƒˆãƒãƒ­ã‚¸ãƒ¼ & Auto-Diagnostics ===
    with col_map:
        st.subheader("ğŸŒ Network Topology")
        graph = render_topology_graph(topology, alarms, analysis_results)
        st.graphviz_chart(graph, use_container_width=True)

        st.markdown("---")
        st.subheader("ğŸ› ï¸ Auto-Diagnostics")

        if st.button("ğŸš€ è¨ºæ–­å®Ÿè¡Œ (Run Diagnostics)", type="primary"):
            if not api_key:
                st.error("API Key Required")
            else:
                with st.status("Agent Operating...", expanded=True) as status_widget:
                    st.write("ğŸ”Œ Connecting to device...")
                    target_node_obj = topology.get(target_device_id) if target_device_id else None
                    res = run_diagnostic_simulation_no_llm(scenario, target_node_obj)
                    st.session_state.live_result = res
                    if res["status"] == "SUCCESS":
                        st.write("âœ… Log Acquired & Sanitized.")
                        status_widget.update(label="Diagnostics Complete!", state="complete", expanded=False)
                        log_content = res.get('sanitized_log', "")
                        st.session_state.verification_result = verify_log_content(log_content)
                        st.session_state.trigger_analysis = True
                    else:
                        st.write("âŒ Connection Failed.")
                        status_widget.update(label="Diagnostics Failed", state="error")
                #st.rerun()  # Disabled to prevent white screen

        if st.session_state.live_result:
            res = st.session_state.live_result
            if res["status"] == "SUCCESS":
                st.markdown("#### ğŸ“„ Diagnostic Results")
                with st.container(border=True):
                    if st.session_state.verification_result:
                        v = st.session_state.verification_result
                        c1, c2, c3 = st.columns(3)
                        c1.metric("Ping Status", v.get('ping_status'))
                        c2.metric("Interface", v.get('interface_status'))
                        c3.metric("Hardware", v.get('hardware_status'))
                    st.divider()
                    st.caption("ğŸ”’ Raw Logs (Sanitized)")
                    st.code(res["sanitized_log"], language="text")

    # =====================================================
    # === å³ã‚«ãƒ©ãƒ : AI Analyst Report & Remediation & Chat ===
    # old_app.py ã®æ§‹é€ ã‚’å®Œå…¨å¾©å…ƒ
    # =====================================================
    with col_chat:

        # ============================================
        # A. AI Analyst Report
        # ============================================
        st.subheader("ğŸ“ AI Analyst Report")

        if selected_incident_candidate:
            cand = selected_incident_candidate

            if st.session_state.generated_report is None:
                st.info(f"ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆé¸æŠä¸­: **{cand['id']}** ({cand.get('label', '')})")

                if api_key and (scenario != "æ­£å¸¸ç¨¼åƒ" or cand.get('is_prediction')):
                    is_pred = cand.get('is_prediction')
                    btn_label = ("ğŸ”® äºˆå…†ã®ç¢ºèªæ‰‹é †ã‚’ç”Ÿæˆ (Predictive Analysis)"
                                 if is_pred else "ğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ (Generate Report)")

                    if st.button(btn_label):
                        report_container = st.empty()
                        target_conf = load_config_by_id(cand['id'])
                        verification_context = cand.get("verification_log", "ç‰¹ã«ãªã—")

                        t_node = topology.get(cand["id"])
                        t_node_dict = {
                            "id":       getattr(t_node, "id",       None) if t_node else None,
                            "type":     getattr(t_node, "type",     None) if t_node else None,
                            "layer":    getattr(t_node, "layer",    None) if t_node else None,
                            "metadata": (getattr(t_node, "metadata", {}) or {}) if t_node else {},
                        }
                        parent_id = t_node.parent_id if t_node and hasattr(t_node, 'parent_id') else None
                        children_ids = [
                            nid for nid, n in topology.items()
                            if (getattr(n, "parent_id", None) if hasattr(n, 'parent_id')
                                else n.get('parent_id')) == cand["id"]
                        ]
                        topology_context = {
                            "node": t_node_dict,
                            "parent_id": parent_id,
                            "children_ids": children_ids
                        }

                        # äºˆå…†ã®å ´åˆ: ãƒãƒƒãƒåŒ–ãƒ»ã‚µãƒ‹ã‚¿ã‚¤ã‚ºæ¸ˆã¿ãƒ˜ãƒ«ãƒ‘ãƒ¼ã§æ§‹ç¯‰ï¼ˆé€Ÿåº¦æ”¹å–„ï¼‰
                        report_scenario = scenario
                        if is_pred:
                            _sig_count      = cand.get('prediction_signal_count', 1)
                            report_scenario = _build_prediction_report_scenario(cand, _sig_count)

                        cache_key_analyst = "|".join([
                            "analyst", site_id, scenario,
                            str(cand.get("id")),
                            _hash_text(json.dumps(topology_context, ensure_ascii=False, sort_keys=True)),
                        ])

                        if cache_key_analyst in st.session_state.report_cache:
                            full_text = st.session_state.report_cache[cache_key_analyst]
                            report_container.markdown(full_text)
                        else:
                            try:
                                report_container.write("ğŸ¤– AI åˆ†æä¸­...")
                                placeholder = report_container.empty()
                                full_text = ""

                                # â˜… æ­£ã—ã„ã‚·ã‚°ãƒãƒãƒ£: topology_context= ã‚’ä½¿ç”¨
                                for chunk in generate_analyst_report_streaming(
                                    scenario=report_scenario,
                                    target_node=t_node,
                                    topology_context=topology_context,
                                    target_conf=target_conf or "ãªã—",
                                    verification_context=verification_context,
                                    api_key=api_key,
                                    max_retries=2,
                                    backoff=3
                                ):
                                    full_text += chunk
                                    placeholder.markdown(full_text)

                                if not full_text or full_text.startswith("Error"):
                                    full_text = f"âš ï¸ åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {full_text}"
                                    placeholder.markdown(full_text)

                                st.session_state.report_cache[cache_key_analyst] = full_text
                            except Exception as e:
                                full_text = f"âš ï¸ åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {type(e).__name__}: {e}"
                                report_container.markdown(full_text)

                        st.session_state.generated_report = full_text
            else:
                # ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºï¼ˆheight=400ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚³ãƒ³ãƒ†ãƒŠï¼‰
                with st.container(height=400, border=True):
                    st.markdown(st.session_state.generated_report)
                if st.button("ğŸ”„ ãƒ¬ãƒãƒ¼ãƒˆå†ä½œæˆ"):
                    st.session_state.generated_report = None
                    #st.rerun()  # Disabled to prevent white screen

        # ============================================
        # B. Remediation & Chat
        #    â˜… Generate Fix / Execute / Cancel ã¯ã™ã¹ã¦ã“ã“ã«é…ç½®
        # ============================================
        st.markdown("---")
        st.subheader("ğŸ¤– Remediation & Chat")

        if selected_incident_candidate and selected_incident_candidate["prob"] > 0.6:
            is_pred_rem = selected_incident_candidate.get('is_prediction')

            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒŠãƒ¼
            if is_pred_rem:
                timeline    = selected_incident_candidate.get('prediction_timeline', 'ä¸æ˜')
                affected    = selected_incident_candidate.get('prediction_affected_count', 0)
                ttf_hours   = selected_incident_candidate.get('prediction_time_to_failure_hours', 0)
                failure_dt  = selected_incident_candidate.get('prediction_failure_datetime', '')
                
                # RULè¡¨ç¤º
                if ttf_hours >= 24:
                    ttf_display = f"ä»Šå¾Œ <b>{ttf_hours // 24}æ—¥å¾Œ</b>"
                    if failure_dt:
                        ttf_display += f" ({failure_dt}é ƒ)"
                elif ttf_hours > 0:
                    ttf_display = f"ä»Šå¾Œ <b>{ttf_hours}æ™‚é–“å¾Œ</b>"
                    if failure_dt:
                        ttf_display += f" ({failure_dt}é ƒ)"
                else:
                    ttf_display = "<b>éšœå®³ãŒåˆ‡è¿«</b>"
                
                st.markdown(f"""
                <div style="background-color:#fff3e0;padding:10px;border-radius:5px;border:1px solid #ff9800;color:#e65100;margin-bottom:10px;">
                    <strong>ğŸ”® Digital Twin æœªæ¥äºˆæ¸¬ (Predictive Maintenance)</strong><br>
                    <b>{selected_incident_candidate['id']}</b> ã§éšœå®³ã®å…†å€™ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚<br>
                    ãƒ»éšœå®³ç™ºç”Ÿäºˆæ¸¬: {ttf_display}<br>
                    ãƒ»æ€¥æ€§æœŸé€²è¡Œ: ç—‡çŠ¶ç™ºç—‡å¾Œ <b>{timeline}</b> ã§ã‚µãƒ¼ãƒ“ã‚¹æ–­ã®æã‚Œ<br>
                    ãƒ»å½±éŸ¿ç¯„å›²: <b>{affected}å°</b> ã®ãƒ‡ãƒã‚¤ã‚¹ã«å½±éŸ¿ã®å¯èƒ½æ€§<br>
                    ãƒ»æ¨å¥¨: ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã®äºˆé˜²äº¤æ›/å¯¾å¿œ<br>
                    (ä¿¡é ¼åº¦: <span style="font-size:1.2em;font-weight:bold;">{selected_incident_candidate['prob']*100:.0f}%</span>)
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div style="background-color:#e8f5e9;padding:10px;border-radius:5px;border:1px solid #4caf50;color:#2e7d32;margin-bottom:10px;">
                    <strong>âœ… AI Analysis Completed</strong><br>
                    ç‰¹å®šã•ã‚ŒãŸåŸå›  <b>{selected_incident_candidate['id']}</b> ã«å¯¾ã™ã‚‹å¾©æ—§æ‰‹é †ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚<br>
                    (ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: <span style="font-size:1.2em;font-weight:bold;">{selected_incident_candidate['prob']*100:.0f}</span>)
                </div>
                """, unsafe_allow_html=True)

            # â˜… Generate Fix ãƒœã‚¿ãƒ³ï¼ˆremediation_plan æœªç”Ÿæˆæ™‚ã®ã¿è¡¨ç¤ºï¼‰
            if st.session_state.remediation_plan is None:
                fix_label    = "ğŸ”® äºˆé˜²æªç½®ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆ (Preventive Measures)" if is_pred_rem else "âœ¨ ä¿®å¾©ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆ (Generate Fix)"
                report_prereq = "ã€ŒğŸ”® äºˆå…†ã®ç¢ºèªæ‰‹é †ã‚’ç”Ÿæˆã€" if is_pred_rem else "ã€ŒğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ (Generate Report)ã€"

                if st.button(fix_label):
                    if st.session_state.generated_report is None:
                        st.warning(f"å…ˆã«{report_prereq}ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                    else:
                        remediation_container = st.empty()
                        t_node = topology.get(selected_incident_candidate["id"])

                        rem_scenario = scenario
                        if is_pred_rem:
                            rem_scenario = _build_prevention_plan_scenario(selected_incident_candidate)

                        cache_key_rem = "|".join([
                            "remediation", site_id, scenario,
                            str(selected_incident_candidate.get("id")),
                            _hash_text(st.session_state.generated_report or ""),
                        ])

                        if cache_key_rem in st.session_state.report_cache:
                            remediation_text = st.session_state.report_cache[cache_key_rem]
                            remediation_container.markdown(remediation_text)
                        else:
                            try:
                                loading_msg = "ğŸ”® äºˆé˜²æªç½®ãƒ—ãƒ©ãƒ³ç”Ÿæˆä¸­..." if is_pred_rem else "ğŸ¤– å¾©æ—§ãƒ—ãƒ©ãƒ³ç”Ÿæˆä¸­..."
                                remediation_container.write(loading_msg)
                                placeholder = remediation_container.empty()
                                remediation_text = ""

                                for chunk in generate_remediation_commands_streaming(
                                    scenario=rem_scenario,
                                    analysis_result=st.session_state.generated_report or "",
                                    target_node=t_node,
                                    api_key=api_key,
                                    max_retries=2,
                                    backoff=3
                                ):
                                    remediation_text += chunk
                                    placeholder.markdown(remediation_text)

                                if not remediation_text or remediation_text.startswith("Error"):
                                    remediation_text = f"âš ï¸ å¾©æ—§ãƒ—ãƒ©ãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {remediation_text}"
                                    placeholder.markdown(remediation_text)

                                st.session_state.report_cache[cache_key_rem] = remediation_text
                            except Exception as e:
                                remediation_text = f"âš ï¸ å¾©æ—§ãƒ—ãƒ©ãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {type(e).__name__}: {e}"
                                remediation_container.markdown(remediation_text)

                        st.session_state.remediation_plan = remediation_text
                        #st.rerun()  # Disabled to prevent white screen

            # â˜… å¾©æ—§æ‰‹é †è¡¨ç¤º + Execute / Cancel ãƒœã‚¿ãƒ³ï¼ˆremediation_plan ç”Ÿæˆæ¸ˆã¿æ™‚ï¼‰
            if st.session_state.remediation_plan is not None:
                with st.container(height=400, border=True):
                    st.info("AI Generated Recovery Procedureï¼ˆå¾©æ—§æ‰‹é †ï¼‰")
                    st.markdown(st.session_state.remediation_plan)

                # Execute / Cancel ãƒœã‚¿ãƒ³ï¼ˆå¾©æ—§æ‰‹é †ã‚³ãƒ³ãƒ†ãƒŠã®ç›´ä¸‹ï¼‰
                col_exec1, col_exec2 = st.columns(2)
                exec_clicked   = col_exec1.button("ğŸš€ ä¿®å¾©å®Ÿè¡Œ (Execute)", type="primary")
                cancel_clicked = col_exec2.button("ã‚­ãƒ£ãƒ³ã‚»ãƒ«")

                if cancel_clicked:
                    st.session_state.remediation_plan  = None
                    st.session_state.verification_log  = None
                    #st.rerun()  # Disabled to prevent white screen

                if exec_clicked:
                    if not api_key:
                        st.error("API Key Required")
                    else:
                        with st.status("ğŸ”§ ä¿®å¾©å‡¦ç†å®Ÿè¡Œä¸­...", expanded=True) as status_widget:
                            target_node_obj = topology.get(selected_incident_candidate["id"])
                            device_info = (target_node_obj.metadata
                                           if target_node_obj and hasattr(target_node_obj, 'metadata')
                                           else {})

                            st.write("ğŸ”„ Executing remediation steps in parallel...")
                            results_rem = run_remediation_parallel_v2(
                                device_id=selected_incident_candidate["id"],
                                device_info=device_info,
                                scenario=scenario,
                                environment=RemediationEnvironment.DEMO,
                                timeout_per_step=30
                            )

                            st.write("ğŸ“‹ Remediation steps result:")
                            all_success = True
                            remediation_summary = []

                            for step_name in ["Backup", "Apply", "Verify"]:
                                result = results_rem.get(step_name)
                                if result:
                                    st.write(str(result))
                                    remediation_summary.append(str(result))
                                    if result.status != "success":
                                        all_success = False

                            verification_log = "\n".join(remediation_summary)
                            st.session_state.verification_log = verification_log

                            if all_success:
                                st.write("âœ… All remediation steps completed successfully.")
                                status_widget.update(label="Process Finished", state="complete", expanded=False)
                                st.session_state.recovered_devices[selected_incident_candidate["id"]] = True
                                st.session_state.recovered_scenario_map[selected_incident_candidate["id"]] = scenario
                                if not st.session_state.balloons_shown:
                                    st.balloons()
                                    st.session_state.balloons_shown = True
                                st.success("âœ… System Recovered Successfully!")
                            else:
                                st.write("âš ï¸ Some remediation steps failed. Please review.")
                                status_widget.update(label="Process Finished - With Errors", state="error", expanded=True)

                if st.session_state.get("verification_log"):
                    st.markdown("#### ğŸ” Post-Fix Verification Logs")
                    st.code(st.session_state.verification_log, language="text")

            # â˜… Phase1: äºˆå…†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å±¥æ­´ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—åŒ–ãƒ»äººé–“å¯èª­åŒ–ï¼‰
            if dt_engine and selected_incident_candidate:
                _oc_device = selected_incident_candidate.get("id", "")
                _open_preds = dt_engine.forecast_list_open(device_id=_oc_device)
                if _open_preds:
                    st.markdown("---")
                    st.markdown("##### ğŸ“œ äºˆå…†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å±¥æ­´")
                    st.caption(
                        f"å¯¾è±¡æ©Ÿå™¨ `{_oc_device}` ã®æœªå¯¾å¿œäºˆå…†: **{len(_open_preds)}ä»¶**  \n"
                        f"ğŸ’¡ é¡ä¼¼äºˆå…†ã¯ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚ä¸€æ‹¬æ“ä½œã‚‚å¯èƒ½ã§ã™ã€‚"
                    )
                    
                    # â˜… ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåæŠ½å‡ºé–¢æ•°
                    import re
                    def _extract_component(message: str) -> str:
                        """ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåã‚’æŠ½å‡º"""
                        if not message:
                            return ""
                        
                        # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹åï¼ˆGi, Te, ge ãªã©ï¼‰
                        interface_patterns = [
                            (r'(Gi\d+/\d+/\d+)', lambda m: m.group(1)),
                            (r'(Te\d+/\d+/\d+)', lambda m: m.group(1)),
                            (r'(ge-\d+/\d+/\d+)', lambda m: m.group(1)),
                            (r'(Ethernet\d+/\d+/\d+)', lambda m: m.group(1)),
                        ]
                        for pattern, formatter in interface_patterns:
                            match = re.search(pattern, message)
                            if match:
                                return formatter(match)
                        
                        # BGP peer (IP address)
                        ip_match = re.search(r'(?:peer|neighbor)\s+(\d+\.\d+\.\d+\.\d+)', message, re.IGNORECASE)
                        if ip_match:
                            return f"Peer {ip_match.group(1)}"
                        
                        # ASç•ªå·
                        as_match = re.search(r'\(AS(\d+)\)', message)
                        if as_match:
                            return f"AS{as_match.group(1)}"
                        
                        return ""
                    
                    # â˜… äºˆå…†ã‚’ãƒ«ãƒ¼ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                    from collections import defaultdict
                    from datetime import datetime
                    
                    grouped_preds = defaultdict(list)
                    for _fp in _open_preds:
                        _rule = _fp.get("rule_pattern", "ä¸æ˜")
                        grouped_preds[_rule].append(_fp)
                    
                    # ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«è¡¨ç¤º
                    for _rule_pattern, _pred_group in grouped_preds.items():
                        _group_size = len(_pred_group)
                        
                        # ã‚°ãƒ«ãƒ¼ãƒ—çµ±è¨ˆæƒ…å ±
                        _confidences = [float(p.get("confidence", 0.0)) for p in _pred_group]
                        _avg_conf = sum(_confidences) / len(_confidences) if _confidences else 0.0

                        # â˜… å…¨ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ¨ªæ–­ã—ã¦å½±éŸ¿ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã‚·ã‚°ãƒŠãƒ«æ•°ã‚’é›†è¨ˆ
                        _all_ifaces: set = set()
                        _total_signals: int = 0
                        for _fp2 in _pred_group:
                            _ifaces = _fp2.get("affected_interfaces", [])
                            _all_ifaces.update(_ifaces)
                            _sc = int(_fp2.get("signal_count", 0))
                            if _sc:
                                _total_signals = max(_total_signals, _sc)
                        # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹åãŒç„¡ã„å ´åˆï¼ˆBGP peerç­‰ï¼‰ã¯ã‚·ã‚°ãƒŠãƒ«æ•°ã§ä»£æ›¿
                        _iface_count  = len(_all_ifaces) if _all_ifaces else _total_signals

                        # æœ€å¤ã¨æœ€æ–°ã®æ¤œå‡ºæ™‚åˆ»ï¼ˆUnix timestamp â†’ äººé–“å¯èª­ï¼‰
                        _timestamps = []
                        for p in _pred_group:
                            _created_raw = p.get("created_at", 0)
                            try:
                                _ts = float(_created_raw)
                                _timestamps.append(_ts)
                            except (ValueError, TypeError):
                                pass
                        
                        if _timestamps:
                            _oldest_ts = min(_timestamps)
                            _newest_ts = max(_timestamps)
                            _oldest_dt = datetime.fromtimestamp(_oldest_ts).strftime("%m/%d %H:%M")
                            _newest_dt = datetime.fromtimestamp(_newest_ts).strftime("%m/%d %H:%M")
                            
                            # ç›¸å¯¾æ™‚é–“è¨ˆç®—ï¼ˆæœ€æ–°ã®æ¤œå‡ºã‹ã‚‰ã®çµŒéæ™‚é–“ï¼‰
                            _elapsed_sec = time.time() - _newest_ts
                            if _elapsed_sec < 3600:
                                _relative = f"{int(_elapsed_sec / 60)}åˆ†å‰"
                            elif _elapsed_sec < 86400:
                                _relative = f"{int(_elapsed_sec / 3600)}æ™‚é–“å‰"
                            else:
                                _relative = f"{int(_elapsed_sec / 86400)}æ—¥å‰"
                        else:
                            _oldest_dt = "ä¸æ˜"
                            _newest_dt = "ä¸æ˜"
                            _relative  = ""

                        # â˜… ãƒ˜ãƒƒãƒ€ãƒ¼æ–‡å­—åˆ—: å½±éŸ¿ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹æ•°ãŒå–ã‚Œã‚‹å ´åˆã¯ãã‚Œã‚’è¡¨ç¤º
                        if _iface_count > 0:
                            _header_suffix = f"å½±éŸ¿ {_iface_count}ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ | ä¿¡é ¼åº¦: {_avg_conf*100:.0f}% | æœ€æ–°: {_relative}"
                        else:
                            _header_suffix = f"ä¿¡é ¼åº¦: {_avg_conf*100:.0f}% | æœ€æ–°: {_relative}"

                        # ã‚°ãƒ«ãƒ¼ãƒ—ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆæŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ï¼‰
                        with st.expander(
                            f"ğŸ”– {_rule_pattern}  ({_header_suffix})",
                            expanded=True
                        ):
                            # â˜… å½±éŸ¿ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ä¸€è¦§ï¼ˆå®Ÿé‹ç”¨ã§æœ‰ç”¨ãªæƒ…å ±ï¼‰
                            if _all_ifaces:
                                _sorted_ifaces = sorted(_all_ifaces)
                                _iface_chips = " ".join(
                                    f"<code style='background:#E3F2FD;padding:2px 6px;"
                                    f"border-radius:3px;font-size:11px;margin:1px;'>{_if}</code>"
                                    for _if in _sorted_ifaces
                                )
                                st.markdown(
                                    f"<div style='background:#F5F5F5;padding:6px 10px;"
                                    f"border-radius:4px;margin-bottom:8px;'>"
                                    f"<small>ğŸ“¡ å½±éŸ¿ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ ({len(_sorted_ifaces)}å€‹): "
                                    f"{_iface_chips}</small><br>"
                                    f"<small>ğŸ“Š æ¤œå‡ºã‚·ã‚°ãƒŠãƒ«æ•°: {_total_signals}ä»¶ | "
                                    f"ğŸ“… æ¤œå‡ºæœŸé–“: {_oldest_dt} ã€œ {_newest_dt}</small>"
                                    f"</div>",
                                    unsafe_allow_html=True
                                )
                            else:
                                st.markdown(
                                    f"<div style='background:#F5F5F5;padding:6px 10px;border-radius:4px;margin-bottom:8px;'>"
                                    f"<small>ğŸ“… æ¤œå‡ºæœŸé–“: {_oldest_dt} ã€œ {_newest_dt}</small>"
                                    f"</div>",
                                    unsafe_allow_html=True
                                )
                            
                            # ä¸€æ‹¬æ“ä½œãƒœã‚¿ãƒ³
                            _bulk_col1, _bulk_col2, _bulk_col3 = st.columns([1, 1, 2])
                            with _bulk_col1:
                                if st.button(
                                    f"âœ… å¯¾å¿œæ¸ˆã¿ã«ã™ã‚‹",
                                    key=f"bulk_handled_{_rule_pattern[:20]}",
                                    help=f"ã“ã®äºˆå…†ã‚’å¯¾å¿œæ¸ˆã¿ã«ã—ã¾ã™",
                                    use_container_width=True
                                ):
                                    _success_count = 0
                                    for _fp in _pred_group:
                                        _fid = _fp.get("forecast_id", "")
                                        r = dt_engine.forecast_register_outcome(
                                            _fid, "mitigated",
                                            note=f"ä¸€æ‹¬å¯¾å¿œæ¸ˆã¿ç™»éŒ²: {_rule_pattern} (device={_oc_device})"
                                        )
                                        if r.get("ok"):
                                            _success_count += 1
                                    st.success(f"âœ… å¯¾å¿œæ¸ˆã¿ã¨ã—ã¦ç™»éŒ²ã—ã¾ã—ãŸ")
                                    #st.rerun()  # Disabled to prevent white screen
                            
                            with _bulk_col2:
                                if st.button(
                                    f"âŒ èª¤æ¤œçŸ¥ã«ã™ã‚‹",
                                    key=f"bulk_false_{_rule_pattern[:20]}",
                                    help=f"ã“ã®äºˆå…†ã‚’èª¤æ¤œçŸ¥ã«ã—ã¾ã™",
                                    use_container_width=True
                                ):
                                    _success_count = 0
                                    for _fp in _pred_group:
                                        _fid = _fp.get("forecast_id", "")
                                        r = dt_engine.forecast_register_outcome(
                                            _fid, "false_alarm",
                                            note=f"ä¸€æ‹¬èª¤æ¤œçŸ¥ç™»éŒ²: {_rule_pattern} (device={_oc_device})"
                                        )
                                        if r.get("ok"):
                                            _success_count += 1
                                    st.info(f"âŒ èª¤æ¤œçŸ¥ã¨ã—ã¦ç™»éŒ²ã—ã¾ã—ãŸ")
                                    #st.rerun()  # Disabled to prevent white screen
                            
                            st.markdown("---")
                            
                            # å€‹åˆ¥ã®äºˆå…†è©³ç´°
                            for idx, _fp in enumerate(_pred_group, 1):
                                _fid        = _fp.get("forecast_id", "")
                                _conf       = float(_fp.get("confidence", 0.0))
                                _created_raw= _fp.get("created_at", 0)
                                _ttf_hours  = _fp.get("time_to_failure_hours", 0)
                                _failure_dt = _fp.get("predicted_failure_datetime", "")
                                _source_msg = _fp.get("message", "")
                                _fp_ifaces  = _fp.get("affected_interfaces", [])
                                _fp_signals = int(_fp.get("signal_count", 0))

                                # â˜… è¡¨ç¤ºIDã®æ±ºå®šï¼šaffected_interfaces > messageãƒ‘ãƒ¼ã‚¹ > fallback
                                if _fp_ifaces:
                                    if len(_fp_ifaces) == 1:
                                        _display_id = _fp_ifaces[0]
                                    else:
                                        _display_id = f"{_fp_ifaces[0]} ä»–{len(_fp_ifaces)-1}å€‹"
                                else:
                                    _component = _extract_component(_source_msg)
                                    _display_id = _component if _component else f"#{idx}"

                                # æ¤œå‡ºæ™‚åˆ»ã‚’äººé–“å¯èª­åŒ–
                                try:
                                    _created_ts = float(_created_raw)
                                    _created_readable = datetime.fromtimestamp(_created_ts).strftime("%Y-%m-%d %H:%M:%S")
                                except (ValueError, TypeError):
                                    _created_readable = str(_created_raw)

                                with st.container():
                                    _signal_label = f" | ã‚·ã‚°ãƒŠãƒ«: {_fp_signals}ä»¶" if _fp_signals else ""
                                    st.markdown(
                                        f"<div style='background:#FAFAFA;border-left:2px solid #CCC;"
                                        f"padding:6px 10px;margin:4px 0;border-radius:3px;'>"
                                        f"<small><b>{_display_id}</b> | æ¤œå‡º: {_created_readable} | ä¿¡é ¼åº¦: {_conf*100:.0f}%{_signal_label}</small>",
                                        unsafe_allow_html=True
                                    )
                                    if _ttf_hours > 0:
                                        if _ttf_hours >= 24:
                                            ttf_display = f"éšœå®³äºˆæ¸¬: {_ttf_hours // 24}æ—¥å¾Œ"
                                            if _failure_dt:
                                                ttf_display += f" ({_failure_dt})"
                                        else:
                                            ttf_display = f"éšœå®³äºˆæ¸¬: {_ttf_hours}æ™‚é–“å¾Œ"
                                        st.markdown(f"<small>â° {ttf_display}</small>", unsafe_allow_html=True)
                                    st.markdown("</div>", unsafe_allow_html=True)
                                    
                                    # å€‹åˆ¥ãƒœã‚¿ãƒ³ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
                                    _ind_col1, _ind_col2, _ind_spacer = st.columns([1, 1, 2])
                                    with _ind_col1:
                                        if st.button(
                                            "âœ…",
                                            key=f"ind_handled_{_fid[:8]}",
                                            help="ã“ã®äºˆå…†ã®ã¿å¯¾å¿œæ¸ˆã¿",
                                            use_container_width=True
                                        ):
                                            r = dt_engine.forecast_register_outcome(
                                                _fid, "mitigated",
                                                note=f"å€‹åˆ¥å¯¾å¿œæ¸ˆã¿: {_rule_pattern} (device={_oc_device})"
                                            )
                                            if r.get("ok"):
                                                st.success(f"âœ… ç™»éŒ²å®Œäº†")
                                                #st.rerun()  # Disabled to prevent white screen
                                    
                                    with _ind_col2:
                                        if st.button(
                                            "âŒ",
                                            key=f"ind_false_{_fid[:8]}",
                                            help="ã“ã®äºˆå…†ã®ã¿èª¤æ¤œçŸ¥",
                                            use_container_width=True
                                        ):
                                            r = dt_engine.forecast_register_outcome(
                                                _fid, "false_alarm",
                                                note=f"å€‹åˆ¥èª¤æ¤œçŸ¥: {_rule_pattern} (device={_oc_device})"
                                            )
                                            if r.get("ok"):
                                                st.info(f"âŒ ç™»éŒ²å®Œäº†")
                                                #st.rerun()  # Disabled to prevent white screen


        else:
            # prob <= 0.6 or no candidate
            if selected_incident_candidate:
                device_id = selected_incident_candidate.get('id', '')
                score = selected_incident_candidate['prob'] * 100
                if device_id == "SYSTEM" and score == 0:
                    st.markdown("""
                    <div style="background-color:#e8f5e9;padding:10px;border-radius:5px;border:1px solid #4caf50;color:#2e7d32;margin-bottom:10px;">
                        <strong>âœ… æ­£å¸¸ç¨¼åƒä¸­</strong><br>
                        ç¾åœ¨ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯æ­£å¸¸ã«ç¨¼åƒã—ã¦ã„ã¾ã™ã€‚å¯¾å¿œãŒå¿…è¦ãªã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                    <div style="background-color:#fff3e0;padding:10px;border-radius:5px;border:1px solid #ff9800;color:#e65100;margin-bottom:10px;">
                        <strong>âš ï¸ ç›£è¦–ä¸­</strong><br>
                        å¯¾è±¡: <b>{device_id}</b><br>
                        (ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: {score:.0f} - 60ä»¥ä¸Šã§è‡ªå‹•ä¿®å¾©ã‚’æ¨å¥¨)
                    </div>
                    """, unsafe_allow_html=True)

        # ============================================
        # C. Chat with AI Agentï¼ˆExpanderå½¢å¼ãƒ»æ—§UIå¾©å…ƒï¼‰
        # ============================================
        with st.expander("ğŸ’¬ Chat with AI Agent", expanded=False):
            _chat_target_id = ""
            if selected_incident_candidate:
                _chat_target_id = selected_incident_candidate.get("id", "") or ""
            if not _chat_target_id and target_device_id:
                _chat_target_id = target_device_id

            _chat_ci = _build_ci_context_for_chat(topology, _chat_target_id) if _chat_target_id else {}
            if _chat_ci:
                _vendor     = _chat_ci.get("vendor", "") or "Unknown"
                _os         = _chat_ci.get("os",     "") or "Unknown"
                _model_name = _chat_ci.get("model",  "") or "Unknown"
                st.caption(f"å¯¾è±¡æ©Ÿå™¨: {_chat_target_id}   Vendor: {_vendor}   OS: {_os}   Model: {_model_name}")

            # ã‚¯ã‚¤ãƒƒã‚¯è³ªå•ãƒœã‚¿ãƒ³
            q1, q2, q3 = st.columns(3)
            with q1:
                if st.button("è¨­å®šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—", use_container_width=True):
                    st.session_state.chat_quick_text = "ã“ã®æ©Ÿå™¨ã§ã€ç¾åœ¨ã®è¨­å®šã‚’å®‰å…¨ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã™ã‚‹æ‰‹é †ã¨ã‚³ãƒãƒ³ãƒ‰ä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
            with q2:
                if st.button("ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯", use_container_width=True):
                    st.session_state.chat_quick_text = "ã“ã®æ©Ÿå™¨ã§ã€å¤‰æ›´ã‚’ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹ä»£è¡¨çš„ãªæ‰‹é †ï¼ˆå€™è£œï¼‰ã¨æ³¨æ„ç‚¹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
            with q3:
                if st.button("ç¢ºèªã‚³ãƒãƒ³ãƒ‰", use_container_width=True):
                    st.session_state.chat_quick_text = "ä»Šå›ã®ç—‡çŠ¶ã‚’åˆ‡ã‚Šåˆ†ã‘ã‚‹ãŸã‚ã«ã€ã¾ãšå®Ÿè¡Œã™ã¹ãç¢ºèªã‚³ãƒãƒ³ãƒ‰ï¼ˆshow/diagnosticï¼‰ã‚’å„ªå…ˆåº¦é †ã«æ•™ãˆã¦ãã ã•ã„ã€‚"

            if st.session_state.chat_quick_text:
                st.info("ã‚¯ã‚¤ãƒƒã‚¯è³ªå•ï¼ˆã‚³ãƒ”ãƒ¼ã—ã¦è²¼ã‚Šä»˜ã‘ï¼‰")
                st.code(st.session_state.chat_quick_text)

            if st.session_state.chat_session is None and api_key and GENAI_AVAILABLE:
                try:
                    # æ–°SDK: Client.chats.create()
                    _client = genai.Client(api_key=api_key)
                    st.session_state.chat_session = _client.chats.create(model="gemma-3-12b-it")
                except AttributeError:
                    # æ—§SDKäº’æ›ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    genai.configure(api_key=api_key)
                    model_obj = genai.GenerativeModel("gemma-3-12b-it")
                    st.session_state.chat_session = model_obj.start_chat(history=[])

            tab1, tab2 = st.tabs(["ğŸ’¬ ä¼šè©±", "ğŸ“ å±¥æ­´"])

            with tab1:
                if st.session_state.messages:
                    last_msg = st.session_state.messages[-1]
                    if last_msg["role"] == "assistant":
                        st.info("ğŸ¤– æœ€æ–°ã®å›ç­”")
                        with st.container(height=300):
                            st.markdown(last_msg["content"])

                st.markdown("---")
                prompt = st.text_area(
                    "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
                    height=70,
                    placeholder="Ctrl+Enter ã¾ãŸã¯ é€ä¿¡ãƒœã‚¿ãƒ³ã§é€ä¿¡",
                    key="chat_textarea"
                )

                col1, col2, col3 = st.columns([3, 1, 1])
                with col2:
                    send_button = st.button("é€ä¿¡", type="primary", use_container_width=True)
                with col3:
                    if st.button("ã‚¯ãƒªã‚¢"):
                        st.session_state.messages = []
                        #st.rerun()  # Disabled to prevent white screen

                if send_button and prompt:
                    st.session_state.messages.append({"role": "user", "content": prompt})
                    if st.session_state.chat_session:
                        ci = _build_ci_context_for_chat(topology, _chat_target_id) if _chat_target_id else {}
                        ci_prompt = f"""ã‚ãªãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é‹ç”¨ï¼ˆNOC/SREï¼‰ã®å®Ÿå‹™è€…ã§ã™ã€‚
æ¬¡ã® CI æƒ…å ±ã¨ Config æŠœç²‹ã‚’å¿…ãšå‚ç…§ã—ã¦ã€å…·ä½“çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚ä¸€èˆ¬è«–ã ã‘ã§çµ‚ã‚ã‚‰ã›ãªã„ã§ãã ã•ã„ã€‚

ã€CI (JSON)ã€‘
{json.dumps(ci, ensure_ascii=False, indent=2)}

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
{prompt}

å›ç­”ãƒ«ãƒ¼ãƒ«:
- CI/Config ã«åŸºã¥ãå…·ä½“æ‰‹é †ãƒ»ã‚³ãƒãƒ³ãƒ‰ä¾‹ã‚’æç¤ºã™ã‚‹
- è¿½åŠ ç¢ºèªãŒå¿…è¦ãªã‚‰ã€è³ªå•ã¯æœ€å°é™ï¼ˆ1ã€œ2ç‚¹ï¼‰ã«çµã‚‹
- ä¸æ˜ãªå‰æã¯æ¨æ¸¬ã›ãšã€ŒCIã«ç„¡ã„ã®ã§ç¢ºèªãŒå¿…è¦ã€ã¨æ˜è¨˜ã™ã‚‹
"""
                        with st.spinner("AI ãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                            try:
                                response = generate_content_with_retry(
                                    st.session_state.chat_session.model, ci_prompt, stream=False
                                )
                                if response:
                                    full_response = response.text if hasattr(response, "text") else str(response)
                                    if not full_response.strip():
                                        full_response = "AIå¿œç­”ãŒç©ºã§ã—ãŸã€‚"
                                    st.session_state.messages.append({"role": "assistant", "content": full_response})
                                else:
                                    st.error("AIã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                            except Exception as e:
                                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    #st.rerun()  # Disabled to prevent white screen

            with tab2:
                if st.session_state.messages:
                    history_container = st.container(height=400)
                    with history_container:
                        for i, msg in enumerate(st.session_state.messages):
                            icon = "ğŸ¤–" if msg["role"] == "assistant" else "ğŸ‘¤"
                            with st.container(border=True):
                                st.markdown(f"{icon} **{msg['role'].upper()}** (ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ {i+1})")
                                st.markdown(msg["content"])
                else:
                    st.info("ä¼šè©±å±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
