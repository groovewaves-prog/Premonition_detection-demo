import streamlit as st
import pandas as pd
import json
import time
import re
import hashlib
from typing import Optional, List, Dict, Any

try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False

from registry import get_paths, load_topology, get_display_name
from alarm_generator import generate_alarms_for_scenario, Alarm, get_alarm_summary
from inference_engine import LogicalRCA
from network_ops import (
    generate_analyst_report_streaming, 
    generate_remediation_commands_streaming, 
    run_remediation_parallel_v2, 
    RemediationEnvironment
)
from utils.helpers import get_status_from_alarms, get_status_icon, load_config_by_id
from utils.llm_helper import get_rate_limiter, generate_content_with_retry
from verifier import verify_log_content
from .graph import render_topology_graph

# =====================================================
# å¾©å…ƒã•ã‚ŒãŸãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# =====================================================
def _hash_text(text: str) -> str:
    return hashlib.sha256((text or "").encode("utf-8")).hexdigest()[:16]

def _pick_first(mapping: dict, keys: list, default: str = "") -> str:
    for k in keys:
        try:
            v = mapping.get(k, None)
        except Exception: v = None
        if v is None: continue
        if isinstance(v, (int, float, bool)):
            s = str(v)
            if s: return s
        elif isinstance(v, str):
            if v.strip(): return v.strip()
    return default

def _build_ci_context_for_chat(topology: dict, target_node_id: str) -> dict:
    node = topology.get(target_node_id)
    if node:
        md = node.metadata if hasattr(node, 'metadata') else node.get('metadata', {})
    else: md = {}
    ci = {
        "device_id": target_node_id or "",
        "hostname": _pick_first(md, ["hostname", "host", "name"], default=(target_node_id or "")),
        "vendor": _pick_first(md, ["vendor", "manufacturer"], default=""),
        "model": _pick_first(md, ["model", "hw_model"], default=""),
        "role": _pick_first(md, ["role", "type"], default=""),
        "site": _pick_first(md, ["site", "location"], default=""),
    }
    try:
        conf = load_config_by_id(target_node_id) if target_node_id else ""
        if conf: ci["config_excerpt"] = conf[:1500]
    except Exception: pass
    return ci

def run_diagnostic_simulation_no_llm(selected_scenario: str, target_node_obj) -> dict:
    device_id = getattr(target_node_obj, "id", "UNKNOWN") if target_node_obj else "UNKNOWN"
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    lines = [f"[PROBE] ts={ts}", f"[PROBE] scenario={selected_scenario}", f"[PROBE] target_device={device_id}", ""]
    recovered_devices = st.session_state.get("recovered_devices") or {}
    if recovered_devices.get(device_id):
        lines += ["show chassis cluster status", "Redundancy group 0: healthy", "control link: up"]
    else:
        if "WAN" in selected_scenario: lines += ["show ip interface brief", "GigabitEthernet0/0 down down", "Neighbor 203.0.113.2 Idle"]
        elif "FW" in selected_scenario: lines += ["show chassis cluster status", "Redundancy group 0: degraded", "control link: down"]
        else: lines += ["show system alarms", "No active alarms"]
    return {"status": "SUCCESS", "sanitized_log": "\n".join(lines), "device_id": device_id}

# =====================================================
# ãƒ¡ã‚¤ãƒ³æç”»é–¢æ•°
# =====================================================
def render_incident_cockpit(site_id: str, api_key: Optional[str]):
    display_name = get_display_name(site_id)
    scenario = st.session_state.site_scenarios.get(site_id, "æ­£å¸¸ç¨¼åƒ")
    
    # ä»¥å‰ã®ãƒ˜ãƒƒãƒ€ãƒ¼ãŠã‚ˆã³æˆ»ã‚‹ãƒœã‚¿ãƒ³ã®å¾©å…ƒ
    col_header = st.columns([4, 1])
    with col_header[0]:
        st.markdown(f"### ğŸ›¡ï¸ AIOps ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆ")
    with col_header[1]:
        st.markdown('<span id="back-btn-marker"></span>', unsafe_allow_html=True)
        st.markdown("""
        <style>
        #back-btn-marker + div button,
        #back-btn-marker ~ div[data-testid="stButton"] button {
            background-color: #d32f2f !important;
            color: white !important;
            border: 2px solid #b71c1c !important;
            font-weight: bold !important;
            border-radius: 8px !important;
        }
        </style>
        """, unsafe_allow_html=True)
        if st.button("ğŸ”™ ä¸€è¦§ã«æˆ»ã‚‹", key="back_to_list"):
            st.session_state.active_site = None
            st.rerun()

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    paths = get_paths(site_id)
    topology = load_topology(paths.topology_path)
    if not topology:
        st.error("ãƒˆãƒãƒ­ã‚¸ãƒ¼èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼")
        return

    alarms = generate_alarms_for_scenario(topology, scenario)
    status = get_status_from_alarms(scenario, alarms)
    
    # äºˆå…†æ³¨å…¥
    injected = st.session_state.get("injected_weak_signal")
    if injected and injected["device_id"] in topology:
        for m in injected.get("messages", []):
            alarms.append(Alarm(injected["device_id"], m, "INFO", False))

    # åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ã®å®Ÿè¡Œ
    engine_key = f"engine_{site_id}"
    if engine_key not in st.session_state.logic_engines:
        st.session_state.logic_engines[engine_key] = LogicalRCA(topology)
    engine = st.session_state.logic_engines[engine_key]
    
    results = engine.analyze(alarms) if alarms else []
    if not results: results = [{"id": "SYSTEM", "label": "æ­£å¸¸ç¨¼åƒ", "prob": 0.0, "type": "Normal"}]

    # KPIãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¡¨ç¤º
    preds = [r for r in results if r.get('is_prediction')]
    st.markdown("---")
    k1, k2, k3 = st.columns(3)
    k1.metric("ğŸš¨ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", f"{get_status_icon(status)} {status}")
    k2.metric("ğŸ“Š ã‚¢ãƒ©ãƒ¼ãƒ æ•°", f"{len(alarms)}ä»¶")
    k3.metric("ğŸ¯ è¢«ç–‘ç®‡æ‰€", f"{len([r for r in results if r.get('prob', 0) > 0.5])}ä»¶", 
              delta=f"ã†ã¡ğŸ”®äºˆå…† {len(preds)}ä»¶" if preds else None, delta_color="off")
    
    st.markdown("---")

    # =====================================================
    # ğŸ”® å¼·åŒ–ç‰ˆ: äºˆå…†æƒ…å ±ç‰¹åŒ–UX (Future Radar)
    # =====================================================
    if preds:
        st.markdown("### ğŸ”® AIOps Future Radar")
        st.caption("AIãŒå°†æ¥ã®éšœå®³ã‚’äºˆæ¸¬ã—ã¾ã—ãŸã€‚é‹ç”¨ã‚’ã€Œå¾Œè¿½ã„ã€ã‹ã‚‰ã€Œå…ˆå›ã‚Šã€ã¸ã€‚")
        for p in preds:
            with st.container():
                st.markdown(f"""
                <div style="border: 2px solid #E1BEE7; border-left: 10px solid #9C27B0; background-color: #F3E5F5; padding: 20px; border-radius: 10px; margin-bottom: 20px;">
                    <div style="display:flex; justify-content:space-between; align-items:center;">
                        <h4 style="margin:0; color:#4A148C;">ğŸ“ {p['id']} : {p.get('label', '').replace('ğŸ”® [äºˆå…†] ', '')}</h4>
                        <span style="background-color:#9C27B0; color:white; padding:5px 15px; border-radius:20px; font-weight:bold;">ç™ºç”Ÿç¢ºç‡ {p.get('prob', 0)*100:.0f}%</span>
                    </div>
                    <div style="margin-top:15px; display:grid; grid-template-columns: 1fr 1fr 1fr; gap:20px;">
                        <div style="background:white; padding:10px; border-radius:5px; text-align:center;">
                            <span style="font-size:0.8em; color:#666;">æ—©æœŸæ¤œçŸ¥</span><br>
                            <b>{p.get('prediction_early_warning_hours', 0)}æ™‚é–“å‰</b> ã«æ•æ‰
                        </div>
                        <div style="background:white; padding:10px; border-radius:5px; text-align:center;">
                            <span style="font-size:0.8em; color:#666;">æ€¥æ€§æœŸ(Critical)ã¾ã§</span><br>
                            <b>ã‚ã¨ç´„ {p.get('prediction_time_to_critical_min', 0)} åˆ†</b>
                        </div>
                        <div style="background:white; padding:10px; border-radius:5px; text-align:center;">
                            <span style="font-size:0.8em; color:#666;">å½±éŸ¿ã®åºƒãŒã‚Š</span><br>
                            é…ä¸‹ <b>{p.get('prediction_affected_count', 0)} å°</b> ã®ãƒªã‚¹ã‚¯
                        </div>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                rec_actions = p.get("recommended_actions", [])
                if rec_actions:
                    st.markdown("##### âš¡ ã ã‹ã‚‰ã©ã†ã™ã‚‹ï¼Ÿ : æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ (Primary Actions)")
                    cols_act = st.columns(len(rec_actions))
                    for idx, act in enumerate(rec_actions):
                        with cols_act[idx]:
                            with st.container(border=True):
                                st.markdown(f"**{act['title']}**")
                                st.caption(f"{act['effect']}")
        st.markdown("---")

    # =====================================================
    # å¾©å…ƒã•ã‚ŒãŸã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆç®¡ç† (ãƒ†ãƒ¼ãƒ–ãƒ« & å½±éŸ¿ç¯„å›²)
    # =====================================================
    root_cause_ids = {a.device_id for a in alarms if a.is_root_cause}
    downstream_ids = {a.device_id for a in alarms if not a.is_root_cause}
    rc_list = [r for r in results if r.get('is_prediction') or r['id'] in root_cause_ids or r.get('prob', 0) > 0.5]
    ds_list = [r for r in results if r['id'] in downstream_ids]

    # é’ã„ã‚¤ãƒ³ãƒ•ã‚©ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã®å¾©å…ƒ
    if rc_list and ds_list:
        st.info(f"ğŸ“ **æ ¹æœ¬åŸå› **: {rc_list[0]['id']} â†’ å½±éŸ¿ç¯„å›²: é…ä¸‹ {len(ds_list)} æ©Ÿå™¨")

    st.markdown("#### ğŸ¯ æ ¹æœ¬åŸå› å€™è£œ")
    df_data = []
    for i, c in enumerate(rc_list, 1):
        p = c.get('prob', 0)
        status_txt = "ğŸ”® äºˆå…†" if c.get('is_prediction') else "ğŸ”´ å±é™º" if p > 0.9 else "ğŸŸ¡ è­¦å‘Š"
        df_data.append({"é †ä½": i, "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": status_txt, "ãƒ‡ãƒã‚¤ã‚¹": c['id'], "åŸå› ": c.get('label'), "ç¢ºä¿¡åº¦": f"{p*100:.0f}%", "_obj": c})
    
    df = pd.DataFrame(df_data)
    sel = st.dataframe(df.drop(columns=["_obj"]), use_container_width=True, hide_index=True, selection_mode="single-row", on_select="rerun")
    
    if sel.selection.rows:
        st.session_state.selected_candidate = df.iloc[sel.selection.rows[0]]["_obj"]
    elif rc_list and not st.session_state.get("selected_candidate"):
        st.session_state.selected_candidate = rc_list[0]

    # å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹æ©Ÿå™¨ãƒªã‚¹ãƒˆã®å¾©å…ƒ
    if ds_list:
        with st.expander(f"â–¼ å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹æ©Ÿå™¨ ({len(ds_list)}å°) - ä¸Šæµå¾©æ—§å¾…ã¡", expanded=False):
            st.dataframe(pd.DataFrame([{"No": i+1, "ãƒ‡ãƒã‚¤ã‚¹": d['id'], "çŠ¶æ…‹": "âš« å¿œç­”ãªã—", "å‚™è€ƒ": "ä¸Šæµå¾©æ—§å¾…ã¡"} for i, d in enumerate(ds_list)]), 
                         use_container_width=True, hide_index=True)

    # ä»¥å‰ã®2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®å¾©å…ƒ
    col_l, col_r = st.columns([1.2, 1])
    
    with col_l:
        st.subheader("ğŸŒ Network Topology")
        st.graphviz_chart(render_topology_graph(topology, alarms, results), use_container_width=True)
        st.markdown("---")
        st.subheader("ğŸ› ï¸ Auto-Diagnostics")
        if st.button("ğŸš€ è¨ºæ–­å®Ÿè¡Œ (Run Diagnostics)", type="primary"):
            with st.status("Agent Operating...", expanded=True) as status_widget:
                res = run_diagnostic_simulation_no_llm(scenario, st.session_state.selected_candidate)
                st.session_state.live_result = res
                st.session_state.verification_result = verify_log_content(res.get('sanitized_log', ""))
                status_widget.update(label="Diagnostics Complete!", state="complete", expanded=False)
            st.rerun()
        if st.session_state.get("live_result"):
            res = st.session_state.live_result
            with st.container(border=True):
                if st.session_state.get("verification_result"):
                    v = st.session_state.verification_result
                    c1, c2, c3 = st.columns(3)
                    c1.metric("Ping", v.get('ping_status'))
                    c2.metric("Intf", v.get('interface_status'))
                    c3.metric("HW", v.get('hardware_status'))
                st.divider()
                st.code(res.get("sanitized_log"), language="text")

    with col_r:
        # ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ï¼ˆåŒåƒšæ¡ˆï¼šä¸€ç”»é¢ã§å®Œçµï¼‰
        st.subheader("ğŸ“ Incident Workspace")
        cand = st.session_state.get("selected_candidate")
        if cand:
            bg_color = "#F3E5F5" if cand.get('is_prediction') else "#FFEBEE"
            st.markdown(f"""
            <div style="background-color:{bg_color}; padding:15px; border-radius:5px; border-left:5px solid #666;">
                <b>Target Device: {cand['id']}</b><br>{cand.get('label')}
            </div>
            """, unsafe_allow_html=True)
            
            tab_act, tab_chat, tab_rpt = st.tabs(["âš¡ Action", "ğŸ’¬ AI Chat", "ğŸ“ Report"])
            with tab_act:
                st.checkbox("æ‰‹é †æ›¸ã®ç¢ºèªå®Œäº†", key=f"check_step1_{cand['id']}")
                if st.button("ğŸš€ è‡ªå‹•ä¿®å¾© / äºˆé˜²æªç½®ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
                    st.balloons()
                    st.success("å®Ÿè¡ŒãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                c_res, c_fp = st.columns(2)
                c_res.button("âœ… è§£æ±ºæ¸ˆã¨ã—ã¦ç™»éŒ²", use_container_width=True)
                c_fp.button("âŒ èª¤æ¤œçŸ¥ã‚’å ±å‘Š", use_container_width=True)
            
            with tab_chat:
                if not st.session_state.get("chat_session") and api_key:
                    genai.configure(api_key=api_key)
                    st.session_state.chat_session = genai.GenerativeModel("gemma-3-12b-it").start_chat(history=[])
                chat_cont = st.container(height=300)
                with chat_cont:
                    for msg in st.session_state.get("messages", []):
                        st.markdown(f"**{'ğŸ¤–' if msg['role']=='assistant' else 'ğŸ‘¤'}**: {msg['content']}")
                prompt = st.chat_input("AIã«è³ªå•...")
                if prompt:
                    st.session_state.setdefault("messages", []).append({"role": "user", "content": prompt})
                    ci = _build_ci_context_for_chat(topology, cand['id'])
                    resp = generate_content_with_retry(st.session_state.chat_session.model, f"Context: {json.dumps(ci)}\nQuestion: {prompt}", stream=False)
                    st.session_state.messages.append({"role": "assistant", "content": resp.text})
                    st.rerun()

            with tab_rpt:
                if st.button("ğŸ“ å ±å‘Šæ›¸ãƒ‰ãƒ©ãƒ•ãƒˆã‚’ä½œæˆ", use_container_width=True):
                    st.markdown("**ã€å ±å‘Šæ›¸æ¡ˆã€‘**\n- ç™ºç”Ÿäº‹è±¡: ...\n- å¯¾å¿œå†…å®¹: ...")
