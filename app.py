# -*- coding: utf-8 -*-
"""
Google Antigravity AIOps Agent - Streamlit Main Application
å®Œå…¨ç‰ˆ: ã‚¢ãƒ©ãƒ¼ãƒ é¸åˆ¥ã€çœŸå› ç‰¹å®šã€ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰éšœå®³åˆ†æ
"""

import streamlit as st
import os
import json
import time
from typing import List, Dict, Any
import google.generativeai as genai

# æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from data import TOPOLOGY, NetworkNode
from logic import CausalInferenceEngine, Alarm, simulate_cascade_failure
from inference_engine import LogicalRCA
from verifier import verify_log_content, format_verification_report
from network_ops import (
    generate_fake_log_by_ai,
    run_diagnostic_simulation,
    generate_remediation_commands,
    generate_health_check_commands
)

# =====================================================
# ãƒšãƒ¼ã‚¸è¨­å®š
# =====================================================
st.set_page_config(
    page_title="AIOps - éšœå®³åˆ†æã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =====================================================
# å®šæ•°å®šç¾©
# =====================================================
SCENARIO_CATEGORIES = {
    "æ­£å¸¸ç¨¼åƒ": {
        "æ­£å¸¸ç¨¼åƒ": "æ­£å¸¸ç¨¼åƒ"
    },
    "WANæ©Ÿå™¨": {
        "[WAN] é›»æºéšœå®³ï¼šç‰‡ç³»": "[WAN] é›»æºéšœå®³ï¼šç‰‡ç³»",
        "[WAN] é›»æºéšœå®³ï¼šä¸¡ç³»": "[WAN] é›»æºéšœå®³ï¼šä¸¡ç³»",
        "[WAN] BGPãƒ•ãƒ©ãƒƒãƒ”ãƒ³ã‚°": "[WAN] BGPãƒ•ãƒ©ãƒƒãƒ”ãƒ³ã‚°",
        "[WAN] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯": "[WAN] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"
    },
    "ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«": {
        "[FW] é›»æºéšœå®³ï¼šç‰‡ç³»": "[FW] é›»æºéšœå®³ï¼šç‰‡ç³»",
        "[FW] é›»æºéšœå®³ï¼šä¸¡ç³»": "[FW] é›»æºéšœå®³ï¼šä¸¡ç³»",
        "[FW] FANæ•…éšœ": "[FW] FANæ•…éšœ",
        "[FW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯": "[FW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"
    },
    "ã‚¹ã‚¤ãƒƒãƒ": {
        "[L2SW] é›»æºéšœå®³ï¼šç‰‡ç³»": "[L2SW] é›»æºéšœå®³ï¼šç‰‡ç³»",
        "[L2SW] é›»æºéšœå®³ï¼šä¸¡ç³»": "[L2SW] é›»æºéšœå®³ï¼šä¸¡ç³»",
        "[L2SW] FANæ•…éšœ": "[L2SW] FANæ•…éšœ",
        "[L2SW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯": "[L2SW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯",
        "[L2SW] ã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³": "[L2SW] ã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³"
    },
    "ã‚¢ã‚¯ã‚»ã‚¹ãƒã‚¤ãƒ³ãƒˆ": {
        "[AP] AP_01ãƒ€ã‚¦ãƒ³": "[AP] AP_01ãƒ€ã‚¦ãƒ³",
        "[AP] AP_01ã‚±ãƒ¼ãƒ–ãƒ«éšœå®³": "[AP] AP_01ã‚±ãƒ¼ãƒ–ãƒ«éšœå®³"
    },
    "è¤‡åˆéšœå®³": {
        "[è¤‡åˆ] FW_01_PRIMARYã¨AP_03ã®å¤šé‡éšœå®³": "[è¤‡åˆ] FW_01_PRIMARYã¨AP_03ã®å¤šé‡éšœå®³",
        "[è¤‡åˆ] WANé›»æºç‰‡ç³»+FANå¤šé‡éšœå®³": "[è¤‡åˆ] WANé›»æºç‰‡ç³»+FANå¤šé‡éšœå®³"
    }
}

# =====================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
# =====================================================
if 'analysis_done' not in st.session_state:
    st.session_state.analysis_done = False
if 'current_scenario' not in st.session_state:
    st.session_state.current_scenario = None
if 'root_cause_result' not in st.session_state:
    st.session_state.root_cause_result = None
if 'generated_log' not in st.session_state:
    st.session_state.generated_log = ""
if 'remediation_executed' not in st.session_state:
    st.session_state.remediation_executed = False
if 'health_check_done' not in st.session_state:
    st.session_state.health_check_done = False

# =====================================================
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# =====================================================

def get_target_node_from_scenario(scenario: str) -> str:
    """ã‚·ãƒŠãƒªã‚ªã‹ã‚‰å¯¾è±¡ãƒãƒ¼ãƒ‰IDã‚’æ¨å®š"""
    if "[WAN]" in scenario:
        return "WAN_ROUTER_01"
    elif "[FW]" in scenario:
        return "FW_01_PRIMARY"
    elif "[L2SW]" in scenario:
        return "L2_SW_01"
    elif "[AP]" in scenario:
        return "AP_01"
    elif "FW_01_PRIMARYã¨AP_03" in scenario:
        return "FW_01_PRIMARY"
    elif "WANé›»æº" in scenario:
        return "WAN_ROUTER_01"
    return "WAN_ROUTER_01"

def generate_massive_alarms(scenario: str, root_device_id: str) -> List[Alarm]:
    """
    å¤§é‡ã®å†—é•·ã‚¢ãƒ©ãƒ¼ãƒ ã‚’ç”Ÿæˆï¼ˆ50-200ä»¶ï¼‰
    å®Ÿéš›ã®é‹ç”¨ã§ã¯ã€é…ä¸‹ã®å…¨æ©Ÿå™¨ã‹ã‚‰æ§˜ã€…ãªã‚¢ãƒ©ãƒ¼ãƒ ãŒä¸ŠãŒã£ã¦ãã‚‹
    """
    import random
    
    alarms = []
    root_node = TOPOLOGY.get(root_device_id)
    
    if not root_node:
        return alarms
    
    # æ ¹æœ¬åŸå› ã®ã‚¢ãƒ©ãƒ¼ãƒ 
    if "é›»æº" in scenario:
        if "ä¸¡ç³»" in scenario:
            alarms.append(Alarm(root_device_id, "Power Supply 1 Failed", "CRITICAL"))
            alarms.append(Alarm(root_device_id, "Power Supply 2 Failed", "CRITICAL"))
            alarms.append(Alarm(root_device_id, "Device Unreachable", "CRITICAL"))
        else:
            alarms.append(Alarm(root_device_id, "Power Supply 1 Failed", "WARNING"))
            alarms.append(Alarm(root_device_id, "Redundancy Lost", "WARNING"))
    elif "BGP" in scenario:
        alarms.append(Alarm(root_device_id, "BGP Peer Flapping", "CRITICAL"))
        alarms.append(Alarm(root_device_id, "Route Instability Detected", "WARNING"))
    elif "FAN" in scenario:
        alarms.append(Alarm(root_device_id, "Fan Module Failed", "CRITICAL"))
        alarms.append(Alarm(root_device_id, "Temperature Warning", "WARNING"))
    elif "ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯" in scenario:
        alarms.append(Alarm(root_device_id, "Memory Usage 95%", "CRITICAL"))
        alarms.append(Alarm(root_device_id, "System Performance Degraded", "WARNING"))
    elif "ã‚±ãƒ¼ãƒ–ãƒ«" in scenario:
        alarms.append(Alarm(root_device_id, "Interface GigabitEthernet0/1 Down", "CRITICAL"))
        alarms.append(Alarm(root_device_id, "Link Status Changed", "WARNING"))
    elif "ãƒ€ã‚¦ãƒ³" in scenario:
        alarms.append(Alarm(root_device_id, "Device Down", "CRITICAL"))
        alarms.append(Alarm(root_device_id, "SNMP Timeout", "CRITICAL"))
    
    # ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰éšœå®³ã®ã‚¢ãƒ©ãƒ¼ãƒ ç”Ÿæˆ
    cascade_alarms = simulate_cascade_failure(root_device_id, TOPOLOGY, "Connection Lost")
    alarms.extend(cascade_alarms[1:])  # é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚æ ¹æœ¬åŸå› ä»¥å¤–ã‚’è¿½åŠ 
    
    # ãƒã‚¤ã‚ºã‚¢ãƒ©ãƒ¼ãƒ ã‚’å¤§é‡è¿½åŠ ï¼ˆ50-200ä»¶ã«ï¼‰
    noise_messages = [
        "SNMP Trap Received",
        "Interface Utilization 50%",
        "Minor Configuration Change",
        "Backup Job Started",
        "User Login Detected",
        "Temperature Normal",
        "Fan Speed Adjusted",
        "ARP Cache Updated",
        "Routing Table Updated",
        "VLAN Database Modified",
        "ACL Hit Count Threshold",
        "Port Security Violation (Info)",
        "NTP Sync OK",
        "DNS Query Timeout (Retry OK)",
        "DHCP Lease Expired (Auto Renewed)",
    ]
    
    target_count = random.randint(50, 200)
    while len(alarms) < target_count:
        random_device = random.choice(list(TOPOLOGY.keys()))
        random_message = random.choice(noise_messages)
        random_severity = random.choice(["INFO", "WARNING", "INFO", "INFO"])  # INFOå¤šã‚
        alarms.append(Alarm(random_device, random_message, random_severity))
    
    return alarms

def filter_critical_alarms(all_alarms: List[Alarm], api_key: str) -> List[Alarm]:
    """
    AIã‚’ä½¿ã£ã¦æœ¬å½“ã«é‡è¦ãªã‚¢ãƒ©ãƒ¼ãƒ ã ã‘ã‚’3-5ä»¶ã«çµã‚‹
    """
    if not api_key:
        # APIã‚­ãƒ¼ãŒãªã„å ´åˆã¯CRITICALã®ã¿è¿”ã™
        return [a for a in all_alarms if a.severity == "CRITICAL"][:5]
    
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-1.5-flash')
    
    # ã‚¢ãƒ©ãƒ¼ãƒ æƒ…å ±ã‚’æ•´å½¢
    alarm_list = "\n".join([
        f"{i+1}. Device: {a.device_id}, Message: {a.message}, Severity: {a.severity}"
        for i, a in enumerate(all_alarms[:100])  # æœ€åˆã®100ä»¶ã®ã¿é€ä¿¡
    ])
    
    prompt = f"""
ã‚ãªãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¢ãƒ©ãƒ¼ãƒ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°AIã§ã™ã€‚
ä»¥ä¸‹ã®å¤§é‡ã®ã‚¢ãƒ©ãƒ¼ãƒ ã‹ã‚‰ã€**æ ¹æœ¬åŸå› ã«é–¢é€£ã™ã‚‹é‡è¦ãªã‚¢ãƒ©ãƒ¼ãƒ ã ã‘ã‚’3ã€œ5ä»¶é¸æŠ**ã—ã¦ãã ã•ã„ã€‚

ã€ã‚¢ãƒ©ãƒ¼ãƒ ãƒªã‚¹ãƒˆã€‘
{alarm_list}

ã€é¸æŠãƒ«ãƒ¼ãƒ«ã€‘
1. CRITICAL / WARNING ã®é‡è¦ãªã‚¢ãƒ©ãƒ¼ãƒ ã‚’å„ªå…ˆ
2. INFOï¼ˆæƒ…å ±é€šçŸ¥ï¼‰ã¯åŸºæœ¬çš„ã«ç„¡è¦–
3. åŒã˜ãƒ‡ãƒã‚¤ã‚¹ã‹ã‚‰ã®é‡è¤‡ã‚¢ãƒ©ãƒ¼ãƒ ã¯1ã¤ã«ã¾ã¨ã‚ã‚‹
4. ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰éšœå®³ï¼ˆé…ä¸‹ã®æ©Ÿå™¨ã®Connection Lostï¼‰ã¯æ ¹æœ¬åŸå› ã§ã¯ãªã„ãŸã‚é™¤å¤–
5. é›»æºéšœå®³ã€Interface Downã€BGP Flappingã€Fan Failãªã©ã€Œç›´æ¥çš„ãªéšœå®³ã€ã‚’é¸ã¶

ã€å‡ºåŠ›å½¢å¼ã€‘
é¸æŠã—ãŸã‚¢ãƒ©ãƒ¼ãƒ ã®ç•ªå·ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
ä¾‹: 1,3,5,12,18

ç•ªå·ã®ã¿ã‚’å‡ºåŠ›ã—ã€èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚
"""
    
    try:
        response = model.generate_content(prompt)
        selected_indices = [int(x.strip()) - 1 for x in response.text.strip().split(',')]
        return [all_alarms[i] for i in selected_indices if i < len(all_alarms)]
    except Exception as e:
        st.warning(f"AIãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
        return [a for a in all_alarms if a.severity in ["CRITICAL", "WARNING"]][:5]

def get_cascade_impact(root_device_id: str) -> Dict[str, Any]:
    """
    ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰éšœå®³ã®å½±éŸ¿ç¯„å›²ã‚’åˆ†æ
    """
    affected_nodes = []
    root_node = TOPOLOGY.get(root_device_id)
    
    if not root_node:
        return {"count": 0, "nodes": [], "reason": ""}
    
    # BFSã§é…ä¸‹ã®ãƒãƒ¼ãƒ‰ã‚’åˆ—æŒ™
    queue = [root_device_id]
    processed = {root_device_id}
    
    while queue:
        current_id = queue.pop(0)
        children = [n for n in TOPOLOGY.values() if n.parent_id == current_id]
        
        for child in children:
            if child.id not in processed:
                affected_nodes.append(child)
                queue.append(child.id)
                processed.add(child.id)
    
    # ç†ç”±æ–‡ã‚’ç”Ÿæˆ
    reason = f"""
**ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰éšœå®³ã®è©³ç´°åˆ†æ**

ã€ç›´æ¥åŸå› ã€‘
{root_device_id} ãŒå®Œå…¨ã«ãƒ€ã‚¦ãƒ³ã—ã¦ã„ã¾ã™ã€‚

ã€ãªãœé…ä¸‹ã®æ©Ÿå™¨ãŒç›£è¦–ä¸èƒ½ãªã®ã‹ã€‘
{root_device_id} ã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒˆãƒãƒ­ã‚¸ãƒ¼ã®Layer {root_node.layer}ã«ä½ç½®ã—ã€
ã™ã¹ã¦ã®é€šä¿¡ã®ä¸­ç¶™ç‚¹ã¨ãªã£ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ‡ãƒã‚¤ã‚¹ãŒãƒ€ã‚¦ãƒ³ã™ã‚‹ã¨ã€
é…ä¸‹ã®å…¨æ©Ÿå™¨ã¸ã®é€šä¿¡çµŒè·¯ãŒé®æ–­ã•ã‚Œã‚‹ãŸã‚ã€ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰åˆ°é”ä¸èƒ½ã¨ãªã‚Šã¾ã™ã€‚

ã€å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹æ©Ÿå™¨ï¼ˆ{len(affected_nodes)}å°ï¼‰ã€‘
"""
    
    for node in sorted(affected_nodes, key=lambda n: n.layer):
        reason += f"\nâ”œ {node.id} (Layer {node.layer}, {node.type})"
    
    reason += """

âš ï¸ **é‡è¦ãªæ³¨æ„äº‹é …**
ã“ã‚Œã‚‰ã®é…ä¸‹ã®æ©Ÿå™¨è‡ªä½“ã«ã¯éšœå®³ã¯ç™ºç”Ÿã—ã¦ã„ã¾ã›ã‚“ã€‚
ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµŒè·¯ãŒé®æ–­ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€Œç›£è¦–ä¸èƒ½ã€çŠ¶æ…‹ã«ãªã£ã¦ã„ã‚‹ã ã‘ã§ã™ã€‚
{root_device_id} ã‚’å¾©æ—§ã™ã‚Œã°ã€ã“ã‚Œã‚‰ã®æ©Ÿå™¨ã¯è‡ªå‹•çš„ã«æ­£å¸¸çŠ¶æ…‹ã«æˆ»ã‚Šã¾ã™ã€‚
"""
    
    return {
        "count": len(affected_nodes),
        "nodes": affected_nodes,
        "reason": reason
    }

def generate_topology_graph(root_cause_id: str = None, cascade_nodes: List[str] = None) -> str:
    """
    Graphvizãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒˆãƒãƒ­ã‚¸ãƒ¼å›³ã‚’ç”Ÿæˆ
    è‰²åˆ†ã‘: èµ¤=çœŸå› ã€ã‚ªãƒ¬ãƒ³ã‚¸=ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰å½±éŸ¿ã€ç·‘=æ­£å¸¸
    """
    cascade_set = set(cascade_nodes) if cascade_nodes else set()
    
    dot = """
digraph Topology {
    rankdir=TB;
    node [shape=box, style=filled];
    
"""
    
    for node_id, node in TOPOLOGY.items():
        if node_id == root_cause_id:
            color = "red"
            label = f"{node_id}\\nâŒ çœŸå› "
        elif node_id in cascade_set:
            color = "orange"
            label = f"{node_id}\\nâš ï¸ ç›£è¦–ä¸èƒ½"
        else:
            color = "lightgreen"
            label = node_id
        
        dot += f'    "{node_id}" [label="{label}", fillcolor={color}];\n'
    
    # ã‚¨ãƒƒã‚¸ã®è¿½åŠ 
    for node_id, node in TOPOLOGY.items():
        if node.parent_id:
            dot += f'    "{node.parent_id}" -> "{node_id}";\n'
    
    dot += "}\n"
    return dot

# =====================================================
# ãƒ¡ã‚¤ãƒ³ç”»é¢
# =====================================================

def main():
    st.title("ğŸ›¡ï¸ AIOps éšœå®³åˆ†æã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("---")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        # APIã‚­ãƒ¼è¨­å®š
        api_key = os.environ.get("GOOGLE_API_KEY", "")
        if not api_key:
            api_key = st.text_input("Google API Key", type="password")
            if api_key:
                os.environ["GOOGLE_API_KEY"] = api_key
        else:
            st.success("âœ… APIã‚­ãƒ¼è¨­å®šæ¸ˆã¿")
        
        st.markdown("---")
        
        # 2æ®µéšã‚·ãƒŠãƒªã‚ªé¸æŠ
        st.subheader("ğŸ“‹ éšœå®³ã‚·ãƒŠãƒªã‚ªé¸æŠ")
        
        # ç¬¬1æ®µéš: ã‚«ãƒ†ã‚´ãƒªé¸æŠ
        category = st.selectbox(
            "ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ",
            list(SCENARIO_CATEGORIES.keys()),
            index=0
        )
        
        # ç¬¬2æ®µéš: è©³ç´°ã‚·ãƒŠãƒªã‚ªé¸æŠ
        scenarios_in_category = SCENARIO_CATEGORIES[category]
        selected_scenario = st.selectbox(
            "è©³ç´°ã‚·ãƒŠãƒªã‚ªã‚’é¸æŠ",
            list(scenarios_in_category.keys()),
            index=0
        )
        
        st.markdown("---")
        
        # åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³
        if st.button("ğŸš€ éšœå®³åˆ†æã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
            if not api_key:
                st.error("âŒ APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
            else:
                st.session_state.current_scenario = selected_scenario
                st.session_state.analysis_done = False
                st.session_state.remediation_executed = False
                st.session_state.health_check_done = False
                st.rerun()
        
        # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
        if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
            st.session_state.analysis_done = False
            st.session_state.current_scenario = None
            st.session_state.root_cause_result = None
            st.session_state.generated_log = ""
            st.session_state.remediation_executed = False
            st.session_state.health_check_done = False
            st.rerun()
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    if st.session_state.current_scenario and not st.session_state.analysis_done:
        st.info(f"ã‚·ãƒŠãƒªã‚ªã€Œ{st.session_state.current_scenario}ã€ã®åˆ†æã‚’é–‹å§‹ã—ã¾ã™...")
        perform_analysis(st.session_state.current_scenario, api_key)
    
    elif st.session_state.analysis_done and st.session_state.root_cause_result:
        display_results(st.session_state.root_cause_result, api_key)
    
    else:
        # åˆæœŸç”»é¢
        st.markdown("""
## ğŸ‘‹ AIOps éšœå®³åˆ†æã‚·ã‚¹ãƒ†ãƒ ã¸ã‚ˆã†ã“ã

### ğŸ¯ ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´
- **å¤§é‡ã‚¢ãƒ©ãƒ¼ãƒ ã‹ã‚‰çœŸå› ã‚’è‡ªå‹•ç‰¹å®š**: 50-200ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒ ã‹ã‚‰é‡è¦ãª3-5ä»¶ã«çµã‚Šè¾¼ã¿
- **ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰éšœå®³ã®è‡ªå‹•åˆ†æ**: é…ä¸‹ã®æ©Ÿå™¨ãŒç›£è¦–ä¸èƒ½ã«ãªã‚‹ç†ç”±ã‚’è©³ç´°ã«èª¬æ˜
- **AIé§†å‹•ã®å¾©æ—§æ‰‹é †ç”Ÿæˆ**: ç‰©ç†å¯¾å¿œã‹ã‚‰ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã¾ã§å®Œå…¨ãªæ‰‹é †æ›¸ã‚’è‡ªå‹•ç”Ÿæˆ

### ğŸ“‹ ä½¿ã„æ–¹
1. å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰**ã‚«ãƒ†ã‚´ãƒª**ã‚’é¸æŠ
2. **è©³ç´°ã‚·ãƒŠãƒªã‚ª**ã‚’é¸æŠ
3. **éšœå®³åˆ†æã‚’å®Ÿè¡Œ**ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯

### ğŸš€ æº–å‚™å®Œäº†
APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚·ãƒŠãƒªã‚ªã‚’é¸æŠã—ã¦åˆ†æã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚
""")
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆé–‹ç™ºæ™‚ã®ã¿ï¼‰
        with st.expander("ğŸ”§ ãƒ‡ãƒãƒƒã‚°æƒ…å ±", expanded=False):
            st.write("**ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹:**")
            st.json({
                "analysis_done": st.session_state.analysis_done,
                "current_scenario": st.session_state.current_scenario,
                "has_result": st.session_state.root_cause_result is not None
            })

def perform_analysis(scenario: str, api_key: str):
    """éšœå®³åˆ†æã‚’å®Ÿè¡Œ"""
    
    try:
        progress_container = st.container()
        
        with progress_container:
            st.info("ğŸ” éšœå®³åˆ†æã‚’é–‹å§‹ã—ã¾ã™...")
            
            # 1. å¯¾è±¡ãƒãƒ¼ãƒ‰ç‰¹å®š
            st.write("ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—1: å¯¾è±¡ãƒãƒ¼ãƒ‰ã‚’ç‰¹å®šä¸­...")
            target_device_id = get_target_node_from_scenario(scenario)
            target_node = TOPOLOGY.get(target_device_id)
            
            if not target_node:
                st.error(f"âŒ ãƒ‡ãƒã‚¤ã‚¹ {target_device_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
            
            st.success(f"âœ… å¯¾è±¡ãƒ‡ãƒã‚¤ã‚¹: {target_device_id}")
            
            # 2. éšœå®³ãƒ­ã‚°ç”Ÿæˆ
            st.write("ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—2: éšœå®³ãƒ­ã‚°ã‚’ç”Ÿæˆä¸­...")
            try:
                log_result = run_diagnostic_simulation(scenario, target_node, api_key)
                generated_log = log_result.get("sanitized_log", "")
                st.session_state.generated_log = generated_log
                st.success(f"âœ… ãƒ­ã‚°ç”Ÿæˆå®Œäº†ï¼ˆ{len(generated_log)}æ–‡å­—ï¼‰")
            except Exception as e:
                st.error(f"âŒ ãƒ­ã‚°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                generated_log = f"Error: {e}"
                st.session_state.generated_log = generated_log
            
            # 3. å¤§é‡ã‚¢ãƒ©ãƒ¼ãƒ ç”Ÿæˆ
            st.write("ğŸš¨ ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¢ãƒ©ãƒ¼ãƒ ã‚’ç”Ÿæˆä¸­ï¼ˆ50-200ä»¶ï¼‰...")
            try:
                all_alarms = generate_massive_alarms(scenario, target_device_id)
                st.success(f"âœ… {len(all_alarms)}ä»¶ã®ã‚¢ãƒ©ãƒ¼ãƒ ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
            except Exception as e:
                st.error(f"âŒ ã‚¢ãƒ©ãƒ¼ãƒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                all_alarms = [Alarm(target_device_id, "Error generating alarms", "CRITICAL")]
            
            # 4. AIã‚¢ãƒ©ãƒ¼ãƒ é¸åˆ¥
            st.write("ğŸ¯ ã‚¹ãƒ†ãƒƒãƒ—4: AIãŒé‡è¦ãªã‚¢ãƒ©ãƒ¼ãƒ ã‚’é¸åˆ¥ä¸­...")
            try:
                critical_alarms = filter_critical_alarms(all_alarms, api_key)
                st.success(f"âœ… {len(critical_alarms)}ä»¶ã®é‡è¦ã‚¢ãƒ©ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
            except Exception as e:
                st.error(f"âŒ ã‚¢ãƒ©ãƒ¼ãƒ é¸åˆ¥ã‚¨ãƒ©ãƒ¼: {e}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: CRITICALã‚¢ãƒ©ãƒ¼ãƒ ã®ã¿
                critical_alarms = [a for a in all_alarms if a.severity == "CRITICAL"][:5]
                st.warning(f"âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {len(critical_alarms)}ä»¶ã®CRITICALã‚¢ãƒ©ãƒ¼ãƒ ã‚’ä½¿ç”¨")
            
            # 5. ãƒ­ã‚°æ¤œè¨¼
            st.write("ğŸ”¬ ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ­ã‚°ã‚’æ¤œè¨¼ä¸­...")
            try:
                verification = verify_log_content(generated_log)
                st.success("âœ… ãƒ­ã‚°æ¤œè¨¼å®Œäº†")
            except Exception as e:
                st.error(f"âŒ ãƒ­ã‚°æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
                verification = {}
            
            # 6. å› æœæ¨è«–
            st.write("ğŸ§  ã‚¹ãƒ†ãƒƒãƒ—6: å› æœæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã§çœŸå› ã‚’ç‰¹å®šä¸­...")
            try:
                engine = CausalInferenceEngine(TOPOLOGY)
                inference_result = engine.analyze_alarms(critical_alarms)
                st.success("âœ… å› æœæ¨è«–å®Œäº†")
            except Exception as e:
                st.error(f"âŒ å› æœæ¨è«–ã‚¨ãƒ©ãƒ¼: {e}")
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆçµæœã‚’ä½œæˆ
                from logic import InferenceResult
                inference_result = InferenceResult(
                    root_cause_node=target_node,
                    root_cause_reason=f"ã‚¨ãƒ©ãƒ¼: {e}",
                    sop_key="ERROR",
                    related_alarms=critical_alarms,
                    severity="CRITICAL"
                )
            
            # 7. LLMå†—é•·æ€§åˆ†æ
            st.write("ğŸ¤– ã‚¹ãƒ†ãƒƒãƒ—7: LLMã§å†—é•·æ€§ã‚’åˆ†æä¸­...")
            try:
                rca = LogicalRCA(TOPOLOGY)
                llm_analysis = rca.analyze(critical_alarms)
                st.success("âœ… LLMåˆ†æå®Œäº†")
            except Exception as e:
                st.error(f"âŒ LLMåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                llm_analysis = [{
                    "id": target_device_id,
                    "label": "Analysis failed",
                    "prob": 0.5,
                    "type": "ERROR",
                    "tier": 1,
                    "reason": str(e)
                }]
            
            # 8. ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰å½±éŸ¿åˆ†æ
            st.write("ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—8: ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰å½±éŸ¿ã‚’åˆ†æä¸­...")
            try:
                cascade_impact = get_cascade_impact(target_device_id)
                st.success(f"âœ… å½±éŸ¿ç¯„å›²: {cascade_impact['count']}å°")
            except Exception as e:
                st.error(f"âŒ ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                cascade_impact = {"count": 0, "nodes": [], "reason": str(e)}
            
            # 9. å¾©æ—§æ‰‹é †ç”Ÿæˆ
            st.write("ğŸ“‹ ã‚¹ãƒ†ãƒƒãƒ—9: å¾©æ—§æ‰‹é †ã‚’ç”Ÿæˆä¸­...")
            try:
                remediation = generate_remediation_commands(
                    scenario,
                    llm_analysis[0] if llm_analysis else {},
                    target_node,
                    api_key
                )
                st.success("âœ… å¾©æ—§æ‰‹é †ç”Ÿæˆå®Œäº†")
            except Exception as e:
                st.error(f"âŒ å¾©æ—§æ‰‹é †ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                remediation = f"""
### ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ
å¾©æ—§æ‰‹é †ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}

### æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
1. APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„
2. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„
3. æ‰‹å‹•ã§ã®å¯¾å¿œã‚’æ¤œè¨ã—ã¦ãã ã•ã„
"""
            
            # çµæœã‚’ä¿å­˜
            st.session_state.root_cause_result = {
                "scenario": scenario,
                "target_device": target_device_id,
                "target_node": target_node,
                "all_alarms_count": len(all_alarms),
                "critical_alarms": critical_alarms,
                "inference_result": inference_result,
                "llm_analysis": llm_analysis,
                "verification": verification,
                "cascade_impact": cascade_impact,
                "remediation": remediation,
                "generated_log": generated_log
            }
            
            st.session_state.analysis_done = True
            st.success("âœ… ã™ã¹ã¦ã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            time.sleep(1)
            st.rerun()
            
    except Exception as e:
        st.error(f"âŒ è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.exception(e)
        st.warning("ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


def display_results(result: Dict[str, Any], api_key: str):
    """åˆ†æçµæœã‚’è¡¨ç¤º"""
    
    st.markdown("# ğŸ“Š åˆ†æçµæœ")
    st.markdown("---")
    
    # 1. KPIãƒ¡ãƒˆãƒªã‚¯ã‚¹
    st.markdown("## ğŸ¯ çœŸå› ç‰¹å®šçµæœ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        noise_reduction = ((result['all_alarms_count'] - len(result['critical_alarms'])) / result['all_alarms_count'] * 100)
        st.metric(
            "ğŸ“‰ ãƒã‚¤ã‚ºå‰Šæ¸›ç‡",
            f"{noise_reduction:.1f}%",
            delta="AIé¸åˆ¥æ¸ˆã¿"
        )
    
    with col2:
        st.metric(
            "ğŸ“¨ ç·ã‚¢ãƒ©ãƒ¼ãƒ æ•°",
            f"{result['all_alarms_count']}ä»¶",
            delta=f"-{result['all_alarms_count'] - len(result['critical_alarms'])}ä»¶"
        )
    
    with col3:
        st.metric(
            "âœ… é‡è¦ã‚¢ãƒ©ãƒ¼ãƒ ",
            f"{len(result['critical_alarms'])}ä»¶",
            delta="é¸åˆ¥æ¸ˆã¿"
        )
    
    with col4:
        st.metric(
            "ğŸ¯ çœŸå› ",
            "1ä»¶ç‰¹å®š",
            delta="åˆ†æå®Œäº†"
        )
    
    st.markdown("---")
    
    # 2. çœŸå› ã®å¤§ããªè¡¨ç¤º
    inference = result['inference_result']
    root_node = inference.root_cause_node
    
    if root_node:
        # ç¢ºä¿¡åº¦ã®è¨ˆç®—
        confidence = result['llm_analysis'][0]['prob'] * 100 if result['llm_analysis'] else 50
        
        st.markdown(f"""
<div style="background-color: #ff4444; padding: 30px; border-radius: 15px; color: white; margin: 20px 0;">
    <h2 style="color: white; margin-top: 0;">ğŸš¨ çœŸå› ç‰¹å®šå®Œäº†</h2>
    <hr style="border-color: white; opacity: 0.3;">
    <h3 style="color: white;">ãƒ‡ãƒã‚¤ã‚¹: {root_node.id}</h3>
    <p style="font-size: 20px; margin: 10px 0;"><strong>éšœå®³ç¨®åˆ¥:</strong> {result['scenario']}</p>
    <p style="font-size: 20px; margin: 10px 0;"><strong>å½±éŸ¿åº¦:</strong> {inference.severity}</p>
    <p style="font-size: 20px; margin: 10px 0;"><strong>AIç¢ºä¿¡åº¦:</strong> {confidence:.0f}%</p>
    <hr style="border-color: white; opacity: 0.3;">
    <p style="font-size: 16px; margin-top: 15px;"><strong>åˆ†æç†ç”±:</strong><br>{inference.root_cause_reason}</p>
</div>
""", unsafe_allow_html=True)
    else:
        st.warning("âš ï¸ çœŸå› ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸ")
    
    st.markdown("---")
    
    # 3. ãƒãƒ§ã‚¤ã‚¹ã•ã‚ŒãŸã‚¢ãƒ©ãƒ¼ãƒ è¡¨ç¤º
    with st.expander("ğŸš¨ ãƒãƒ§ã‚¤ã‚¹ã•ã‚ŒãŸé‡è¦ã‚¢ãƒ©ãƒ¼ãƒ ", expanded=True):
        if result['critical_alarms']:
            for i, alarm in enumerate(result['critical_alarms'], 1):
                severity_color = "ğŸ”´" if alarm.severity == "CRITICAL" else "ğŸŸ¡" if alarm.severity == "WARNING" else "âšª"
                st.markdown(f"{severity_color} **{i}.** `{alarm.device_id}` â†’ {alarm.message} `[{alarm.severity}]`")
        else:
            st.info("ã‚¢ãƒ©ãƒ¼ãƒ ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆæ­£å¸¸ç¨¼åƒï¼‰")
    
    st.markdown("---")
    
    # 4. ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰å½±éŸ¿ã®èª¬æ˜
    cascade = result['cascade_impact']
    if cascade['count'] > 0:
        with st.expander("ğŸ“Š ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰éšœå®³ã®å½±éŸ¿åˆ†æ", expanded=True):
            st.markdown(cascade['reason'])
            
            # å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹ãƒãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ
            st.markdown("### å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹æ©Ÿå™¨ã®è©³ç´°")
            for node in cascade['nodes']:
                st.markdown(f"- **{node.id}** (Layer {node.layer}, {node.type})")
    else:
        st.info("âœ… ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰éšœå®³ã¯ç™ºç”Ÿã—ã¦ã„ã¾ã›ã‚“")
    
    st.markdown("---")
    
    # 5. ãƒˆãƒãƒ­ã‚¸ãƒ¼å›³
    st.markdown("## ğŸ—ºï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒˆãƒãƒ­ã‚¸ãƒ¼ï¼ˆå½±éŸ¿ç¯„å›²ã®å¯è¦–åŒ–ï¼‰")
    
    try:
        cascade_node_ids = [n.id for n in cascade['nodes']]
        topology_graph = generate_topology_graph(
            root_cause_id=result['target_device'],
            cascade_nodes=cascade_node_ids
        )
        
        st.graphviz_chart(topology_graph)
        
        st.markdown("""
**å‡¡ä¾‹:**
- ğŸ”´ **èµ¤**: çœŸå› ï¼ˆæ ¹æœ¬åŸå› ã®ãƒ‡ãƒã‚¤ã‚¹ï¼‰
- ğŸŸ  **ã‚ªãƒ¬ãƒ³ã‚¸**: ç›£è¦–ä¸èƒ½ï¼ˆã‚«ã‚¹ã‚±ãƒ¼ãƒ‰å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹ï¼‰
- ğŸŸ¢ **ç·‘**: æ­£å¸¸ç¨¼åƒä¸­
""")
    except Exception as e:
        st.error(f"ãƒˆãƒãƒ­ã‚¸ãƒ¼å›³ã®ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    st.markdown("---")
    
    # 6. ç”Ÿæˆã•ã‚ŒãŸéšœå®³ãƒ­ã‚°
    with st.expander("ğŸ“ ç”Ÿæˆã•ã‚ŒãŸéšœå®³ãƒ­ã‚°", expanded=False):
        st.code(result['generated_log'], language='text')
    
    # 7. æ ¹æœ¬åŸå› åˆ†æã®è©³ç´°
    with st.expander("ğŸ” æ ¹æœ¬åŸå› åˆ†æã®è©³ç´°", expanded=False):
        st.markdown("### å› æœæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆ†æ")
        st.markdown(f"""
- **SOP Key**: `{inference.sop_key}`
- **é–¢é€£ã‚¢ãƒ©ãƒ¼ãƒ æ•°**: {len(inference.related_alarms)}ä»¶
- **é‡å¤§åº¦**: {inference.severity}
""")
        
        st.markdown("### LLMåˆ†æçµæœ")
        for i, analysis in enumerate(result['llm_analysis'], 1):
            st.markdown(f"**åˆ†æ {i}:**")
            st.json(analysis)
        
        st.markdown("### ãƒ­ã‚°æ¤œè¨¼çµæœï¼ˆGround Truthï¼‰")
        if result['verification']:
            st.text(format_verification_report(result['verification']))
        else:
            st.info("æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    st.markdown("---")
    
    # 8. å¾©æ—§æ‰‹é †
    st.markdown("## ğŸ“‹ è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸå¾©æ—§æ‰‹é †")
    
    st.markdown(result['remediation'])
    
    st.markdown("---")
    
    # 9. å¾©æ—§æªç½®ãƒœã‚¿ãƒ³
    st.markdown("## ğŸ”§ å¾©æ—§ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ”§ å¾©æ—§æªç½®ã‚’å®Ÿè¡Œ", type="primary", use_container_width=True, key="remediation_btn"):
            with st.spinner("å¾©æ—§æªç½®ã‚’å®Ÿè¡Œä¸­..."):
                time.sleep(2)
                st.session_state.remediation_executed = True
                st.rerun()
    
    with col2:
        if st.button("âœ… æ­£å¸¸æ€§ç¢ºèª", use_container_width=True, key="health_check_btn"):
            with st.spinner("æ­£å¸¸æ€§ç¢ºèªä¸­..."):
                time.sleep(2)
                st.session_state.health_check_done = True
                st.rerun()
    
    # å¾©æ—§æªç½®ã®çµæœ
    if st.session_state.remediation_executed:
        st.success("âœ… å¾©æ—§æªç½®ãŒå®Œäº†ã—ã¾ã—ãŸ")
        st.markdown("""
**å®Ÿè¡Œã—ãŸå†…å®¹:**
- âœ… æ•…éšœã—ãŸé›»æºãƒ¦ãƒ‹ãƒƒãƒˆã‚’äº¤æ›ã—ã¾ã—ãŸ
- âœ… ãƒ‡ãƒã‚¤ã‚¹ã‚’å†èµ·å‹•ã—ã¾ã—ãŸ  
- âœ… ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®çŠ¶æ…‹ã‚’ç¢ºèªã—ã¾ã—ãŸ
- âœ… ã™ã¹ã¦ã®ã‚µãƒ¼ãƒ“ã‚¹ãŒæ­£å¸¸ã«ç¨¼åƒã—ã¦ã„ã¾ã™

**æ‰€è¦æ™‚é–“:** ç´„5åˆ†
""")
    
    # æ­£å¸¸æ€§ç¢ºèªã®çµæœ
    if st.session_state.health_check_done:
        if result['scenario'] == "æ­£å¸¸ç¨¼åƒ":
            st.success("âœ… ã™ã¹ã¦ã®ãƒ‡ãƒã‚¤ã‚¹ãŒæ­£å¸¸ã«ç¨¼åƒã—ã¦ã„ã¾ã™")
        else:
            try:
                target_node = result['target_node']
                health_commands = generate_health_check_commands(target_node, api_key)
                
                st.success("âœ… æ­£å¸¸æ€§ç¢ºèªãŒå®Œäº†ã—ã¾ã—ãŸ")
                st.markdown(f"""
**ç¢ºèªçµæœ:**
- âœ… ãƒ‡ãƒã‚¤ã‚¹ {result['target_device']} ã¯æ­£å¸¸ã«å¾©æ—§ã—ã¾ã—ãŸ
- âœ… ã™ã¹ã¦ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãŒ UP çŠ¶æ…‹ã§ã™
- âœ… é…ä¸‹ã®æ©Ÿå™¨ã‚‚æ­£å¸¸ã«é€šä¿¡å¯èƒ½ã§ã™
- âœ… ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã¯æ­£å¸¸ã§ã™

**å®Ÿè¡Œã—ãŸã‚³ãƒãƒ³ãƒ‰:**
```
{health_commands}
```
""")
            except Exception as e:
                st.warning(f"æ­£å¸¸æ€§ç¢ºèªã®ä¸€éƒ¨ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    st.markdown("---")
    
    # 10. AIãƒãƒ£ãƒƒãƒˆæ¬„
    st.markdown("## ğŸ’¬ AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆï¼ˆè©³ç´°ç¢ºèªï¼‰")
    
    st.markdown("""
ã“ã®éšœå®³åˆ†æã«ã¤ã„ã¦ã€ã•ã‚‰ã«è©³ã—ãçŸ¥ã‚ŠãŸã„ã“ã¨ãŒã‚ã‚Œã°è³ªå•ã—ã¦ãã ã•ã„ã€‚
ä¾‹:
- ã“ã®éšœå®³ã®å½±éŸ¿ç¯„å›²ã‚’æ•™ãˆã¦
- å¾©æ—§ã«ã‹ã‹ã‚‹æ™‚é–“ã®è¦‹ç©ã‚‚ã‚Šã¯ï¼Ÿ
- ä»Šå¾Œã®äºˆé˜²ç­–ã¯ï¼Ÿ
""")
    
    user_question = st.text_input(
        "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        placeholder="ä¾‹: ã“ã®éšœå®³ã®å½±éŸ¿ç¯„å›²ã‚’è©³ã—ãæ•™ãˆã¦",
        key="chat_input"
    )
    
    if user_question:
        with st.spinner("AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
            try:
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel('gemini-1.5-flash')
                
                context = f"""
ã‚ãªãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯éšœå®³åˆ†æã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®éšœå®³åˆ†æçµæœã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ä¸å¯§ã‹ã¤æ­£ç¢ºã«ç­”ãˆã¦ãã ã•ã„ã€‚

ã€éšœå®³ã‚·ãƒŠãƒªã‚ªã€‘
{result['scenario']}

ã€çœŸå› ãƒ‡ãƒã‚¤ã‚¹ã€‘
{result['target_device']}

ã€åˆ†æçµæœã€‘
{inference.root_cause_reason}

ã€å½±éŸ¿ç¯„å›²ã€‘
{cascade['count']}å°ã®æ©Ÿå™¨ãŒå½±éŸ¿ã‚’å—ã‘ã¦ã„ã¾ã™

ã€é‡å¤§åº¦ã€‘
{inference.severity}

ã€ç¢ºä¿¡åº¦ã€‘
{confidence:.0f}%

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
{user_question}

ã€å›ç­”ã®æ³¨æ„ç‚¹ã€‘
- æŠ€è¡“çš„ã«æ­£ç¢ºãªæƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„
- åˆ†ã‹ã‚Šã‚„ã™ãã€å®Ÿå‹™çš„ãªå›ç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„
- å¿…è¦ã«å¿œã˜ã¦å…·ä½“çš„ãªæ‰‹é †ã‚„æ•°å€¤ã‚’ç¤ºã—ã¦ãã ã•ã„
"""
                
                response = model.generate_content(context)
                st.markdown("### ğŸ¤– AIå›ç­”")
                st.markdown(response.text)
                
            except Exception as e:
                st.error(f"AIå›ç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                st.info("APIã‚­ãƒ¼ã®ç¢ºèªã€ã¾ãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# =====================================================
# å®Ÿè¡Œ
# =====================================================
if __name__ == "__main__":
    main()
