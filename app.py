# -*- coding: utf-8 -*-
"""
AIOps Incident Cockpit - Multi-Site Edition
=============================================
è¤‡æ•°æ‹ ç‚¹å¯¾å¿œç‰ˆ AIOps ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆ
å‰å›ã®UXã¨æ©Ÿèƒ½ã‚’å®Œå…¨ã«å¾©å…ƒ
"""

import streamlit as st
import graphviz
import os
import time
import json
import re
import hashlib
import pandas as pd
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from google.api_core import exceptions as google_exceptions

# Google Generative AI
try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¾¤ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from registry import (
    SiteRegistry,
    list_sites,
    list_networks,
    get_paths,
    load_topology,
    get_display_name,
    NetworkNode,
)
from alarm_generator import generate_alarms_for_scenario, get_alarm_summary, Alarm, NodeColor
from inference_engine import LogicalRCA
from network_ops import (
    run_diagnostic_simulation,
    generate_remediation_commands,
    generate_analyst_report_streaming,
    generate_remediation_commands_streaming,
    run_remediation_parallel_v2,
    RemediationEnvironment,
    sanitize_output,
)
from verifier import verify_log_content, format_verification_report
from rate_limiter import GlobalRateLimiter, RateLimitConfig

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(
    page_title="AIOps Incident Cockpit",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =====================================================
# å®šæ•°å®šç¾©
# =====================================================
class ImpactLevel:
    """å½±éŸ¿åº¦ãƒ¬ãƒ™ãƒ«å®šç¾©"""
    COMPLETE_OUTAGE = 100
    CRITICAL = 90
    DEGRADED_HIGH = 80
    DEGRADED_MID = 70
    DOWNSTREAM = 50
    LOW_PRIORITY = 20

# ã‚·ãƒŠãƒªã‚ªã¨å½±éŸ¿åº¦ã®ãƒãƒƒãƒ”ãƒ³ã‚°
SCENARIO_IMPACT_MAP = {
    "æ­£å¸¸ç¨¼åƒ": 0,
    "WANå…¨å›ç·šæ–­": ImpactLevel.COMPLETE_OUTAGE,
    "[WAN] é›»æºéšœå®³ï¼šä¸¡ç³»": ImpactLevel.COMPLETE_OUTAGE,
    "[L2SW] é›»æºéšœå®³ï¼šä¸¡ç³»": ImpactLevel.COMPLETE_OUTAGE,
    "[Core] ä¸¡ç³»æ•…éšœ": ImpactLevel.CRITICAL,
    "[FW] é›»æºéšœå®³ï¼šä¸¡ç³»": ImpactLevel.CRITICAL,
    "[FW] é›»æºéšœå®³ï¼šç‰‡ç³»": ImpactLevel.DEGRADED_HIGH,
    "FWç‰‡ç³»éšœå®³": ImpactLevel.DEGRADED_HIGH,
    "[WAN] é›»æºéšœå®³ï¼šç‰‡ç³»": ImpactLevel.DEGRADED_MID,
    "[L2SW] é›»æºéšœå®³ï¼šç‰‡ç³»": ImpactLevel.DEGRADED_MID,
    "L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³": ImpactLevel.DEGRADED_HIGH,
    "[WAN] BGPãƒ«ãƒ¼ãƒˆãƒ•ãƒ©ãƒƒãƒ”ãƒ³ã‚°": ImpactLevel.DEGRADED_HIGH,
    "[WAN] FANæ•…éšœ": ImpactLevel.DEGRADED_MID,
    "[FW] FANæ•…éšœ": ImpactLevel.DEGRADED_MID,
    "[L2SW] FANæ•…éšœ": ImpactLevel.DEGRADED_MID,
    "[WAN] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯": ImpactLevel.DEGRADED_MID,
    "[FW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯": ImpactLevel.DEGRADED_MID,
    "[L2SW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯": ImpactLevel.DEGRADED_MID,
    "[WAN] è¤‡åˆéšœå®³ï¼šé›»æºï¼†FAN": ImpactLevel.DEGRADED_HIGH,
    "[Complex] åŒæ™‚å¤šç™ºï¼šFW & AP": ImpactLevel.DEGRADED_HIGH,
}

# ã‚·ãƒŠãƒªã‚ªã‚«ãƒ†ã‚´ãƒª
SCENARIO_MAP = {
    "åŸºæœ¬ãƒ»åºƒåŸŸéšœå®³": [
        "æ­£å¸¸ç¨¼åƒ",
        "1. WANå…¨å›ç·šæ–­",
        "2. FWç‰‡ç³»éšœå®³",
        "3. L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³"
    ],
    "WAN Router": [
        "4. [WAN] é›»æºéšœå®³ï¼šç‰‡ç³»",
        "5. [WAN] é›»æºéšœå®³ï¼šä¸¡ç³»",
        "6. [WAN] BGPãƒ«ãƒ¼ãƒˆãƒ•ãƒ©ãƒƒãƒ”ãƒ³ã‚°",
        "7. [WAN] FANæ•…éšœ",
        "8. [WAN] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"
    ],
    "Firewall": [
        "9. [FW] é›»æºéšœå®³ï¼šç‰‡ç³»",
        "10. [FW] é›»æºéšœå®³ï¼šä¸¡ç³»",
        "11. [FW] FANæ•…éšœ",
        "12. [FW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"
    ],
    "L2 Switch": [
        "13. [L2SW] é›»æºéšœå®³ï¼šç‰‡ç³»",
        "14. [L2SW] é›»æºéšœå®³ï¼šä¸¡ç³»",
        "15. [L2SW] FANæ•…éšœ",
        "16. [L2SW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"
    ],
    "è¤‡åˆãƒ»ãã®ä»–": [
        "17. [WAN] è¤‡åˆéšœå®³ï¼šé›»æºï¼†FAN",
        "18. [Complex] åŒæ™‚å¤šç™ºï¼šFW & AP"
    ]
}


# =====================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =====================================================
def get_scenario_impact_level(scenario: str) -> int:
    """ã‚·ãƒŠãƒªã‚ªã®å½±éŸ¿åº¦ã‚’å–å¾—"""
    for key, value in SCENARIO_IMPACT_MAP.items():
        if key in scenario:
            return value
    return ImpactLevel.DEGRADED_MID


def get_status_from_alarms(scenario: str, alarms: List[Alarm]) -> str:
    """ã‚¢ãƒ©ãƒ¼ãƒ ã‹ã‚‰ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’åˆ¤å®š"""
    if not alarms:
        return "æ­£å¸¸"
    
    impact = get_scenario_impact_level(scenario)
    
    if impact >= ImpactLevel.COMPLETE_OUTAGE:
        return "åœæ­¢"
    elif impact >= ImpactLevel.DEGRADED_HIGH:
        return "è¦å¯¾å¿œ"
    elif impact >= ImpactLevel.DEGRADED_MID:
        if any(a.severity == "CRITICAL" for a in alarms):
            return "è¦å¯¾å¿œ"
        return "æ³¨æ„"
    elif impact >= ImpactLevel.DOWNSTREAM:
        return "æ³¨æ„"
    else:
        return "æ­£å¸¸"


def get_status_color(status: str) -> str:
    """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«å¯¾å¿œã™ã‚‹è‰²ã‚’å–å¾—"""
    return {
        "åœæ­¢": "#d32f2f",
        "è¦å¯¾å¿œ": "#f57c00",
        "æ³¨æ„": "#fbc02d",
        "æ­£å¸¸": "#4caf50"
    }.get(status, "#9e9e9e")


def get_status_icon(status: str) -> str:
    """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«å¯¾å¿œã™ã‚‹ã‚¢ã‚¤ã‚³ãƒ³ã‚’å–å¾—"""
    return {
        "åœæ­¢": "ğŸ”´",
        "è¦å¯¾å¿œ": "ğŸŸ ",
        "æ³¨æ„": "ğŸŸ¡",
        "æ­£å¸¸": "ğŸŸ¢"
    }.get(status, "âšª")


def _hash_text(text: str) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—"""
    return hashlib.sha256((text or "").encode("utf-8")).hexdigest()[:16]


def load_config_by_id(device_id: str) -> str:
    """configsãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    possible_paths = [f"configs/{device_id}.txt", f"{device_id}.txt"]
    for path in possible_paths:
        if os.path.exists(path):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    return f.read()
            except Exception:
                pass
    return "Config file not found."


@st.cache_resource
def get_rate_limiter():
    """ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒã‚¿ãƒ¼ã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³"""
    return GlobalRateLimiter(RateLimitConfig(rpm=30, rpd=14400, safety_margin=0.9))


def generate_content_with_retry(model, prompt, stream=True, retries=3):
    """ãƒªãƒˆãƒ©ã‚¤ä»˜ãã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ"""
    limiter = get_rate_limiter()
    for i in range(retries):
        try:
            if not limiter.wait_for_slot(timeout=60):
                raise RuntimeError("Rate limit timeout")
            limiter.record_request()
            return model.generate_content(prompt, stream=stream)
        except google_exceptions.ServiceUnavailable:
            if i == retries - 1:
                raise
            time.sleep(2 * (i + 1))
    return None


def _pick_first(mapping: dict, keys: list, default: str = "") -> str:
    """ãƒãƒƒãƒ”ãƒ³ã‚°ã‹ã‚‰æœ€åˆã®éç©ºå€¤ã‚’å–å¾—"""
    for k in keys:
        try:
            v = mapping.get(k, None)
        except Exception:
            v = None
        if v is None:
            continue
        if isinstance(v, (int, float, bool)):
            s = str(v)
            if s:
                return s
        elif isinstance(v, str):
            if v.strip():
                return v.strip()
    return default


def _build_ci_context_for_chat(topology: dict, target_node_id: str) -> dict:
    """ãƒãƒ£ãƒƒãƒˆç”¨ã®CIã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰"""
    node = topology.get(target_node_id) if target_node_id else None
    if node:
        if hasattr(node, 'metadata'):
            md = node.metadata or {}
        else:
            md = node.get('metadata', {}) if isinstance(node, dict) else {}
    else:
        md = {}

    ci = {
        "device_id": target_node_id or "",
        "hostname": _pick_first(md, ["hostname", "host", "name"], default=(target_node_id or "")),
        "vendor": _pick_first(md, ["vendor", "manufacturer", "maker", "brand"], default=""),
        "os": _pick_first(md, ["os", "platform", "os_name", "software", "sw"], default=""),
        "model": _pick_first(md, ["model", "hw_model", "product", "sku"], default=""),
        "role": _pick_first(md, ["role", "type", "device_role"], default=""),
        "layer": _pick_first(md, ["layer", "level", "network_layer"], default=""),
        "site": _pick_first(md, ["site", "dc", "datacenter", "location"], default=""),
    }

    try:
        conf = load_config_by_id(target_node_id) if target_node_id else ""
        if conf:
            ci["config_excerpt"] = conf[:1500]
    except Exception:
        pass

    return ci


def run_diagnostic_simulation_no_llm(selected_scenario: str, target_node_obj) -> dict:
    """LLMã‚’å‘¼ã°ãªã„ç–‘ä¼¼è¨ºæ–­"""
    device_id = getattr(target_node_obj, "id", "UNKNOWN") if target_node_obj else "UNKNOWN"
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    lines = [
        f"[PROBE] ts={ts}",
        f"[PROBE] scenario={selected_scenario}",
        f"[PROBE] target_device={device_id}",
        "",
    ]

    # å¾©æ—§æˆåŠŸãƒ•ãƒ©ã‚°ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
    recovered_devices = st.session_state.get("recovered_devices") or {}
    recovered_map = st.session_state.get("recovered_scenario_map") or {}

    if recovered_devices.get(device_id) and recovered_map.get(device_id) == selected_scenario:
        # å¾©æ—§å¾Œã®ç–‘ä¼¼ãƒ­ã‚°
        if "FW" in selected_scenario:
            lines += [
                "show chassis cluster status",
                "Redundancy group 0: healthy",
                "control link: up",
                "fabric link: up",
            ]
        elif "WAN" in selected_scenario or "WANå…¨å›ç·šæ–­" in selected_scenario:
            lines += [
                "show ip interface brief",
                "GigabitEthernet0/0 up up",
                "show ip bgp summary",
                "Neighbor 203.0.113.2 Established",
                "ping 203.0.113.2 repeat 5",
                "Success rate is 100 percent (5/5)",
            ]
        elif "L2SW" in selected_scenario:
            lines += [
                "show environment",
                "Fan: OK",
                "Temperature: OK",
                "show interface status",
                "Uplink: up",
            ]
        else:
            lines += [
                "show system alarms",
                "No active alarms",
                "ping 8.8.8.8 repeat 5",
                "Success rate is 100 percent (5/5)",
            ]
        return {
            "status": "SUCCESS",
            "sanitized_log": "\n".join(lines),
            "device_id": device_id,
        }

    # éšœå®³ä¸­ã®ç–‘ä¼¼ãƒ­ã‚°
    if "WANå…¨å›ç·šæ–­" in selected_scenario or "[WAN]" in selected_scenario:
        lines += [
            "show ip interface brief",
            "GigabitEthernet0/0 down down",
            "show ip bgp summary",
            "Neighbor 203.0.113.2 Idle",
            "ping 203.0.113.2 repeat 5",
            "Success rate is 0 percent (0/5)",
        ]
    elif "FWç‰‡ç³»éšœå®³" in selected_scenario or "[FW]" in selected_scenario:
        lines += [
            "show chassis cluster status",
            "Redundancy group 0: degraded",
            "control link: down",
            "fabric link: up",
        ]
    elif "L2SW" in selected_scenario:
        lines += [
            "show environment",
            "Fan: FAIL",
            "Temperature: HIGH",
            "show interface status",
            "Uplink: flapping",
        ]
    else:
        lines += [
            "show system alarms",
            "No active alarms",
        ]

    return {
        "status": "SUCCESS",
        "sanitized_log": "\n".join(lines),
        "device_id": device_id,
    }


# =====================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
# =====================================================
def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
    defaults = {
        # æ‹ ç‚¹åˆ¥ã‚·ãƒŠãƒªã‚ª
        "site_scenarios": {},
        # é¸æŠä¸­ã®æ‹ ç‚¹
        "active_site": None,
        # ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ•ãƒ©ã‚°
        "maint_flags": {},
        # åˆ†æçµæœ
        "live_result": None,
        "verification_result": None,
        "generated_report": None,
        "remediation_plan": None,
        "verification_log": None,
        # ãƒãƒ£ãƒƒãƒˆ
        "messages": [],
        "chat_session": None,
        "chat_quick_text": "",
        # ãã®ä»–
        "trigger_analysis": False,
        "logic_engines": {},
        "balloons_shown": False,
        "recovered_devices": {},
        "recovered_scenario_map": {},
        "report_cache": {},
    }
    
    for key, default in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default


init_session_state()


# =====================================================
# æ‹ ç‚¹çŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰
# =====================================================
@dataclass
class SiteStatus:
    """æ‹ ç‚¹ã®çŠ¶æ…‹æƒ…å ±"""
    site_id: str
    display_name: str
    scenario: str
    status: str
    alarm_count: int
    critical_count: int
    warning_count: int
    affected_devices: List[str]
    is_maintenance: bool
    mttr_estimate: str


def build_site_statuses() -> List[SiteStatus]:
    """å…¨æ‹ ç‚¹ã®çŠ¶æ…‹ã‚’æ§‹ç¯‰"""
    sites = list_sites()
    statuses = []
    
    for site_id in sites:
        scenario = st.session_state.site_scenarios.get(site_id, "æ­£å¸¸ç¨¼åƒ")
        paths = get_paths(site_id)
        topology = load_topology(paths.topology_path)
        alarms = generate_alarms_for_scenario(topology, scenario)
        summary = get_alarm_summary(alarms)
        status = get_status_from_alarms(scenario, alarms)
        is_maint = st.session_state.maint_flags.get(site_id, False)
        
        if status in ["åœæ­¢", "è¦å¯¾å¿œ"]:
            mttr = f"{30 + summary['total'] * 5}åˆ†"
        else:
            mttr = "-"
        
        statuses.append(SiteStatus(
            site_id=site_id,
            display_name=get_display_name(site_id),
            scenario=scenario,
            status=status,
            alarm_count=summary['total'],
            critical_count=summary['critical'],
            warning_count=summary['warning'],
            affected_devices=summary['devices'],
            is_maintenance=is_maint,
            mttr_estimate=mttr
        ))
    
    priority = {"åœæ­¢": 0, "è¦å¯¾å¿œ": 1, "æ³¨æ„": 2, "æ­£å¸¸": 3}
    statuses.sort(key=lambda s: (priority.get(s.status, 4), -s.alarm_count))
    
    return statuses


# =====================================================
# æ‹ ç‚¹çŠ¶æ…‹ãƒœãƒ¼ãƒ‰ã®æç”»
# =====================================================
def render_site_status_board():
    """æ‹ ç‚¹çŠ¶æ…‹ãƒœãƒ¼ãƒ‰ã‚’æç”»"""
    st.subheader("ğŸ¢ æ‹ ç‚¹çŠ¶æ…‹ãƒœãƒ¼ãƒ‰")
    
    statuses = build_site_statuses()
    
    count_stop = sum(1 for s in statuses if s.status == "åœæ­¢")
    count_action = sum(1 for s in statuses if s.status == "è¦å¯¾å¿œ")
    count_warn = sum(1 for s in statuses if s.status == "æ³¨æ„")
    count_normal = sum(1 for s in statuses if s.status == "æ­£å¸¸")
    
    cols = st.columns(4)
    cols[0].metric("ğŸ”´ éšœå®³ç™ºç”Ÿ", f"{count_stop}æ‹ ç‚¹", help="ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢ãƒ¬ãƒ™ãƒ«")
    cols[1].metric("ğŸŸ  è¦å¯¾å¿œ", f"{count_action}æ‹ ç‚¹", help="å†—é•·æ€§å–ªå¤±")
    cols[2].metric("ğŸŸ¡ æ³¨æ„", f"{count_warn}æ‹ ç‚¹", help="è»½å¾®ãªã‚¢ãƒ©ãƒ¼ãƒˆ")
    cols[3].metric("ğŸŸ¢ æ­£å¸¸", f"{count_normal}æ‹ ç‚¹", help="å•é¡Œãªã—")
    
    st.divider()
    
    if not statuses:
        st.info("æ‹ ç‚¹ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    cols_per_row = 2
    for i in range(0, len(statuses), cols_per_row):
        cols = st.columns(cols_per_row)
        for j, col in enumerate(cols):
            if i + j < len(statuses):
                site = statuses[i + j]
                render_site_card(col, site)


def render_site_card(col, site: SiteStatus):
    """æ‹ ç‚¹ã‚«ãƒ¼ãƒ‰ã‚’æç”»"""
    with col:
        icon = get_status_icon(site.status)
        
        with st.container(border=True):
            header_cols = st.columns([3, 1])
            with header_cols[0]:
                st.markdown(f"### {icon} {site.display_name}")
            with header_cols[1]:
                if st.button("è©³ç´°", key=f"detail_{site.site_id}", type="primary"):
                    st.session_state.active_site = site.site_id
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                    st.session_state.live_result = None
                    st.session_state.verification_result = None
                    st.session_state.generated_report = None
                    st.session_state.remediation_plan = None
                    st.session_state.messages = []
                    st.session_state.chat_session = None
                    st.rerun()
            
            if site.is_maintenance:
                st.caption("ğŸ› ï¸ ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­")
            
            scenario_display = site.scenario.split(". ", 1)[-1] if ". " in site.scenario else site.scenario
            st.caption(f"ğŸ“‹ {scenario_display}")
            
            m_cols = st.columns(3)
            m_cols[0].metric("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", site.status)
            m_cols[1].metric("ã‚¢ãƒ©ãƒ¼ãƒ ", f"{site.alarm_count}ä»¶")
            m_cols[2].metric("MTTR", site.mttr_estimate)
            
            if site.alarm_count > 0:
                # æ·±åˆ»åº¦ = CRITICAL Ã— 30 + WARNING Ã— 10ï¼ˆæœ€å¤§100%ï¼‰
                severity = min(100, site.critical_count * 30 + site.warning_count * 10)
                st.progress(severity / 100, text=f"æ·±åˆ»åº¦: {severity}%")
            
            if site.affected_devices:
                st.caption(f"å½±éŸ¿æ©Ÿå™¨: {', '.join(site.affected_devices[:3])}")


# =====================================================
# ãƒˆãƒªã‚¢ãƒ¼ã‚¸ãƒ»ã‚³ãƒãƒ³ãƒ‰ã‚»ãƒ³ã‚¿ãƒ¼
# =====================================================
def render_triage_center():
    """ãƒˆãƒªã‚¢ãƒ¼ã‚¸ãƒ»ã‚³ãƒãƒ³ãƒ‰ã‚»ãƒ³ã‚¿ãƒ¼ã‚’æç”»"""
    st.subheader("ğŸš¨ ãƒˆãƒªã‚¢ãƒ¼ã‚¸ãƒ»ã‚³ãƒãƒ³ãƒ‰ã‚»ãƒ³ã‚¿ãƒ¼")
    
    statuses = build_site_statuses()
    
    col1, col2 = st.columns(2)
    with col1:
        filter_status = st.multiselect(
            "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§ãƒ•ã‚£ãƒ«ã‚¿",
            ["åœæ­¢", "è¦å¯¾å¿œ", "æ³¨æ„", "æ­£å¸¸"],
            default=["åœæ­¢", "è¦å¯¾å¿œ"],
            key="triage_filter"
        )
    with col2:
        show_maint = st.checkbox("ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­ã‚’å«ã‚€", value=False, key="triage_maint")
    
    filtered = [
        s for s in statuses
        if s.status in filter_status
        and (show_maint or not s.is_maintenance)
    ]
    
    if not filtered:
        st.info("ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã«è©²å½“ã™ã‚‹æ‹ ç‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    for site in filtered:
        with st.container(border=True):
            cols = st.columns([0.5, 2, 1.5, 1, 1.5])
            
            with cols[0]:
                st.markdown(f"## {get_status_icon(site.status)}")
            
            with cols[1]:
                st.markdown(f"**{site.display_name}**")
                scenario_short = site.scenario.split(". ", 1)[-1][:30]
                st.caption(scenario_short)
            
            with cols[2]:
                if site.critical_count > 0:
                    st.error(f"ğŸ”´ {site.critical_count} CRITICAL")
                if site.warning_count > 0:
                    st.warning(f"ğŸŸ¡ {site.warning_count} WARNING")
            
            with cols[3]:
                st.metric("MTTR", site.mttr_estimate, label_visibility="collapsed")
            
            with cols[4]:
                btn_type = "primary" if site.status in ["åœæ­¢", "è¦å¯¾å¿œ"] else "secondary"
                if st.button("ğŸ“‹ è©³ç´°ã‚’ç¢ºèª", key=f"triage_detail_{site.site_id}", type=btn_type):
                    st.session_state.active_site = site.site_id
                    st.session_state.live_result = None
                    st.session_state.verification_result = None
                    st.session_state.generated_report = None
                    st.session_state.remediation_plan = None
                    st.session_state.messages = []
                    st.session_state.chat_session = None
                    st.rerun()


# =====================================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼
# =====================================================
def render_sidebar():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’æç”»"""
    with st.sidebar:
        st.header("âš¡ æ‹ ç‚¹ã‚·ãƒŠãƒªã‚ªè¨­å®š")
        st.caption("å„æ‹ ç‚¹ã§ç™ºç”Ÿã•ã›ã‚‹ã‚·ãƒŠãƒªã‚ªã‚’é¸æŠ")
        
        sites = list_sites()
        
        for site_id in sites:
            display_name = get_display_name(site_id)
            
            with st.expander(f"ğŸ“ {display_name}", expanded=True):
                category = st.selectbox(
                    "ã‚«ãƒ†ã‚´ãƒª",
                    list(SCENARIO_MAP.keys()),
                    key=f"cat_{site_id}",
                    label_visibility="collapsed"
                )
                
                scenarios = SCENARIO_MAP[category]
                current = st.session_state.site_scenarios.get(site_id, "æ­£å¸¸ç¨¼åƒ")
                
                default_idx = 0
                for idx, s in enumerate(scenarios):
                    if s == current or current in s:
                        default_idx = idx
                        break
                
                selected = st.radio(
                    "ã‚·ãƒŠãƒªã‚ª",
                    scenarios,
                    index=default_idx,
                    key=f"scenario_{site_id}",
                    label_visibility="collapsed"
                )
                
                # ã‚·ãƒŠãƒªã‚ªãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã€è©²å½“ã‚µã‚¤ãƒˆã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ã¿ãƒªã‚»ãƒƒãƒˆ
                if selected != current:
                    st.session_state.site_scenarios[site_id] = selected
                    # è©²å½“ã‚µã‚¤ãƒˆã®ãƒ¬ãƒãƒ¼ãƒˆé–¢é€£ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
                    keys_to_remove = [k for k in list(st.session_state.report_cache.keys()) if site_id in k]
                    for k in keys_to_remove:
                        del st.session_state.report_cache[k]
                    # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚µã‚¤ãƒˆãŒå¤‰æ›´ã•ã‚ŒãŸã‚µã‚¤ãƒˆã®å ´åˆã®ã¿ã€ãƒ¬ãƒãƒ¼ãƒˆçŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                    if st.session_state.active_site == site_id:
                        st.session_state.generated_report = None
                        st.session_state.remediation_plan = None
                        st.session_state.messages = []
                        st.session_state.chat_session = None
                        st.session_state.live_result = None
                        st.session_state.verification_result = None
                else:
                    st.session_state.site_scenarios[site_id] = selected
        
        st.divider()
        
        with st.expander("ğŸ› ï¸ ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹è¨­å®š", expanded=False):
            for site_id in sites:
                display_name = get_display_name(site_id)
                is_maint = st.checkbox(
                    display_name,
                    value=st.session_state.maint_flags.get(site_id, False),
                    key=f"maint_{site_id}"
                )
                st.session_state.maint_flags[site_id] = is_maint
        
        st.divider()
        
        api_key = None
        if GENAI_AVAILABLE:
            if "GOOGLE_API_KEY" in st.secrets:
                api_key = st.secrets["GOOGLE_API_KEY"]
            else:
                api_key = os.environ.get("GOOGLE_API_KEY")
            
            if api_key:
                st.success("âœ… API æ¥ç¶šæ¸ˆã¿")
                stats = get_rate_limiter().get_stats()
                st.caption(f"ğŸ“Š API: {stats['requests_last_minute']}/{stats['rpm_limit']} RPM")
            else:
                st.warning("âš ï¸ API Keyæœªè¨­å®š")
                user_key = st.text_input("Google API Key", type="password")
                if user_key:
                    api_key = user_key
        
        return api_key


# =====================================================
# ãƒˆãƒãƒ­ã‚¸ãƒ¼æç”»
# =====================================================
def render_topology_graph(topology: dict, alarms: List[Alarm], analysis_results: List[dict]):
    """
    ãƒˆãƒãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
    
    â–  ãƒãƒ¼ãƒ‰è‰²ã®å®šç¾©ï¼ˆæ°¸ç¶šçš„ãƒ«ãƒ¼ãƒ«ï¼‰
    | çŠ¶æ…‹ | è‰² | æ¡ä»¶ |
    |------|-----|------|
    | æ ¹æœ¬åŸå› ï¼ˆã‚µãƒ¼ãƒ“ã‚¹åœæ­¢ï¼‰ | èµ¤è‰² #ffcdd2 | ä¸¡ç³»éšœå®³ã€CRITICAL |
    | æ ¹æœ¬åŸå› ï¼ˆå†—é•·æ€§ä½ä¸‹ï¼‰ | é»„è‰² #fff9c4 | ç‰‡ç³»éšœå®³ã€WARNING |
    | ã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³ç–‘ã„ | è–„ç´«è‰² #e1bee7 | is_silent_suspect=True |
    | å½±éŸ¿ãƒ‡ãƒã‚¤ã‚¹ | ã‚°ãƒ¬ãƒ¼ #cfd8dc | is_root_cause=False & ã‚¢ãƒ©ãƒ¼ãƒ ã‚ã‚Š |
    | æ­£å¸¸ | ã‚°ãƒªãƒ¼ãƒ³ #e8f5e9 | å•é¡Œãªã— |
    """
    graph = graphviz.Digraph()
    graph.attr(rankdir='TB')
    graph.attr('node', shape='box', style='rounded,filled', fontname='Helvetica')
    
    # ã‚¢ãƒ©ãƒ¼ãƒ æƒ…å ±ã‚’ãƒ‡ãƒã‚¤ã‚¹IDã§ãƒãƒƒãƒ”ãƒ³ã‚°
    alarm_map = {}
    for a in alarms:
        if a.device_id not in alarm_map:
            alarm_map[a.device_id] = {
                'is_root_cause': False,
                'is_silent_suspect': False,
                'max_severity': 'INFO',
                'messages': []
            }
        info = alarm_map[a.device_id]
        info['messages'].append(a.message)
        if a.is_root_cause:
            info['is_root_cause'] = True
        if a.is_silent_suspect:
            info['is_silent_suspect'] = True
        # æœ€å¤§severity ã‚’æ›´æ–°
        severity_order = {'CRITICAL': 3, 'WARNING': 2, 'INFO': 1}
        if severity_order.get(a.severity, 0) > severity_order.get(info['max_severity'], 0):
            info['max_severity'] = a.severity
    
    for node_id, node in topology.items():
        if hasattr(node, 'type'):
            node_type = node.type
            metadata = node.metadata if hasattr(node, 'metadata') else {}
        else:
            node_type = node.get('type', 'UNKNOWN')
            metadata = node.get('metadata', {})
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æ­£å¸¸ï¼ˆã‚°ãƒªãƒ¼ãƒ³ï¼‰
        color = NodeColor.NORMAL
        penwidth = "1"
        fontcolor = "black"
        label = f"{node_id}\n({node_type})"
        status_label = ""
        
        red_type = metadata.get("redundancy_type")
        if red_type:
            label += f"\n[{red_type} Redundancy]"
        vendor = metadata.get("vendor")
        if vendor:
            label += f"\n[{vendor}]"
        
        # ã‚¢ãƒ©ãƒ¼ãƒ æƒ…å ±ã«åŸºã¥ã„ã¦è‰²ã‚’æ±ºå®š
        if node_id in alarm_map:
            info = alarm_map[node_id]
            
            if info['is_root_cause']:
                # æ ¹æœ¬åŸå› 
                if info['is_silent_suspect']:
                    # ã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³ç–‘ã„ï¼ˆè–„ç´«è‰²ï¼‰
                    color = NodeColor.SILENT_FAILURE
                    penwidth = "3"
                    status_label = "\n[SILENT SUSPECT]"
                elif info['max_severity'] == 'CRITICAL':
                    # ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢ãƒ¬ãƒ™ãƒ«ï¼ˆèµ¤è‰²ï¼‰
                    color = NodeColor.ROOT_CAUSE_CRITICAL
                    penwidth = "3"
                    status_label = "\n[ROOT CAUSE]"
                else:
                    # å†—é•·æ€§ä½ä¸‹ãƒ¬ãƒ™ãƒ«ï¼ˆé»„è‰²ï¼‰
                    color = NodeColor.ROOT_CAUSE_WARNING
                    penwidth = "2"
                    status_label = "\n[WARNING]"
            else:
                # å½±éŸ¿ãƒ‡ãƒã‚¤ã‚¹ï¼ˆã‚°ãƒ¬ãƒ¼ï¼‰
                color = NodeColor.UNREACHABLE
                fontcolor = "#546e7a"
                status_label = "\n[Unreachable]"
        
        label += status_label
        
        graph.node(node_id, label=label, fillcolor=color, color='black', penwidth=penwidth, fontcolor=fontcolor)
    
    for node_id, node in topology.items():
        if hasattr(node, 'parent_id'):
            parent_id = node.parent_id
        else:
            parent_id = node.get('parent_id')
        
        if parent_id:
            graph.edge(parent_id, node_id)
            parent_node = topology.get(parent_id)
            if parent_node:
                if hasattr(parent_node, 'redundancy_group'):
                    rg = parent_node.redundancy_group
                else:
                    rg = parent_node.get('redundancy_group')
                if rg:
                    for nid, n in topology.items():
                        n_rg = n.redundancy_group if hasattr(n, 'redundancy_group') else n.get('redundancy_group')
                        if n_rg == rg and nid != parent_id:
                            graph.edge(nid, node_id)
    
    return graph


# =====================================================
# ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆï¼ˆå‰å›ã®UXã‚’å®Œå…¨å¾©å…ƒï¼‰
# =====================================================
def render_incident_cockpit(site_id: str, api_key: Optional[str]):
    """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆã‚’æç”»ï¼ˆå‰å›ã®UXã‚’å®Œå…¨å¾©å…ƒï¼‰"""
    display_name = get_display_name(site_id)
    scenario = st.session_state.site_scenarios.get(site_id, "æ­£å¸¸ç¨¼åƒ")
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    col_header = st.columns([4, 1])
    with col_header[0]:
        st.markdown(f"### ğŸ›¡ï¸ AIOps ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆ")
    with col_header[1]:
        # æˆ»ã‚‹ãƒœã‚¿ãƒ³å°‚ç”¨ã®èµ¤è‰²ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆãƒãƒ¼ã‚«ãƒ¼ã§ç‰¹å®šï¼‰
        st.markdown('<span id="back-btn-marker"></span>', unsafe_allow_html=True)
        st.markdown("""
        <style>
        #back-btn-marker + div button,
        #back-btn-marker ~ div[data-testid="stButton"] button {
            background-color: #d32f2f !important;
            color: white !important;
            border: 2px solid #b71c1c !important;
            font-weight: bold !important;
            border-radius: 8px !important;
        }
        #back-btn-marker + div button:hover,
        #back-btn-marker ~ div[data-testid="stButton"] button:hover {
            background-color: #b71c1c !important;
        }
        </style>
        """, unsafe_allow_html=True)
        
        if st.button("ğŸ”™ ä¸€è¦§ã«æˆ»ã‚‹", key="back_to_list"):
            st.session_state.active_site = None
            st.rerun()
    
    # ãƒˆãƒãƒ­ã‚¸ãƒ¼èª­ã¿è¾¼ã¿
    paths = get_paths(site_id)
    topology = load_topology(paths.topology_path)
    
    if not topology:
        st.error("ãƒˆãƒãƒ­ã‚¸ãƒ¼ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    
    # ã‚¢ãƒ©ãƒ¼ãƒ ç”Ÿæˆ
    alarms = generate_alarms_for_scenario(topology, scenario)
    status = get_status_from_alarms(scenario, alarms)
    
    # LogicalRCA ã‚¨ãƒ³ã‚¸ãƒ³
    engine_key = f"engine_{site_id}"
    if engine_key not in st.session_state.logic_engines:
        st.session_state.logic_engines[engine_key] = LogicalRCA(topology)
    engine = st.session_state.logic_engines[engine_key]
    
    # åˆ†æå®Ÿè¡Œ
    if alarms:
        analysis_results = engine.analyze(alarms)
    else:
        analysis_results = [{
            "id": "SYSTEM",
            "label": "æ­£å¸¸ç¨¼åƒ",
            "prob": 0.0,
            "type": "Normal",
            "tier": 3,
            "reason": "ã‚¢ãƒ©ãƒ¼ãƒ ãªã—"
        }]
    
    # =====================================================
    # KPIãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆå…ƒã®æƒ…å ± + æ–°ã—ã„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼‰
    # =====================================================
    # æ ¹æœ¬åŸå› å€™è£œã®æ•°ã‚’è¨ˆç®—
    root_cause_alarms = [a for a in alarms if a.is_root_cause]
    downstream_alarms = [a for a in alarms if not a.is_root_cause]
    
    # ãƒã‚¤ã‚ºå‰Šæ¸›ç‡ã®è¨ˆç®—
    total_alarms = len(alarms)
    if total_alarms > 0:
        noise_reduction = ((total_alarms - len(root_cause_alarms)) / total_alarms) * 100
    else:
        noise_reduction = 0.0
    
    # è¦å¯¾å¿œã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ•°ï¼ˆæ ¹æœ¬åŸå› ã®æ•°ï¼‰
    action_required = len(set(a.device_id for a in root_cause_alarms))
    
    # --- å…ƒã®KPIãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼ˆä¸Šæ®µï¼‰ ---
    st.markdown("---")
    cols = st.columns(3)
    cols[0].metric("ğŸš¨ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", f"{get_status_icon(status)} {status}")
    cols[1].metric("ğŸ“Š ã‚¢ãƒ©ãƒ¼ãƒ æ•°", f"{len(alarms)}ä»¶")
    cols[2].metric("ğŸ¯ è¢«ç–‘ç®‡æ‰€", f"{len([r for r in analysis_results if r.get('prob', 0) > 0.5])}ä»¶")
    
    # --- æ–°ã—ã„KPIãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼ˆä¸‹æ®µï¼‰ ---
    kpi_cols = st.columns(3)
    with kpi_cols[0]:
        if noise_reduction > 90:
            delta_text = "â†‘ é«˜åŠ¹ç‡ç¨¼åƒä¸­"
            delta_color = "normal"
        elif noise_reduction > 50:
            delta_text = "â†’ é€šå¸¸ç¨¼åƒ"
            delta_color = "off"
        else:
            delta_text = "â†“ è¦ç¢ºèª"
            delta_color = "inverse"
        st.metric(
            "ğŸ“‰ ãƒã‚¤ã‚ºå‰Šæ¸›ç‡",
            f"{noise_reduction:.1f}%",
            delta=delta_text,
            delta_color=delta_color
        )
    
    with kpi_cols[1]:
        if total_alarms > 0:
            delta_text = "â†‘ æŠ‘åˆ¶æ¸ˆ"
        else:
            delta_text = "æ­£å¸¸"
        st.metric(
            "ğŸ“Š å‡¦ç†ã‚¢ãƒ©ãƒ¼ãƒ æ•°",
            f"{total_alarms}ä»¶",
            delta=delta_text
        )
    
    with kpi_cols[2]:
        if action_required > 0:
            delta_text = "â†‘ å¯¾å‡¦ãŒå¿…è¦"
            delta_color = "inverse"
        else:
            delta_text = "å•é¡Œãªã—"
            delta_color = "normal"
        st.metric(
            "ğŸš¨ è¦å¯¾å¿œã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ",
            f"{action_required}ä»¶",
            delta=delta_text,
            delta_color=delta_color
        )
    
    st.markdown("---")
    
    # =====================================================
    # æ ¹æœ¬åŸå› å€™è£œã¨ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ æ©Ÿå™¨ã®åˆ†é›¢
    # =====================================================
    # ã‚¢ãƒ©ãƒ¼ãƒ æƒ…å ±ã‚’ä½¿ã£ã¦æ ¹æœ¬åŸå› ã¨å½±éŸ¿ãƒ‡ãƒã‚¤ã‚¹ã‚’åˆ†é›¢
    root_cause_device_ids = set(a.device_id for a in alarms if a.is_root_cause)
    downstream_device_ids = set(a.device_id for a in alarms if not a.is_root_cause)
    
    root_cause_candidates = []
    downstream_devices = []
    
    for cand in analysis_results:
        device_id = cand.get('id', '')
        if device_id in root_cause_device_ids:
            root_cause_candidates.append(cand)
        elif device_id in downstream_device_ids:
            downstream_devices.append(cand)
        elif cand.get('prob', 0) > 0.5:
            # åˆ†æçµæœã‹ã‚‰ã‚‚æ ¹æœ¬åŸå› å€™è£œã‚’æŠ½å‡º
            root_cause_candidates.append(cand)
    
    # æ­£å¸¸ç¨¼åƒæ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    if not root_cause_candidates and not alarms:
        root_cause_candidates = [{
            "id": "SYSTEM",
            "label": "æ­£å¸¸ç¨¼åƒ",
            "prob": 0.0,
            "type": "Normal",
            "tier": 3,
            "reason": "ã‚¢ãƒ©ãƒ¼ãƒ ãªã—"
        }]
    
    if root_cause_candidates and downstream_devices:
        st.info(f"ğŸ“ **æ ¹æœ¬åŸå› **: {root_cause_candidates[0]['id']} â†’ å½±éŸ¿ç¯„å›²: é…ä¸‹ {len(downstream_devices)} æ©Ÿå™¨")
    
    # å€™è£œãƒ†ãƒ¼ãƒ–ãƒ«
    selected_incident_candidate = None
    target_device_id = None
    
    if root_cause_candidates:
        # ã‚¢ãƒ©ãƒ¼ãƒ ã‹ã‚‰severityã¨is_silent_suspectã‚’å–å¾—ã™ã‚‹ãƒãƒƒãƒ—ã‚’ä½œæˆ
        alarm_info_map = {}
        for a in alarms:
            if a.device_id not in alarm_info_map:
                alarm_info_map[a.device_id] = {'severity': 'INFO', 'is_silent': False}
            if a.severity == 'CRITICAL':
                alarm_info_map[a.device_id]['severity'] = 'CRITICAL'
            elif a.severity == 'WARNING' and alarm_info_map[a.device_id]['severity'] != 'CRITICAL':
                alarm_info_map[a.device_id]['severity'] = 'WARNING'
            if a.is_silent_suspect:
                alarm_info_map[a.device_id]['is_silent'] = True
        
        df_data = []
        for rank, cand in enumerate(root_cause_candidates, 1):
            prob = cand.get('prob', 0)
            cand_type = cand.get('type', 'UNKNOWN')
            device_id = cand['id']
            
            # ã‚¢ãƒ©ãƒ¼ãƒ æƒ…å ±ã‹ã‚‰ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’åˆ¤å®š
            alarm_info = alarm_info_map.get(device_id, {'severity': 'INFO', 'is_silent': False})
            
            if alarm_info['is_silent'] or "Silent" in cand_type:
                status_text = "ğŸŸ£ ã‚µã‚¤ãƒ¬ãƒ³ãƒˆç–‘ã„"
                action = "ğŸ” ä¸Šä½ç¢ºèª"
            elif alarm_info['severity'] == 'CRITICAL':
                status_text = "ğŸ”´ å±é™º (æ ¹æœ¬åŸå› )"
                action = "ğŸš€ è‡ªå‹•ä¿®å¾©ãŒå¯èƒ½"
            elif alarm_info['severity'] == 'WARNING':
                status_text = "ğŸŸ¡ è­¦å‘Š"
                action = "ğŸ” è©³ç´°èª¿æŸ»"
            elif prob > 0.6:
                status_text = "ğŸŸ¡ è¢«ç–‘ç®‡æ‰€"
                action = "ğŸ” è©³ç´°èª¿æŸ»"
            else:
                status_text = "âšª ç›£è¦–ä¸­"
                action = "ğŸ‘ï¸ é™è¦³"
            
            df_data.append({
                "é †ä½": rank,
                "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": status_text,
                "ãƒ‡ãƒã‚¤ã‚¹": device_id,
                "åŸå› ": cand.get('label', ''),
                "ç¢ºä¿¡åº¦": f"{prob*100:.0f}%",
                "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³": action,
                "_id": device_id,
                "_prob": prob
            })
        
        df = pd.DataFrame(df_data)
        
        st.markdown("#### ğŸ¯ æ ¹æœ¬åŸå› å€™è£œ")
        event = st.dataframe(
            df[["é †ä½", "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "ãƒ‡ãƒã‚¤ã‚¹", "åŸå› ", "ç¢ºä¿¡åº¦", "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"]],
            use_container_width=True,
            hide_index=True,
            selection_mode="single-row",
            on_select="rerun"
        )
        
        if event.selection and len(event.selection.rows) > 0:
            sel_row = df.iloc[event.selection.rows[0]]
            for cand in root_cause_candidates:
                if cand['id'] == sel_row['_id']:
                    selected_incident_candidate = cand
                    target_device_id = cand['id']
                    break
        elif root_cause_candidates:
            selected_incident_candidate = root_cause_candidates[0]
            target_device_id = root_cause_candidates[0]['id']
        
        # ä¸‹æµãƒ‡ãƒã‚¤ã‚¹ï¼ˆ10å°ä»¥ä¸Šã®å ´åˆã¯ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«è¡¨ç¤ºï¼‰
        if downstream_devices:
            with st.expander(f"â–¼ å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹æ©Ÿå™¨ ({len(downstream_devices)}å°) - ä¸Šæµå¾©æ—§å¾…ã¡", expanded=False):
                dd_df = pd.DataFrame([
                    {"No": i+1, "ãƒ‡ãƒã‚¤ã‚¹": d['id'], "çŠ¶æ…‹": "âš« å¿œç­”ãªã—", "å‚™è€ƒ": "ä¸Šæµå¾©æ—§å¾…ã¡"}
                    for i, d in enumerate(downstream_devices)
                ])
                # 10å°ä»¥ä¸Šã®å ´åˆã¯ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªã‚³ãƒ³ãƒ†ãƒŠå†…ã«è¡¨ç¤º
                if len(downstream_devices) >= 10:
                    with st.container(height=300):
                        st.dataframe(dd_df, use_container_width=True, hide_index=True)
                else:
                    st.dataframe(dd_df, use_container_width=True, hide_index=True)
    
    # ========================================
    # 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼ˆå‰å›ã®UXã‚’å¾©å…ƒï¼‰
    # ========================================
    col_map, col_chat = st.columns([1.2, 1])
    
    # === å·¦ã‚«ãƒ©ãƒ : ãƒˆãƒãƒ­ã‚¸ãƒ¼ & Auto-Diagnostics ===
    with col_map:
        st.subheader("ğŸŒ Network Topology")
        graph = render_topology_graph(topology, alarms, analysis_results)
        st.graphviz_chart(graph, use_container_width=True)
        
        st.markdown("---")
        st.subheader("ğŸ› ï¸ Auto-Diagnostics")
        
        if st.button("ğŸš€ è¨ºæ–­å®Ÿè¡Œ (Run Diagnostics)", type="primary"):
            if not api_key:
                st.error("API Key Required")
            else:
                with st.status("Agent Operating...", expanded=True) as status_widget:
                    st.write("ğŸ”Œ Connecting to device...")
                    target_node_obj = topology.get(target_device_id) if target_device_id else None
                    
                    res = run_diagnostic_simulation_no_llm(scenario, target_node_obj)
                    st.session_state.live_result = res
                    
                    if res["status"] == "SUCCESS":
                        st.write("âœ… Log Acquired & Sanitized.")
                        status_widget.update(label="Diagnostics Complete!", state="complete", expanded=False)
                        log_content = res.get('sanitized_log', "")
                        verification = verify_log_content(log_content)
                        st.session_state.verification_result = verification
                        st.session_state.trigger_analysis = True
                    else:
                        st.write("âŒ Connection Failed.")
                        status_widget.update(label="Diagnostics Failed", state="error")
                st.rerun()
        
        if st.session_state.live_result:
            res = st.session_state.live_result
            if res["status"] == "SUCCESS":
                st.markdown("#### ğŸ“„ Diagnostic Results")
                with st.container(border=True):
                    if st.session_state.verification_result:
                        v = st.session_state.verification_result
                        c1, c2, c3 = st.columns(3)
                        c1.metric("Ping Status", v.get('ping_status'))
                        c2.metric("Interface", v.get('interface_status'))
                        c3.metric("Hardware", v.get('hardware_status'))
                    
                    st.divider()
                    st.caption("ğŸ”’ Raw Logs (Sanitized)")
                    st.code(res["sanitized_log"], language="text")
    
    # === å³ã‚«ãƒ©ãƒ : AI Analyst Report & Remediation & Chat ===
    with col_chat:
        st.subheader("ğŸ“ AI Analyst Report")
        
        if selected_incident_candidate:
            cand = selected_incident_candidate
            
            # --- A. åŸå› åˆ†æãƒ¬ãƒãƒ¼ãƒˆ ---
            if st.session_state.generated_report is None:
                st.info(f"ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆé¸æŠä¸­: **{cand['id']}** ({cand['label']})")
                
                if api_key and scenario != "æ­£å¸¸ç¨¼åƒ":
                    if st.button("ğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ (Generate Report)"):
                        report_container = st.empty()
                        target_conf = load_config_by_id(cand['id'])
                        verification_context = cand.get("verification_log", "ç‰¹ã«ãªã—")
                        
                        t_node = topology.get(cand["id"])
                        t_node_dict = {
                            "id": getattr(t_node, "id", None) if t_node else None,
                            "type": getattr(t_node, "type", None) if t_node else None,
                            "layer": getattr(t_node, "layer", None) if t_node else None,
                            "metadata": (getattr(t_node, "metadata", {}) or {}) if t_node else {},
                        }
                        
                        parent_id = t_node.parent_id if t_node and hasattr(t_node, 'parent_id') else None
                        children_ids = [
                            nid for nid, n in topology.items()
                            if (getattr(n, "parent_id", None) if hasattr(n, 'parent_id') else n.get('parent_id')) == cand["id"]
                        ]
                        topology_context = {"node": t_node_dict, "parent_id": parent_id, "children_ids": children_ids}
                        
                        cache_key_analyst = "|".join([
                            "analyst",
                            site_id,
                            scenario,
                            str(cand.get("id")),
                            _hash_text(json.dumps(topology_context, ensure_ascii=False, sort_keys=True)),
                        ])
                        
                        if cache_key_analyst in st.session_state.report_cache:
                            full_text = st.session_state.report_cache[cache_key_analyst]
                            report_container.markdown(full_text)
                        else:
                            try:
                                report_container.write("ğŸ¤– AI åˆ†æä¸­...")
                                placeholder = report_container.empty()
                                full_text = ""
                                
                                for chunk in generate_analyst_report_streaming(
                                    scenario=scenario,
                                    target_node=t_node,
                                    topology_context=topology_context,
                                    target_conf=target_conf or "ãªã—",
                                    verification_context=verification_context,
                                    api_key=api_key,
                                    max_retries=2,
                                    backoff=3
                                ):
                                    full_text += chunk
                                    placeholder.markdown(full_text)
                                
                                if not full_text or full_text.startswith("Error"):
                                    full_text = f"âš ï¸ åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {full_text}"
                                    placeholder.markdown(full_text)
                                
                                st.session_state.report_cache[cache_key_analyst] = full_text
                            except Exception as e:
                                full_text = f"âš ï¸ åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {type(e).__name__}: {e}"
                                report_container.markdown(full_text)
                        
                        st.session_state.generated_report = full_text
            else:
                with st.container(height=400, border=True):
                    st.markdown(st.session_state.generated_report)
                if st.button("ğŸ”„ ãƒ¬ãƒãƒ¼ãƒˆå†ä½œæˆ"):
                    st.session_state.generated_report = None
                    st.rerun()
        
        # --- B. è‡ªå‹•ä¿®å¾© & ãƒãƒ£ãƒƒãƒˆ ---
        st.markdown("---")
        st.subheader("ğŸ¤– Remediation & Chat")
        
        if selected_incident_candidate and selected_incident_candidate["prob"] > 0.6:
            st.markdown(f"""
            <div style="background-color:#e8f5e9;padding:10px;border-radius:5px;border:1px solid #4caf50;color:#2e7d32;margin-bottom:10px;">
                <strong>âœ… AI Analysis Completed</strong><br>
                ç‰¹å®šã•ã‚ŒãŸåŸå›  <b>{selected_incident_candidate['id']}</b> ã«å¯¾ã™ã‚‹å¾©æ—§æ‰‹é †ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚<br>
                (ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: <span style="font-size:1.2em;font-weight:bold;">{selected_incident_candidate['prob']*100:.0f}</span>)
            </div>
            """, unsafe_allow_html=True)
            
            if st.session_state.remediation_plan is None:
                if st.button("âœ¨ ä¿®å¾©ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆ (Generate Fix)"):
                    if st.session_state.generated_report is None:
                        st.warning("å…ˆã«ã€ŒğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ (Generate Report)ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                    else:
                        remediation_container = st.empty()
                        t_node = topology.get(selected_incident_candidate["id"])
                        
                        cache_key_remediation = "|".join([
                            "remediation",
                            site_id,
                            scenario,
                            str(selected_incident_candidate.get("id")),
                            _hash_text(st.session_state.generated_report or ""),
                        ])
                        
                        if cache_key_remediation in st.session_state.report_cache:
                            remediation_text = st.session_state.report_cache[cache_key_remediation]
                            remediation_container.markdown(remediation_text)
                        else:
                            try:
                                remediation_container.write("ğŸ¤– å¾©æ—§ãƒ—ãƒ©ãƒ³ç”Ÿæˆä¸­...")
                                placeholder = remediation_container.empty()
                                remediation_text = ""
                                
                                for chunk in generate_remediation_commands_streaming(
                                    scenario=scenario,
                                    analysis_result=st.session_state.generated_report or "",
                                    target_node=t_node,
                                    api_key=api_key,
                                    max_retries=2,
                                    backoff=3
                                ):
                                    remediation_text += chunk
                                    placeholder.markdown(remediation_text)
                                
                                if not remediation_text or remediation_text.startswith("Error"):
                                    remediation_text = f"âš ï¸ å¾©æ—§ãƒ—ãƒ©ãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {remediation_text}"
                                    placeholder.markdown(remediation_text)
                                
                                st.session_state.report_cache[cache_key_remediation] = remediation_text
                            except Exception as e:
                                remediation_text = f"âš ï¸ å¾©æ—§ãƒ—ãƒ©ãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {type(e).__name__}: {e}"
                                remediation_container.markdown(remediation_text)
                        
                        st.session_state.remediation_plan = remediation_text
                        st.rerun()
            
            if st.session_state.remediation_plan is not None:
                with st.container(height=400, border=True):
                    st.info("AI Generated Recovery Procedureï¼ˆå¾©æ—§æ‰‹é †ï¼‰")
                    st.markdown(st.session_state.remediation_plan)
                
                col_exec1, col_exec2 = st.columns(2)
                
                with col_exec1:
                    if st.button("ğŸš€ ä¿®å¾©å®Ÿè¡Œ (Execute)", type="primary"):
                        if not api_key:
                            st.error("API Key Required")
                        else:
                            with st.status("Autonomic Remediation in progress...", expanded=True) as status_widget:
                                target_node_obj = topology.get(selected_incident_candidate["id"])
                                device_info = target_node_obj.metadata if target_node_obj and hasattr(target_node_obj, 'metadata') else {}
                                
                                st.write("ğŸ”„ Executing remediation steps in parallel...")
                                
                                results = run_remediation_parallel_v2(
                                    device_id=selected_incident_candidate["id"],
                                    device_info=device_info,
                                    scenario=scenario,
                                    environment=RemediationEnvironment.DEMO,
                                    timeout_per_step=30
                                )
                                
                                st.write("ğŸ“‹ Remediation steps result:")
                                
                                all_success = True
                                remediation_summary = []
                                
                                for step_name in ["Backup", "Apply", "Verify"]:
                                    result = results.get(step_name)
                                    if result:
                                        st.write(str(result))
                                        remediation_summary.append(str(result))
                                        if result.status != "success":
                                            all_success = False
                                
                                verification_log = "\n".join(remediation_summary)
                                st.session_state.verification_log = verification_log
                                
                                if all_success:
                                    st.write("âœ… All remediation steps completed successfully.")
                                    status_widget.update(label="Process Finished", state="complete", expanded=False)
                                    
                                    # å¾©æ—§æˆåŠŸãƒ•ãƒ©ã‚°ã‚’è¨­å®š
                                    st.session_state.recovered_devices[selected_incident_candidate["id"]] = True
                                    st.session_state.recovered_scenario_map[selected_incident_candidate["id"]] = scenario
                                    
                                    if not st.session_state.balloons_shown:
                                        st.balloons()
                                        st.session_state.balloons_shown = True
                                    
                                    st.success("âœ… System Recovered Successfully!")
                                else:
                                    st.write("âš ï¸ Some remediation steps failed. Please review.")
                                    status_widget.update(label="Process Finished - With Errors", state="error", expanded=True)
                
                with col_exec2:
                    if st.button("ã‚­ãƒ£ãƒ³ã‚»ãƒ«"):
                        st.session_state.remediation_plan = None
                        st.session_state.verification_log = None
                        st.rerun()
                
                if st.session_state.get("verification_log"):
                    st.markdown("#### ğŸ” Post-Fix Verification Logs")
                    st.code(st.session_state.verification_log, language="text")
        else:
            if selected_incident_candidate:
                device_id = selected_incident_candidate.get('id', '')
                score = selected_incident_candidate['prob'] * 100
                
                if device_id == "SYSTEM" and score == 0:
                    st.markdown("""
                    <div style="background-color:#e8f5e9;padding:10px;border-radius:5px;border:1px solid #4caf50;color:#2e7d32;margin-bottom:10px;">
                        <strong>âœ… æ­£å¸¸ç¨¼åƒä¸­</strong><br>
                        ç¾åœ¨ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯æ­£å¸¸ã«ç¨¼åƒã—ã¦ã„ã¾ã™ã€‚å¯¾å¿œãŒå¿…è¦ãªã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                    <div style="background-color:#fff3e0;padding:10px;border-radius:5px;border:1px solid #ff9800;color:#e65100;margin-bottom:10px;">
                        <strong>âš ï¸ ç›£è¦–ä¸­</strong><br>
                        å¯¾è±¡: <b>{device_id}</b><br>
                        (ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: {score:.0f} - 60ä»¥ä¸Šã§è‡ªå‹•ä¿®å¾©ã‚’æ¨å¥¨)
                    </div>
                    """, unsafe_allow_html=True)
        
        # --- C. Chat with AI Agent ---
        with st.expander("ğŸ’¬ Chat with AI Agent", expanded=False):
            _chat_target_id = ""
            if selected_incident_candidate:
                _chat_target_id = selected_incident_candidate.get("id", "") or ""
            if not _chat_target_id and target_device_id:
                _chat_target_id = target_device_id
            
            _chat_ci = _build_ci_context_for_chat(topology, _chat_target_id) if _chat_target_id else {}
            if _chat_ci:
                _vendor = _chat_ci.get("vendor", "") or "Unknown"
                _os = _chat_ci.get("os", "") or "Unknown"
                _model = _chat_ci.get("model", "") or "Unknown"
                st.caption(f"å¯¾è±¡æ©Ÿå™¨: {_chat_target_id}   Vendor: {_vendor}   OS: {_os}   Model: {_model}")
            
            # ã‚¯ã‚¤ãƒƒã‚¯è³ªå•ãƒœã‚¿ãƒ³
            q1, q2, q3 = st.columns(3)
            
            with q1:
                if st.button("è¨­å®šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—", use_container_width=True):
                    st.session_state.chat_quick_text = "ã“ã®æ©Ÿå™¨ã§ã€ç¾åœ¨ã®è¨­å®šã‚’å®‰å…¨ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã™ã‚‹æ‰‹é †ã¨ã‚³ãƒãƒ³ãƒ‰ä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
            with q2:
                if st.button("ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯", use_container_width=True):
                    st.session_state.chat_quick_text = "ã“ã®æ©Ÿå™¨ã§ã€å¤‰æ›´ã‚’ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹ä»£è¡¨çš„ãªæ‰‹é †ï¼ˆå€™è£œï¼‰ã¨æ³¨æ„ç‚¹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
            with q3:
                if st.button("ç¢ºèªã‚³ãƒãƒ³ãƒ‰", use_container_width=True):
                    st.session_state.chat_quick_text = "ä»Šå›ã®ç—‡çŠ¶ã‚’åˆ‡ã‚Šåˆ†ã‘ã‚‹ãŸã‚ã«ã€ã¾ãšå®Ÿè¡Œã™ã¹ãç¢ºèªã‚³ãƒãƒ³ãƒ‰ï¼ˆshow/diagnosticï¼‰ã‚’å„ªå…ˆåº¦é †ã«æ•™ãˆã¦ãã ã•ã„ã€‚"
            
            if st.session_state.chat_quick_text:
                st.info("ã‚¯ã‚¤ãƒƒã‚¯è³ªå•ï¼ˆã‚³ãƒ”ãƒ¼ã—ã¦è²¼ã‚Šä»˜ã‘ï¼‰")
                st.code(st.session_state.chat_quick_text)
            
            if st.session_state.chat_session is None and api_key and GENAI_AVAILABLE:
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel("gemma-3-12b-it")
                st.session_state.chat_session = model.start_chat(history=[])
            
            # ã‚¿ãƒ–ã§ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
            tab1, tab2 = st.tabs(["ğŸ’¬ ä¼šè©±", "ğŸ“ å±¥æ­´"])
            
            with tab1:
                if st.session_state.messages:
                    last_msg = st.session_state.messages[-1]
                    if last_msg["role"] == "assistant":
                        st.info("ğŸ¤– æœ€æ–°ã®å›ç­”")
                        with st.container(height=300):
                            st.markdown(last_msg["content"])
                
                st.markdown("---")
                prompt = st.text_area(
                    "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
                    height=70,
                    placeholder="Ctrl+Enter ã¾ãŸã¯ é€ä¿¡ãƒœã‚¿ãƒ³ã§é€ä¿¡",
                    key="chat_textarea"
                )
                
                col1, col2, col3 = st.columns([3, 1, 1])
                with col2:
                    send_button = st.button("é€ä¿¡", type="primary", use_container_width=True)
                with col3:
                    if st.button("ã‚¯ãƒªã‚¢"):
                        st.session_state.messages = []
                        st.rerun()
                
                if send_button and prompt:
                    st.session_state.messages.append({"role": "user", "content": prompt})
                    
                    if st.session_state.chat_session:
                        ci = _build_ci_context_for_chat(topology, _chat_target_id) if _chat_target_id else {}
                        ci_prompt = f"""ã‚ãªãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é‹ç”¨ï¼ˆNOC/SREï¼‰ã®å®Ÿå‹™è€…ã§ã™ã€‚
æ¬¡ã® CI æƒ…å ±ã¨ Config æŠœç²‹ã‚’å¿…ãšå‚ç…§ã—ã¦ã€å…·ä½“çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚ä¸€èˆ¬è«–ã ã‘ã§çµ‚ã‚ã‚‰ã›ãªã„ã§ãã ã•ã„ã€‚

ã€CI (JSON)ã€‘
{json.dumps(ci, ensure_ascii=False, indent=2)}

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
{prompt}

å›ç­”ãƒ«ãƒ¼ãƒ«:
- CI/Config ã«åŸºã¥ãå…·ä½“æ‰‹é †ãƒ»ã‚³ãƒãƒ³ãƒ‰ä¾‹ã‚’æç¤ºã™ã‚‹
- è¿½åŠ ç¢ºèªãŒå¿…è¦ãªã‚‰ã€è³ªå•ã¯æœ€å°é™ï¼ˆ1ã€œ2ç‚¹ï¼‰ã«çµã‚‹
- ä¸æ˜ãªå‰æã¯æ¨æ¸¬ã›ãšã€ŒCIã«ç„¡ã„ã®ã§ç¢ºèªãŒå¿…è¦ã€ã¨æ˜è¨˜ã™ã‚‹
"""
                        
                        with st.spinner("AI ãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                            try:
                                response = generate_content_with_retry(st.session_state.chat_session.model, ci_prompt, stream=False)
                                if response:
                                    full_response = response.text if hasattr(response, "text") else str(response)
                                    if not full_response.strip():
                                        full_response = "AIå¿œç­”ãŒç©ºã§ã—ãŸã€‚"
                                    st.session_state.messages.append({"role": "assistant", "content": full_response})
                                else:
                                    st.error("AIã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                            except Exception as e:
                                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        st.rerun()
            
            with tab2:
                if st.session_state.messages:
                    history_container = st.container(height=400)
                    with history_container:
                        for i, msg in enumerate(st.session_state.messages):
                            icon = "ğŸ¤–" if msg["role"] == "assistant" else "ğŸ‘¤"
                            with st.container(border=True):
                                st.markdown(f"{icon} **{msg['role'].upper()}** (ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ {i+1})")
                                st.markdown(msg["content"])
                else:
                    st.info("ä¼šè©±å±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")


# =====================================================
# ãƒ¡ã‚¤ãƒ³
# =====================================================
def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    api_key = render_sidebar()
    
    st.title("ğŸ›¡ï¸ AIOps ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆ")
    st.caption("è¤‡æ•°æ‹ ç‚¹ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯éšœå®³ã‚’çµ±åˆç®¡ç†ãƒ»åˆ†æ")
    
    active_site = st.session_state.get("active_site")
    
    if active_site:
        render_incident_cockpit(active_site, api_key)
    else:
        tab1, tab2 = st.tabs(["ğŸ“Š æ‹ ç‚¹çŠ¶æ…‹ãƒœãƒ¼ãƒ‰", "ğŸš¨ ãƒˆãƒªã‚¢ãƒ¼ã‚¸ãƒ»ã‚³ãƒãƒ³ãƒ‰ã‚»ãƒ³ã‚¿ãƒ¼"])
        
        with tab1:
            render_site_status_board()
        
        with tab2:
            render_triage_center()


if __name__ == "__main__":
    main()
