# -*- coding: utf-8 -*-
"""
AIOps Incident Cockpit - Multi-Site Edition
=============================================
è¤‡æ•°æ‹ ç‚¹å¯¾å¿œç‰ˆ AIOps ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆ
[ä¿®æ­£] é‡è¤‡ã—ã¦ã„ãŸäºˆå…†æ¤œçŸ¥ãƒãƒŠãƒ¼ã‚’å‰Šé™¤
"""

import streamlit as st
import graphviz
import os
import time
import json
import re
import hashlib
import pandas as pd
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from google.api_core import exceptions as google_exceptions

# Google Generative AI
try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¾¤ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from registry import (
    SiteRegistry,
    list_sites,
    list_networks,
    get_paths,
    load_topology,
    get_display_name,
    NetworkNode,
)
from alarm_generator import generate_alarms_for_scenario, get_alarm_summary, Alarm, NodeColor
from inference_engine import LogicalRCA
from network_ops import (
    run_diagnostic_simulation,
    generate_remediation_commands,
    generate_analyst_report_streaming,
    generate_remediation_commands_streaming,
    run_remediation_parallel_v2,
    RemediationEnvironment,
    sanitize_output,
)
from verifier import verify_log_content, format_verification_report
from rate_limiter import GlobalRateLimiter, RateLimitConfig

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(
    page_title="AIOps Incident Cockpit",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# =====================================================
# å®šæ•°å®šç¾©
# =====================================================
class ImpactLevel:
    """å½±éŸ¿åº¦ãƒ¬ãƒ™ãƒ«å®šç¾©"""
    COMPLETE_OUTAGE = 100
    CRITICAL = 90
    DEGRADED_HIGH = 80
    DEGRADED_MID = 70
    DOWNSTREAM = 50
    LOW_PRIORITY = 20

# ã‚·ãƒŠãƒªã‚ªã¨å½±éŸ¿åº¦ã®ãƒãƒƒãƒ”ãƒ³ã‚°
SCENARIO_IMPACT_MAP = {
    "æ­£å¸¸ç¨¼åƒ": 0,
    "WANå…¨å›ç·šæ–­": ImpactLevel.COMPLETE_OUTAGE,
    "[WAN] é›»æºéšœå®³ï¼šä¸¡ç³»": ImpactLevel.COMPLETE_OUTAGE,
    "[L2SW] é›»æºéšœå®³ï¼šä¸¡ç³»": ImpactLevel.COMPLETE_OUTAGE,
    "[Core] ä¸¡ç³»æ•…éšœ": ImpactLevel.CRITICAL,
    "[FW] é›»æºéšœå®³ï¼šä¸¡ç³»": ImpactLevel.CRITICAL,
    "[FW] é›»æºéšœå®³ï¼šç‰‡ç³»": ImpactLevel.DEGRADED_HIGH,
    "FWç‰‡ç³»éšœå®³": ImpactLevel.DEGRADED_HIGH,
    "[WAN] é›»æºéšœå®³ï¼šç‰‡ç³»": ImpactLevel.DEGRADED_MID,
    "[L2SW] é›»æºéšœå®³ï¼šç‰‡ç³»": ImpactLevel.DEGRADED_MID,
    "L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³": ImpactLevel.DEGRADED_HIGH,
    "[WAN] BGPãƒ«ãƒ¼ãƒˆãƒ•ãƒ©ãƒƒãƒ”ãƒ³ã‚°": ImpactLevel.DEGRADED_HIGH,
    "[WAN] FANæ•…éšœ": ImpactLevel.DEGRADED_MID,
    "[FW] FANæ•…éšœ": ImpactLevel.DEGRADED_MID,
    "[L2SW] FANæ•…éšœ": ImpactLevel.DEGRADED_MID,
    "[WAN] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯": ImpactLevel.DEGRADED_MID,
    "[FW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯": ImpactLevel.DEGRADED_MID,
    "[L2SW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯": ImpactLevel.DEGRADED_MID,
    "[WAN] è¤‡åˆéšœå®³ï¼šé›»æºï¼†FAN": ImpactLevel.DEGRADED_HIGH,
    "[Complex] åŒæ™‚å¤šç™ºï¼šFW & AP": ImpactLevel.DEGRADED_HIGH,
}

# ã‚·ãƒŠãƒªã‚ªã‚«ãƒ†ã‚´ãƒª
SCENARIO_MAP = {
    "åŸºæœ¬ãƒ»åºƒåŸŸéšœå®³": [
        "æ­£å¸¸ç¨¼åƒ",
        "1. WANå…¨å›ç·šæ–­",
        "2. FWç‰‡ç³»éšœå®³",
        "3. L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³"
    ],
    "WAN Router": [
        "4. [WAN] é›»æºéšœå®³ï¼šç‰‡ç³»",
        "5. [WAN] é›»æºéšœå®³ï¼šä¸¡ç³»",
        "6. [WAN] BGPãƒ«ãƒ¼ãƒˆãƒ•ãƒ©ãƒƒãƒ”ãƒ³ã‚°",
        "7. [WAN] FANæ•…éšœ",
        "8. [WAN] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"
    ],
    "Firewall": [
        "9. [FW] é›»æºéšœå®³ï¼šç‰‡ç³»",
        "10. [FW] é›»æºéšœå®³ï¼šä¸¡ç³»",
        "11. [FW] FANæ•…éšœ",
        "12. [FW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"
    ],
    "L2 Switch": [
        "13. [L2SW] é›»æºéšœå®³ï¼šç‰‡ç³»",
        "14. [L2SW] é›»æºéšœå®³ï¼šä¸¡ç³»",
        "15. [L2SW] FANæ•…éšœ",
        "16. [L2SW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"
    ],
    "è¤‡åˆãƒ»ãã®ä»–": [
        "17. [WAN] è¤‡åˆéšœå®³ï¼šé›»æºï¼†FAN",
        "18. [Complex] åŒæ™‚å¤šç™ºï¼šFW & AP"
    ]
}


# =====================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =====================================================
def get_scenario_impact_level(scenario: str) -> int:
    """ã‚·ãƒŠãƒªã‚ªã®å½±éŸ¿åº¦ã‚’å–å¾—"""
    for key, value in SCENARIO_IMPACT_MAP.items():
        if key in scenario:
            return value
    return ImpactLevel.DEGRADED_MID


def get_status_from_alarms(scenario: str, alarms: List[Alarm]) -> str:
    """ã‚¢ãƒ©ãƒ¼ãƒ ã‹ã‚‰ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’åˆ¤å®š"""
    if not alarms:
        return "æ­£å¸¸"
    
    impact = get_scenario_impact_level(scenario)
    
    if impact >= ImpactLevel.COMPLETE_OUTAGE:
        return "åœæ­¢"
    elif impact >= ImpactLevel.DEGRADED_HIGH:
        return "è¦å¯¾å¿œ"
    elif impact >= ImpactLevel.DEGRADED_MID:
        if any(a.severity == "CRITICAL" for a in alarms):
            return "è¦å¯¾å¿œ"
        return "æ³¨æ„"
    elif impact >= ImpactLevel.DOWNSTREAM:
        return "æ³¨æ„"
    else:
        return "æ­£å¸¸"


def get_status_color(status: str) -> str:
    """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«å¯¾å¿œã™ã‚‹è‰²ã‚’å–å¾—"""
    return {
        "åœæ­¢": "#d32f2f",
        "è¦å¯¾å¿œ": "#f57c00",
        "æ³¨æ„": "#fbc02d",
        "æ­£å¸¸": "#4caf50"
    }.get(status, "#9e9e9e")


def get_status_icon(status: str) -> str:
    """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«å¯¾å¿œã™ã‚‹ã‚¢ã‚¤ã‚³ãƒ³ã‚’å–å¾—"""
    return {
        "åœæ­¢": "ğŸ”´",
        "è¦å¯¾å¿œ": "ğŸŸ ",
        "æ³¨æ„": "ğŸŸ¡",
        "æ­£å¸¸": "ğŸŸ¢"
    }.get(status, "âšª")


def _hash_text(text: str) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—"""
    return hashlib.sha256((text or "").encode("utf-8")).hexdigest()[:16]


def load_config_by_id(device_id: str) -> str:
    """configsãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    possible_paths = [f"configs/{device_id}.txt", f"{device_id}.txt"]
    for path in possible_paths:
        if os.path.exists(path):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    return f.read()
            except Exception:
                pass
    return "Config file not found."


@st.cache_resource
def get_rate_limiter():
    """ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒã‚¿ãƒ¼ã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³"""
    return GlobalRateLimiter(RateLimitConfig(rpm=30, rpd=14400, safety_margin=0.9))


def generate_content_with_retry(model, prompt, stream=True, retries=3):
    """ãƒªãƒˆãƒ©ã‚¤ä»˜ãã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ"""
    limiter = get_rate_limiter()
    for i in range(retries):
        try:
            if not limiter.wait_for_slot(timeout=60):
                raise RuntimeError("Rate limit timeout")
            limiter.record_request()
            return model.generate_content(prompt, stream=stream)
        except google_exceptions.ServiceUnavailable:
            if i == retries - 1:
                raise
            time.sleep(2 * (i + 1))
    return None


def _pick_first(mapping: dict, keys: list, default: str = "") -> str:
    """ãƒãƒƒãƒ”ãƒ³ã‚°ã‹ã‚‰æœ€åˆã®éç©ºå€¤ã‚’å–å¾—"""
    for k in keys:
        try:
            v = mapping.get(k, None)
        except Exception:
            v = None
        if v is None:
            continue
        if isinstance(v, (int, float, bool)):
            s = str(v)
            if s:
                return s
        elif isinstance(v, str):
            if v.strip():
                return v.strip()
    return default


def _build_ci_context_for_chat(topology: dict, target_node_id: str) -> dict:
    """ãƒãƒ£ãƒƒãƒˆç”¨ã®CIã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰"""
    node = topology.get(target_node_id) if target_node_id else None
    if node:
        if hasattr(node, 'metadata'):
            md = node.metadata or {}
        else:
            md = node.get('metadata', {}) if isinstance(node, dict) else {}
    else:
        md = {}

    ci = {
        "device_id": target_node_id or "",
        "hostname": _pick_first(md, ["hostname", "host", "name"], default=(target_node_id or "")),
        "vendor": _pick_first(md, ["vendor", "manufacturer", "maker", "brand"], default=""),
        "os": _pick_first(md, ["os", "platform", "os_name", "software", "sw"], default=""),
        "model": _pick_first(md, ["model", "hw_model", "product", "sku"], default=""),
        "role": _pick_first(md, ["role", "type", "device_role"], default=""),
        "layer": _pick_first(md, ["layer", "level", "network_layer"], default=""),
        "site": _pick_first(md, ["site", "dc", "datacenter", "location"], default=""),
    }

    try:
        conf = load_config_by_id(target_node_id) if target_node_id else ""
        if conf:
            ci["config_excerpt"] = conf[:1500]
    except Exception:
        pass

    return ci


def run_diagnostic_simulation_no_llm(selected_scenario: str, target_node_obj) -> dict:
    """LLMã‚’å‘¼ã°ãªã„ç–‘ä¼¼è¨ºæ–­"""
    device_id = getattr(target_node_obj, "id", "UNKNOWN") if target_node_obj else "UNKNOWN"
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    lines = [
        f"[PROBE] ts={ts}",
        f"[PROBE] scenario={selected_scenario}",
        f"[PROBE] target_device={device_id}",
        "",
    ]

    # å¾©æ—§æˆåŠŸãƒ•ãƒ©ã‚°ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰
    recovered_devices = st.session_state.get("recovered_devices") or {}
    recovered_map = st.session_state.get("recovered_scenario_map") or {}

    if recovered_devices.get(device_id) and recovered_map.get(device_id) == selected_scenario:
        # å¾©æ—§å¾Œã®ç–‘ä¼¼ãƒ­ã‚°
        if "FW" in selected_scenario:
            lines += [
                "show chassis cluster status",
                "Redundancy group 0: healthy",
                "control link: up",
                "fabric link: up",
            ]
        elif "WAN" in selected_scenario or "WANå…¨å›ç·šæ–­" in selected_scenario:
            lines += [
                "show ip interface brief",
                "GigabitEthernet0/0 up up",
                "show ip bgp summary",
                "Neighbor 203.0.113.2 Established",
                "ping 203.0.113.2 repeat 5",
                "Success rate is 100 percent (5/5)",
            ]
        elif "L2SW" in selected_scenario:
            lines += [
                "show environment",
                "Fan: OK",
                "Temperature: OK",
                "show interface status",
                "Uplink: up",
            ]
        else:
            lines += [
                "show system alarms",
                "No active alarms",
                "ping 8.8.8.8 repeat 5",
                "Success rate is 100 percent (5/5)",
            ]
        return {
            "status": "SUCCESS",
            "sanitized_log": "\n".join(lines),
            "device_id": device_id,
        }

    # éšœå®³ä¸­ã®ç–‘ä¼¼ãƒ­ã‚°
    if "WANå…¨å›ç·šæ–­" in selected_scenario or "[WAN]" in selected_scenario:
        lines += [
            "show ip interface brief",
            "GigabitEthernet0/0 down down",
            "show ip bgp summary",
            "Neighbor 203.0.113.2 Idle",
            "ping 203.0.113.2 repeat 5",
            "Success rate is 0 percent (0/5)",
        ]
    elif "FWç‰‡ç³»éšœå®³" in selected_scenario or "[FW]" in selected_scenario:
        lines += [
            "show chassis cluster status",
            "Redundancy group 0: degraded",
            "control link: down",
            "fabric link: up",
        ]
    elif "L2SW" in selected_scenario:
        lines += [
            "show environment",
            "Fan: FAIL",
            "Temperature: HIGH",
            "show interface status",
            "Uplink: flapping",
        ]
    else:
        lines += [
            "show system alarms",
            "No active alarms",
        ]

    return {
        "status": "SUCCESS",
        "sanitized_log": "\n".join(lines),
        "device_id": device_id,
    }


# =====================================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
# =====================================================
def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
    defaults = {
        # æ‹ ç‚¹åˆ¥ã‚·ãƒŠãƒªã‚ª
        "site_scenarios": {},
        # é¸æŠä¸­ã®æ‹ ç‚¹
        "active_site": None,
        # ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ•ãƒ©ã‚°
        "maint_flags": {},
        # åˆ†æçµæœ
        "live_result": None,
        "verification_result": None,
        "generated_report": None,
        "remediation_plan": None,
        "verification_log": None,
        # ãƒãƒ£ãƒƒãƒˆ
        "messages": [],
        "chat_session": None,
        "chat_quick_text": "",
        # ãã®ä»–
        "trigger_analysis": False,
        "logic_engines": {},
        "balloons_shown": False,
        "recovered_devices": {},
        "recovered_scenario_map": {},
        "report_cache": {},
        "injected_weak_signal": None,
    }
    
    for key, default in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default


init_session_state()


# =====================================================
# æ‹ ç‚¹çŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰
# =====================================================
@dataclass
class SiteStatus:
    """æ‹ ç‚¹ã®çŠ¶æ…‹æƒ…å ±"""
    site_id: str
    display_name: str
    scenario: str
    status: str
    alarm_count: int
    critical_count: int
    warning_count: int
    affected_devices: List[str]
    is_maintenance: bool
    mttr_estimate: str


def build_site_statuses() -> List[SiteStatus]:
    """å…¨æ‹ ç‚¹ã®çŠ¶æ…‹ã‚’æ§‹ç¯‰"""
    sites = list_sites()
    statuses = []
    
    for site_id in sites:
        scenario = st.session_state.site_scenarios.get(site_id, "æ­£å¸¸ç¨¼åƒ")
        paths = get_paths(site_id)
        topology = load_topology(paths.topology_path)
        alarms = generate_alarms_for_scenario(topology, scenario)
        summary = get_alarm_summary(alarms)
        status = get_status_from_alarms(scenario, alarms)
        is_maint = st.session_state.maint_flags.get(site_id, False)
        
        if status in ["åœæ­¢", "è¦å¯¾å¿œ"]:
            mttr = f"{30 + summary['total'] * 5}åˆ†"
        else:
            mttr = "-"
        
        statuses.append(SiteStatus(
            site_id=site_id,
            display_name=get_display_name(site_id),
            scenario=scenario,
            status=status,
            alarm_count=summary['total'],
            critical_count=summary['critical'],
            warning_count=summary['warning'],
            affected_devices=summary['devices'],
            is_maintenance=is_maint,
            mttr_estimate=mttr
        ))
    
    priority = {"åœæ­¢": 0, "è¦å¯¾å¿œ": 1, "æ³¨æ„": 2, "æ­£å¸¸": 3}
    statuses.sort(key=lambda s: (priority.get(s.status, 4), -s.alarm_count))
    
    return statuses


# =====================================================
# æ‹ ç‚¹çŠ¶æ…‹ãƒœãƒ¼ãƒ‰ã®æç”»
# =====================================================
def render_site_status_board():
    """æ‹ ç‚¹çŠ¶æ…‹ãƒœãƒ¼ãƒ‰ã‚’æç”»"""
    st.subheader("ğŸ¢ æ‹ ç‚¹çŠ¶æ…‹ãƒœãƒ¼ãƒ‰")
    
    statuses = build_site_statuses()
    
    count_stop = sum(1 for s in statuses if s.status == "åœæ­¢")
    count_action = sum(1 for s in statuses if s.status == "è¦å¯¾å¿œ")
    count_warn = sum(1 for s in statuses if s.status == "æ³¨æ„")
    count_normal = sum(1 for s in statuses if s.status == "æ­£å¸¸")
    
    cols = st.columns(4)
    cols[0].metric("ğŸ”´ éšœå®³ç™ºç”Ÿ", f"{count_stop}æ‹ ç‚¹", help="ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢ãƒ¬ãƒ™ãƒ«")
    cols[1].metric("ğŸŸ  è¦å¯¾å¿œ", f"{count_action}æ‹ ç‚¹", help="å†—é•·æ€§å–ªå¤±")
    cols[2].metric("ğŸŸ¡ æ³¨æ„", f"{count_warn}æ‹ ç‚¹", help="è»½å¾®ãªã‚¢ãƒ©ãƒ¼ãƒˆ")
    cols[3].metric("ğŸŸ¢ æ­£å¸¸", f"{count_normal}æ‹ ç‚¹", help="å•é¡Œãªã—")
    
    st.divider()
    
    if not statuses:
        st.info("æ‹ ç‚¹ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
    
    cols_per_row = 2
    for i in range(0, len(statuses), cols_per_row):
        cols = st.columns(cols_per_row)
        for j, col in enumerate(cols):
            if i + j < len(statuses):
                site = statuses[i + j]
                render_site_card(col, site)


def render_site_card(col, site: SiteStatus):
    """æ‹ ç‚¹ã‚«ãƒ¼ãƒ‰ã‚’æç”»"""
    with col:
        icon = get_status_icon(site.status)
        
        with st.container(border=True):
            header_cols = st.columns([3, 1])
            with header_cols[0]:
                st.markdown(f"### {icon} {site.display_name}")
            with header_cols[1]:
                if st.button("è©³ç´°", key=f"detail_{site.site_id}", type="primary"):
                    st.session_state.active_site = site.site_id
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                    st.session_state.live_result = None
                    st.session_state.verification_result = None
                    st.session_state.generated_report = None
                    st.session_state.remediation_plan = None
                    st.session_state.messages = []
                    st.session_state.chat_session = None
                    st.rerun()
            
            if site.is_maintenance:
                st.caption("ğŸ› ï¸ ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­")
            
            scenario_display = site.scenario.split(". ", 1)[-1] if ". " in site.scenario else site.scenario
            st.caption(f"ğŸ“‹ {scenario_display}")
            
            m_cols = st.columns(3)
            m_cols[0].metric("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", site.status)
            m_cols[1].metric("ã‚¢ãƒ©ãƒ¼ãƒ ", f"{site.alarm_count}ä»¶")
            m_cols[2].metric("MTTR", site.mttr_estimate)
            
            if site.alarm_count > 0:
                # æ·±åˆ»åº¦ = CRITICAL Ã— 30 + WARNING Ã— 10ï¼ˆæœ€å¤§100%ï¼‰
                severity = min(100, site.critical_count * 30 + site.warning_count * 10)
                st.progress(severity / 100, text=f"æ·±åˆ»åº¦: {severity}%")
            
            if site.affected_devices:
                st.caption(f"å½±éŸ¿æ©Ÿå™¨: {', '.join(site.affected_devices[:3])}")


# =====================================================
# ãƒˆãƒªã‚¢ãƒ¼ã‚¸ãƒ»ã‚³ãƒãƒ³ãƒ‰ã‚»ãƒ³ã‚¿ãƒ¼
# =====================================================
def render_triage_center():
    """ãƒˆãƒªã‚¢ãƒ¼ã‚¸ãƒ»ã‚³ãƒãƒ³ãƒ‰ã‚»ãƒ³ã‚¿ãƒ¼ã‚’æç”»"""
    st.subheader("ğŸš¨ ãƒˆãƒªã‚¢ãƒ¼ã‚¸ãƒ»ã‚³ãƒãƒ³ãƒ‰ã‚»ãƒ³ã‚¿ãƒ¼")
    
    statuses = build_site_statuses()
    
    col1, col2 = st.columns(2)
    with col1:
        filter_status = st.multiselect(
            "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§ãƒ•ã‚£ãƒ«ã‚¿",
            ["åœæ­¢", "è¦å¯¾å¿œ", "æ³¨æ„", "æ­£å¸¸"],
            default=["åœæ­¢", "è¦å¯¾å¿œ"],
            key="triage_filter"
        )
    with col2:
        show_maint = st.checkbox("ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­ã‚’å«ã‚€", value=False, key="triage_maint")
    
    filtered = [
        s for s in statuses
        if s.status in filter_status
        and (show_maint or not s.is_maintenance)
    ]
    
    if not filtered:
        st.info("ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã«è©²å½“ã™ã‚‹æ‹ ç‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    for site in filtered:
        with st.container(border=True):
            cols = st.columns([0.5, 2, 1.5, 1, 1.5])
            
            with cols[0]:
                st.markdown(f"## {get_status_icon(site.status)}")
            
            with cols[1]:
                st.markdown(f"**{site.display_name}**")
                scenario_short = site.scenario.split(". ", 1)[-1][:30]
                st.caption(scenario_short)
            
            with cols[2]:
                if site.critical_count > 0:
                    st.error(f"ğŸ”´ {site.critical_count} CRITICAL")
                if site.warning_count > 0:
                    st.warning(f"ğŸŸ¡ {site.warning_count} WARNING")
            
            with cols[3]:
                st.metric("MTTR", site.mttr_estimate, label_visibility="collapsed")
            
            with cols[4]:
                btn_type = "primary" if site.status in ["åœæ­¢", "è¦å¯¾å¿œ"] else "secondary"
                if st.button("ğŸ“‹ è©³ç´°ã‚’ç¢ºèª", key=f"triage_detail_{site.site_id}", type=btn_type):
                    st.session_state.active_site = site.site_id
                    st.session_state.live_result = None
                    st.session_state.verification_result = None
                    st.session_state.generated_report = None
                    st.session_state.remediation_plan = None
                    st.session_state.messages = []
                    st.session_state.chat_session = None
                    st.rerun()


# =====================================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼
# =====================================================
def render_sidebar():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’æç”»"""
    with st.sidebar:
        st.header("âš¡ æ‹ ç‚¹ã‚·ãƒŠãƒªã‚ªè¨­å®š")
        st.caption("å„æ‹ ç‚¹ã§ç™ºç”Ÿã•ã›ã‚‹ã‚·ãƒŠãƒªã‚ªã‚’é¸æŠ")
        
        sites = list_sites()
        
        for site_id in sites:
            display_name = get_display_name(site_id)
            
            with st.expander(f"ğŸ“ {display_name}", expanded=True):
                category = st.selectbox(
                    "ã‚«ãƒ†ã‚´ãƒª",
                    list(SCENARIO_MAP.keys()),
                    key=f"cat_{site_id}",
                    label_visibility="collapsed"
                )
                
                scenarios = SCENARIO_MAP[category]
                current = st.session_state.site_scenarios.get(site_id, "æ­£å¸¸ç¨¼åƒ")
                
                default_idx = 0
                for idx, s in enumerate(scenarios):
                    if s == current or current in s:
                        default_idx = idx
                        break
                
                selected = st.radio(
                    "ã‚·ãƒŠãƒªã‚ª",
                    scenarios,
                    index=default_idx,
                    key=f"scenario_{site_id}",
                    label_visibility="collapsed"
                )
                
                # ã‚·ãƒŠãƒªã‚ªãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã€è©²å½“ã‚µã‚¤ãƒˆã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®ã¿ãƒªã‚»ãƒƒãƒˆ
                if selected != current:
                    st.session_state.site_scenarios[site_id] = selected
                    # è©²å½“ã‚µã‚¤ãƒˆã®ãƒ¬ãƒãƒ¼ãƒˆé–¢é€£ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
                    keys_to_remove = [k for k in list(st.session_state.report_cache.keys()) if site_id in k]
                    for k in keys_to_remove:
                        del st.session_state.report_cache[k]
                    # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚µã‚¤ãƒˆãŒå¤‰æ›´ã•ã‚ŒãŸã‚µã‚¤ãƒˆã®å ´åˆã®ã¿ã€ãƒ¬ãƒãƒ¼ãƒˆçŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                    if st.session_state.active_site == site_id:
                        st.session_state.generated_report = None
                        st.session_state.remediation_plan = None
                        st.session_state.messages = []
                        st.session_state.chat_session = None
                        st.session_state.live_result = None
                        st.session_state.verification_result = None
                else:
                    st.session_state.site_scenarios[site_id] = selected
        
        st.divider()
        
        with st.expander("ğŸ› ï¸ ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹è¨­å®š", expanded=False):
            for site_id in sites:
                display_name = get_display_name(site_id)
                is_maint = st.checkbox(
                    display_name,
                    value=st.session_state.maint_flags.get(site_id, False),
                    key=f"maint_{site_id}"
                )
                st.session_state.maint_flags[site_id] = is_maint
        
        st.divider()
        
        # â˜…â˜…â˜… äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆWeak Signal Injectionï¼‰ â˜…â˜…â˜…
        with st.expander("ğŸ”® äºˆå…†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", expanded=True):
            st.caption("æ­£å¸¸ç¨¼åƒä¸­ã®æ©Ÿå™¨ã«å¾®ç´°ãªã‚·ã‚°ãƒŠãƒ«ã‚’æ³¨å…¥ã—ã€AIã«ã‚ˆã‚‹äºˆå…†æ¤œçŸ¥ã‚’ãƒ‡ãƒ¢ã—ã¾ã™ã€‚")
            
            # â˜… æ”¹å–„1: ãƒˆãƒãƒ­ã‚¸ãƒ¼ã‹ã‚‰å‹•çš„ã«ãƒ‡ãƒã‚¤ã‚¹ãƒªã‚¹ãƒˆç”Ÿæˆ
            # é…ä¸‹ã‚’æŒã¤æ©Ÿå™¨ã®ã¿ï¼ˆAPç­‰ã®æœ«ç«¯ã¯å½±éŸ¿ä¼æ¬ã—ãªã„ãŸã‚é™¤å¤–ï¼‰
            active = st.session_state.get("active_site")
            device_options = []
            try:
                site_for_list = active if active else list_sites()[0] if list_sites() else None
                if site_for_list:
                    paths = get_paths(site_for_list)
                    topo = load_topology(paths.topology_path)
                    if topo:
                        # å„ãƒ‡ãƒã‚¤ã‚¹ã®é…ä¸‹æ•°ã‚’è¨ˆç®—
                        child_count = {}
                        for dev_id, info in topo.items():
                            pid = info.parent_id if hasattr(info, 'parent_id') else info.get('parent_id')
                            if pid:
                                child_count[pid] = child_count.get(pid, 0) + 1
                        # é…ä¸‹ã‚’æŒã¤ãƒ‡ãƒã‚¤ã‚¹ã®ã¿ãƒªã‚¹ãƒˆï¼ˆå½±éŸ¿ä¼æ¬ã™ã‚‹æ©Ÿå™¨ï¼‰
                        for dev_id, info in topo.items():
                            if child_count.get(dev_id, 0) > 0:
                                dtype = info.type if hasattr(info, 'type') else info.get('type', '')
                                layer = info.layer if hasattr(info, 'layer') else info.get('layer', 0)
                                rg = info.redundancy_group if hasattr(info, 'redundancy_group') else info.get('redundancy_group')
                                n_children = child_count.get(dev_id, 0)
                                tag = "âš SPOF" if not rg else "HA"
                                device_options.append((dev_id, f"L{layer} {dev_id} ({dtype}) [{tag}, é…ä¸‹{n_children}å°]"))
                        # layer é † â†’ SPOF å„ªå…ˆã§ã‚½ãƒ¼ãƒˆ
                        device_options.sort(key=lambda x: x[1])
            except Exception:
                pass
            
            if not device_options:
                device_options = [("WAN_ROUTER_01", "WAN_ROUTER_01")]
            
            target_device = st.selectbox(
                "å¯¾è±¡ãƒ‡ãƒã‚¤ã‚¹",
                [d[0] for d in device_options],
                format_func=lambda x: next((d[1] for d in device_options if d[0] == x), x),
                key="pred_target"
            )
            
            scenario_type = st.selectbox(
                "åŠ£åŒ–ã‚·ãƒŠãƒªã‚ª",
                ["Optical Decay (å…‰æ¸›è¡°)", "Microburst (ãƒ‘ã‚±ãƒƒãƒˆç ´æ£„)", "Route Instability (çµŒè·¯æºã‚‰ã)"],
                key="pred_scenario"
            )
            
            degradation_level = st.slider(
                "åŠ£åŒ–é€²è¡Œåº¦",
                min_value=0, max_value=5, value=0,
                help="0:æ­£å¸¸ â†’ 5:éšœå®³ç™ºç”Ÿç›´å‰ã€‚ãƒ¬ãƒ™ãƒ«ãŒä¸ŠãŒã‚‹ã¨ç›¸é–¢ã‚·ã‚°ãƒŠãƒ«ãŒå¢—åŠ ã—ã€äºˆæ¸¬ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™ã€‚",
                key="pred_level"
            )
            
            # â˜… æ”¹å–„2: å¤šæ®µã‚·ã‚°ãƒŠãƒ«æ³¨å…¥ï¼ˆãƒ¬ãƒ™ãƒ«ã«å¿œã˜ã¦ç›¸é–¢ãƒ­ã‚°ãŒå¢—åŠ ï¼‰
            # è«–æ–‡ã®è¨­è¨ˆ: è¤‡æ•°ã®å¾®å¼±ã‚·ã‚°ãƒŠãƒ«ã®ç›¸é–¢ã‹ã‚‰éšœå®³ç¢ºç‡ã‚’é«˜ã‚ã‚‹
            log_messages = []
            if degradation_level > 0:
                if "Optical" in scenario_type:
                    dbm = -23.0 - (degradation_level * 0.4)
                    # ãƒ¬ãƒ™ãƒ«1: å…‰æ¸›è¡°ã®åˆæœŸå…†å€™
                    log_messages.append(
                        f"%TRANSCEIVER-4-THRESHOLD_VIOLATION: Rx Power {dbm:.1f} dBm (Threshold -25.0 dBm). Signal degrading."
                    )
                    if degradation_level >= 2:
                        # ãƒ¬ãƒ™ãƒ«2: CRCã‚¨ãƒ©ãƒ¼å¢—åŠ ï¼ˆå…‰åŠ£åŒ–ã®äºŒæ¬¡ç—‡çŠ¶ï¼‰
                        crc = degradation_level * 150
                        log_messages.append(
                            f"%LINK-3-ERROR: CRC errors increasing on Gi0/0/0 (Count: {crc}/min). Input queue drops detected."
                        )
                    if degradation_level >= 4:
                        # ãƒ¬ãƒ™ãƒ«4: éš£æ¥æ©Ÿå™¨ã‹ã‚‰ã® keepalive é…å»¶
                        log_messages.append(
                            "%OSPF-4-ADJCHANGE: Neighbor keepalive delayed (3 consecutive misses). Stability warning."
                        )
                
                elif "Microburst" in scenario_type:
                    drops = degradation_level * 200
                    log_messages.append(
                        f"%HARDWARE-3-ASIC_ERROR: Input queue drops detected (Count: {drops}). Burst traffic."
                    )
                    if degradation_level >= 2:
                        log_messages.append(
                            f"%QOS-4-POLICER: Traffic exceeding CIR on interface ge-0/0/1. Buffer overflow risk."
                        )
                    if degradation_level >= 4:
                        retrans = degradation_level * 50
                        log_messages.append(
                            f"%TCP-5-RETRANSMIT: Retransmission rate {retrans}/sec on monitored flows. Route updates increasing."
                        )
                
                elif "Route" in scenario_type:
                    updates = degradation_level * 500
                    log_messages.append(
                        f"BGP-5-ADJCHANGE: Route updates {updates}/min. Stability warning."
                    )
                    if degradation_level >= 2:
                        log_messages.append(
                            f"%BGP-4-MAXPFX: Prefix count approaching limit (92%). Route oscillation detected."
                        )
                    if degradation_level >= 4:
                        log_messages.append(
                            "%ROUTING-3-CONVERGENCE: RIB convergence delayed. Prefix withdrawal detected on multiple peers."
                        )
            
            if log_messages:
                st.session_state["injected_weak_signal"] = {
                    "device_id": target_device,
                    "messages": log_messages,  # â˜… è¤‡æ•°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¤‰æ›´
                    "message": log_messages[0],  # å¾Œæ–¹äº’æ›
                    "level": degradation_level,
                    "scenario": scenario_type,
                }
                # æ³¨å…¥ä¸­ã®ã‚·ã‚°ãƒŠãƒ«è¡¨ç¤º
                st.info(f"ğŸ’‰ **{len(log_messages)}ä»¶ã®ã‚·ã‚°ãƒŠãƒ«æ³¨å…¥ä¸­** (Level {degradation_level}/5)")
                for i, msg in enumerate(log_messages, 1):
                    st.caption(f"  {i}. `{msg[:70]}...`" if len(msg) > 70 else f"  {i}. `{msg}`")
            else:
                st.session_state["injected_weak_signal"] = None
        
        api_key = None
        if GENAI_AVAILABLE:
            if "GOOGLE_API_KEY" in st.secrets:
                api_key = st.secrets["GOOGLE_API_KEY"]
            else:
                api_key = os.environ.get("GOOGLE_API_KEY")
            
            if api_key:
                st.success("âœ… API æ¥ç¶šæ¸ˆã¿")
                stats = get_rate_limiter().get_stats()
                st.caption(f"ğŸ“Š API: {stats['requests_last_minute']}/{stats['rpm_limit']} RPM")
            else:
                st.warning("âš ï¸ API Keyæœªè¨­å®š")
                user_key = st.text_input("Google API Key", type="password")
                if user_key:
                    api_key = user_key
        
        return api_key


# =====================================================
# ãƒˆãƒãƒ­ã‚¸ãƒ¼æç”»
# =====================================================
def render_topology_graph(topology: dict, alarms: List[Alarm], analysis_results: List[dict]):
    """
    ãƒˆãƒãƒ­ã‚¸ãƒ¼ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
    """
    graph = graphviz.Digraph()
    graph.attr(rankdir='TB')
    graph.attr('node', shape='box', style='rounded,filled', fontname='Helvetica')
    
    # ã‚¢ãƒ©ãƒ¼ãƒ æƒ…å ±ã‚’ãƒ‡ãƒã‚¤ã‚¹IDã§ãƒãƒƒãƒ”ãƒ³ã‚°
    alarm_map = {}
    for a in alarms:
        if a.device_id not in alarm_map:
            alarm_map[a.device_id] = {
                'is_root_cause': False,
                'is_silent_suspect': False,
                'max_severity': 'INFO',
                'messages': []
            }
        info = alarm_map[a.device_id]
        info['messages'].append(a.message)
        if a.is_root_cause:
            info['is_root_cause'] = True
        if a.is_silent_suspect:
            info['is_silent_suspect'] = True
        # æœ€å¤§severity ã‚’æ›´æ–°
        severity_order = {'CRITICAL': 3, 'WARNING': 2, 'INFO': 1}
        if severity_order.get(a.severity, 0) > severity_order.get(info['max_severity'], 0):
            info['max_severity'] = a.severity
    
    for node_id, node in topology.items():
        if hasattr(node, 'type'):
            node_type = node.type
            metadata = node.metadata if hasattr(node, 'metadata') else {}
        else:
            node_type = node.get('type', 'UNKNOWN')
            metadata = node.get('metadata', {})
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æ­£å¸¸ï¼ˆã‚°ãƒªãƒ¼ãƒ³ï¼‰
        color = NodeColor.NORMAL
        penwidth = "1"
        fontcolor = "black"
        label = f"{node_id}\n({node_type})"
        status_label = ""
        
        red_type = metadata.get("redundancy_type")
        if red_type:
            label += f"\n[{red_type} Redundancy]"
        vendor = metadata.get("vendor")
        if vendor:
            label += f"\n[{vendor}]"
        
        # ã‚¢ãƒ©ãƒ¼ãƒ æƒ…å ±ã«åŸºã¥ã„ã¦è‰²ã‚’æ±ºå®š
        if node_id in alarm_map:
            info = alarm_map[node_id]
            
            if info['is_root_cause']:
                # æ ¹æœ¬åŸå› 
                if info['is_silent_suspect']:
                    # ã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³ç–‘ã„ï¼ˆè–„ç´«è‰²ï¼‰
                    color = NodeColor.SILENT_FAILURE
                    penwidth = "3"
                    status_label = "\n[SILENT SUSPECT]"
                elif info['max_severity'] == 'CRITICAL':
                    # ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢ãƒ¬ãƒ™ãƒ«ï¼ˆèµ¤è‰²ï¼‰
                    color = NodeColor.ROOT_CAUSE_CRITICAL
                    penwidth = "3"
                    status_label = "\n[ROOT CAUSE]"
                else:
                    # å†—é•·æ€§ä½ä¸‹ãƒ¬ãƒ™ãƒ«ï¼ˆé»„è‰²ï¼‰
                    color = NodeColor.ROOT_CAUSE_WARNING
                    penwidth = "2"
                    status_label = "\n[WARNING]"
            else:
                # å½±éŸ¿ãƒ‡ãƒã‚¤ã‚¹ï¼ˆã‚°ãƒ¬ãƒ¼ï¼‰
                color = NodeColor.UNREACHABLE
                fontcolor = "#546e7a"
                status_label = "\n[Unreachable]"
        
        label += status_label
        
        graph.node(node_id, label=label, fillcolor=color, color='black', penwidth=penwidth, fontcolor=fontcolor)
    
    for node_id, node in topology.items():
        if hasattr(node, 'parent_id'):
            parent_id = node.parent_id
        else:
            parent_id = node.get('parent_id')
        
        if parent_id:
            graph.edge(parent_id, node_id)
            parent_node = topology.get(parent_id)
            if parent_node:
                if hasattr(parent_node, 'redundancy_group'):
                    rg = parent_node.redundancy_group
                else:
                    rg = parent_node.get('redundancy_group')
                if rg:
                    for nid, n in topology.items():
                        n_rg = n.redundancy_group if hasattr(n, 'redundancy_group') else n.get('redundancy_group')
                        if n_rg == rg and nid != parent_id:
                            graph.edge(nid, node_id)
    
    return graph


# =====================================================
# ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆï¼ˆå‰å›ã®UXã‚’å®Œå…¨å¾©å…ƒï¼‰
# =====================================================
def render_incident_cockpit(site_id: str, api_key: Optional[str]):
    """ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆã‚’æç”»ï¼ˆå‰å›ã®UXã‚’å®Œå…¨å¾©å…ƒï¼‰"""
    display_name = get_display_name(site_id)
    scenario = st.session_state.site_scenarios.get(site_id, "æ­£å¸¸ç¨¼åƒ")
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    col_header = st.columns([4, 1])
    with col_header[0]:
        st.markdown(f"### ğŸ›¡ï¸ AIOps ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆ")
    with col_header[1]:
        # æˆ»ã‚‹ãƒœã‚¿ãƒ³å°‚ç”¨ã®èµ¤è‰²ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆãƒãƒ¼ã‚«ãƒ¼ã§ç‰¹å®šï¼‰
        st.markdown('<span id="back-btn-marker"></span>', unsafe_allow_html=True)
        st.markdown("""
        <style>
        #back-btn-marker + div button,
        #back-btn-marker ~ div[data-testid="stButton"] button {
            background-color: #d32f2f !important;
            color: white !important;
            border: 2px solid #b71c1c !important;
            font-weight: bold !important;
            border-radius: 8px !important;
        }
        #back-btn-marker + div button:hover,
        #back-btn-marker ~ div[data-testid="stButton"] button:hover {
            background-color: #b71c1c !important;
        }
        </style>
        """, unsafe_allow_html=True)
        
        if st.button("ğŸ”™ ä¸€è¦§ã«æˆ»ã‚‹", key="back_to_list"):
            st.session_state.active_site = None
            st.rerun()
    
    # ãƒˆãƒãƒ­ã‚¸ãƒ¼èª­ã¿è¾¼ã¿
    paths = get_paths(site_id)
    topology = load_topology(paths.topology_path)
    
    if not topology:
        st.error("ãƒˆãƒãƒ­ã‚¸ãƒ¼ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    
    # ã‚¢ãƒ©ãƒ¼ãƒ ç”Ÿæˆ
    alarms = generate_alarms_for_scenario(topology, scenario)
    status = get_status_from_alarms(scenario, alarms)
    
    # â˜…â˜…â˜… äºˆå…†ã‚·ã‚°ãƒŠãƒ«æ³¨å…¥ï¼ˆWeak Signal Injectionï¼‰ â˜…â˜…â˜…
    injected = st.session_state.get("injected_weak_signal")
    if injected and injected["device_id"] in topology:
        # â˜… è¤‡æ•°ã‚·ã‚°ãƒŠãƒ«æ³¨å…¥ï¼ˆãƒ¬ãƒ™ãƒ«ã«å¿œã˜ã¦ãƒ­ã‚°ãŒå¢—åŠ ï¼‰
        messages = injected.get("messages", [injected.get("message", "")])
        for msg in messages:
            if msg:
                weak_alarm = Alarm(
                    device_id=injected["device_id"],
                    message=msg,
                    severity="INFO",
                    is_root_cause=False
                )
                alarms.append(weak_alarm)
    
    # LogicalRCA ã‚¨ãƒ³ã‚¸ãƒ³
    engine_key = f"engine_{site_id}"
    if engine_key not in st.session_state.logic_engines:
        st.session_state.logic_engines[engine_key] = LogicalRCA(topology)
    engine = st.session_state.logic_engines[engine_key]
    
    # åˆ†æå®Ÿè¡Œ
    if alarms:
        analysis_results = engine.analyze(alarms)
    else:
        analysis_results = [{
            "id": "SYSTEM",
            "label": "æ­£å¸¸ç¨¼åƒ",
            "prob": 0.0,
            "type": "Normal",
            "tier": 3,
            "reason": "ã‚¢ãƒ©ãƒ¼ãƒ ãªã—"
        }]
    
    # =====================================================
    # KPIãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆå…ƒã®æƒ…å ± + æ–°ã—ã„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼‰
    # =====================================================
    # æ ¹æœ¬åŸå› å€™è£œã®æ•°ã‚’è¨ˆç®—
    root_cause_alarms = [a for a in alarms if a.is_root_cause]
    downstream_alarms = [a for a in alarms if not a.is_root_cause]
    
    # ãƒã‚¤ã‚ºå‰Šæ¸›ç‡ã®è¨ˆç®—
    total_alarms = len(alarms)
    if total_alarms > 0:
        noise_reduction = ((total_alarms - len(root_cause_alarms)) / total_alarms) * 100
    else:
        noise_reduction = 0.0
    
    # è¦å¯¾å¿œã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆæ•°ï¼ˆæ ¹æœ¬åŸå› ã®æ•°ï¼‰
    action_required = len(set(a.device_id for a in root_cause_alarms))
    
    # â˜… Digital Twin äºˆå…†æ¤œçŸ¥æ•°
    prediction_results = [r for r in analysis_results if r.get('is_prediction')]
    prediction_count = len(prediction_results)
    
    # --- å…ƒã®KPIãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼ˆä¸Šæ®µï¼‰ ---
    st.markdown("---")
    cols = st.columns(3)
    cols[0].metric("ğŸš¨ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", f"{get_status_icon(status)} {status}")
    cols[1].metric("ğŸ“Š ã‚¢ãƒ©ãƒ¼ãƒ æ•°", f"{len(alarms)}ä»¶")
    suspect_count = len([r for r in analysis_results if r.get('prob', 0) > 0.5])
    if prediction_count > 0:
        cols[2].metric("ğŸ¯ è¢«ç–‘ç®‡æ‰€", f"{suspect_count}ä»¶",
                       delta=f"ã†ã¡ğŸ”®äºˆå…† {prediction_count}ä»¶", delta_color="off")
    else:
        cols[2].metric("ğŸ¯ è¢«ç–‘ç®‡æ‰€", f"{suspect_count}ä»¶")
    
    # --- æ–°ã—ã„KPIãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼ˆä¸‹æ®µï¼‰ ---
    kpi_cols = st.columns(3)
    with kpi_cols[0]:
        if noise_reduction > 90:
            delta_text = "â†‘ é«˜åŠ¹ç‡ç¨¼åƒä¸­"
            delta_color = "normal"
        elif noise_reduction > 50:
            delta_text = "â†’ é€šå¸¸ç¨¼åƒ"
            delta_color = "off"
        else:
            delta_text = "â†“ è¦ç¢ºèª"
            delta_color = "inverse"
        st.metric(
            "ğŸ“‰ ãƒã‚¤ã‚ºå‰Šæ¸›ç‡",
            f"{noise_reduction:.1f}%",
            delta=delta_text,
            delta_color=delta_color
        )
    
    with kpi_cols[1]:
        if prediction_count > 0:
            delta_text = "âš¡ è¦æ³¨æ„"
            delta_color = "inverse"
        else:
            delta_text = "å•é¡Œãªã—"
            delta_color = "normal"
        st.metric(
            "ğŸ”® äºˆå…†æ¤œçŸ¥",
            f"{prediction_count}ä»¶",
            delta=delta_text,
            delta_color=delta_color
        )
    
    with kpi_cols[2]:
        if action_required > 0:
            delta_text = "â†‘ å¯¾å‡¦ãŒå¿…è¦"
            delta_color = "inverse"
        else:
            delta_text = "å•é¡Œãªã—"
            delta_color = "normal"
        st.metric(
            "ğŸš¨ è¦å¯¾å¿œã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ",
            f"{action_required}ä»¶",
            delta=delta_text,
            delta_color=delta_color
        )
    
    st.markdown("---")
    
    # =====================================================
    # æ ¹æœ¬åŸå› å€™è£œã¨ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ æ©Ÿå™¨ã®åˆ†é›¢
    # =====================================================
    # ã‚¢ãƒ©ãƒ¼ãƒ æƒ…å ±ã‚’ä½¿ã£ã¦æ ¹æœ¬åŸå› ã¨å½±éŸ¿ãƒ‡ãƒã‚¤ã‚¹ã‚’åˆ†é›¢
    root_cause_device_ids = set(a.device_id for a in alarms if a.is_root_cause)
    downstream_device_ids = set(a.device_id for a in alarms if not a.is_root_cause)
    
    root_cause_candidates = []
    downstream_devices = []
    
    for cand in analysis_results:
        device_id = cand.get('id', '')
        # â˜… äºˆå…†æ¤œçŸ¥ã¯å¸¸ã«æ ¹æœ¬åŸå› å€™è£œã¨ã—ã¦æ‰±ã†
        if cand.get('is_prediction'):
            root_cause_candidates.append(cand)
        elif device_id in root_cause_device_ids:
            root_cause_candidates.append(cand)
        elif device_id in downstream_device_ids:
            downstream_devices.append(cand)
        elif cand.get('prob', 0) > 0.5:
            # åˆ†æçµæœã‹ã‚‰ã‚‚æ ¹æœ¬åŸå› å€™è£œã‚’æŠ½å‡º
            root_cause_candidates.append(cand)
    
    # æ­£å¸¸ç¨¼åƒæ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    if not root_cause_candidates and not alarms:
        root_cause_candidates = [{
            "id": "SYSTEM",
            "label": "æ­£å¸¸ç¨¼åƒ",
            "prob": 0.0,
            "type": "Normal",
            "tier": 3,
            "reason": "ã‚¢ãƒ©ãƒ¼ãƒ ãªã—"
        }]
    
    if root_cause_candidates and downstream_devices:
        st.info(f"ğŸ“ **æ ¹æœ¬åŸå› **: {root_cause_candidates[0]['id']} â†’ å½±éŸ¿ç¯„å›²: é…ä¸‹ {len(downstream_devices)} æ©Ÿå™¨")
    
    # â˜… Digital Twin äºˆå…†æ¤œçŸ¥ãƒãƒŠãƒ¼è¡¨ç¤ºã®å‰Šé™¤ç®‡æ‰€
    # (ã“ã“ã«ä»¥å‰ã‚ã£ãŸ st.warning(...) ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‰Šé™¤ã—ã¾ã—ãŸ)
    # 2025-02-12: ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æœ›ã«ã‚ˆã‚Šå‰Šé™¤ï¼ˆFuture Radarã¨é‡è¤‡ã™ã‚‹ãŸã‚ï¼‰
    
    # =====================================================
    # ğŸ”® AIOps Future Radarï¼ˆäºˆå…†å°‚ç”¨è¡¨ç¤ºã‚¨ãƒªã‚¢ï¼‰
    # =====================================================
    prediction_candidates = [c for c in root_cause_candidates if c.get('is_prediction')]
    
    if prediction_candidates:
        st.markdown("### ğŸ”® AIOps Future Radar")
        
        with st.container(border=True):
            # ãƒ˜ãƒƒãƒ€ãƒ¼
            injected_info = st.session_state.get("injected_weak_signal")
            if injected_info:
                level = injected_info.get("level", 0)
                scenario_name = injected_info.get("scenario", "")
                st.info(
                    f"âš ï¸ **äºˆå…†æ¤œçŸ¥**: ç¾åœ¨ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çŠ¶æ…‹ã¯ã€Œæ­£å¸¸ã€ã§ã™ãŒã€"
                    f"AIãŒå¾®ç´°ãªã‚·ã‚°ãƒŠãƒ«ã‹ã‚‰å°†æ¥ã®éšœå®³ãƒªã‚¹ã‚¯ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚"
                    f"ï¼ˆåŠ£åŒ–ã‚·ãƒŠãƒªã‚ª: {scenario_name} / ãƒ¬ãƒ™ãƒ«: {level}/5ï¼‰"
                )
            else:
                st.info(
                    "âš ï¸ **äºˆå…†æ¤œçŸ¥**: ç¾åœ¨ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çŠ¶æ…‹ã¯ã€Œæ­£å¸¸ã€ã§ã™ãŒã€"
                    "AIãŒå°†æ¥ã®éšœå®³ãƒªã‚¹ã‚¯ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚"
                )
            
            # å„äºˆå…†ã®ã‚«ãƒ¼ãƒ‰è¡¨ç¤º
            radar_cols = st.columns(min(len(prediction_candidates), 3))
            for idx, pred_item in enumerate(prediction_candidates[:3]):
                with radar_cols[idx]:
                    prob_val = pred_item.get('prob', 0)
                    prob_pct = f"{prob_val*100:.0f}%"
                    pred_timeline = pred_item.get('prediction_timeline', 'ä¸æ˜')
                    pred_affected = pred_item.get('prediction_affected_count', 0)
                    pred_label = pred_item.get('label', '').replace('ğŸ”® [äºˆå…†] ', '')
                    pred_early_hours = pred_item.get('prediction_early_warning_hours', 0)
                    
                    st.error(f"**ğŸ“ {pred_item['id']}**")
                    
                    st.markdown(
                        f"<div style='text-align:center;'>"
                        f"<span style='font-size:36px; font-weight:bold; color:#d32f2f;'>{prob_pct}</span>"
                        f"<br><span style='color:#666;'>ç™ºç”Ÿç¢ºç‡ï¼ˆæ€¥æ€§æœŸ: {pred_timeline}ï¼‰</span>"
                        f"</div>",
                        unsafe_allow_html=True
                    )
                    
                    st.divider()
                    st.markdown(f"**äºˆæ¸¬éšœå®³:** {pred_label}")
                    # â˜… 2è»¸è¡¨ç¤º: æ—©æœŸäºˆå…† + æ€¥æ€§æœŸ
                    if pred_early_hours >= 24:
                        early_display = f"æœ€å¤§ **{pred_early_hours // 24}æ—¥å‰** ã‹ã‚‰æ¤œçŸ¥å¯èƒ½"
                    elif pred_early_hours > 0:
                        early_display = f"æœ€å¤§ **{pred_early_hours}æ™‚é–“å‰** ã‹ã‚‰æ¤œçŸ¥å¯èƒ½"
                    else:
                        early_display = "ä¸æ˜"
                    st.markdown(f"**æ—©æœŸäºˆå…†:** {early_display}")
                    st.markdown(f"**æ€¥æ€§æœŸ:** ç™ºç—‡å¾Œ **{pred_timeline}** ã«æ·±åˆ»åŒ–")
                    st.markdown(f"**å½±éŸ¿ç¯„å›²:** é…ä¸‹ **{pred_affected}å°** ãŒé€šä¿¡æ–­ã®æã‚Œ")
                    
                    # æ¤œçŸ¥ã•ã‚ŒãŸ Weak Signal ã®è©³ç´°
                    with st.expander("ğŸ” æ¤œçŸ¥ã•ã‚ŒãŸäºˆå…† (Weak Signal)"):
                        reason = pred_item.get('reason', '')
                        st.text(reason)
                        
                        factors = pred_item.get('prediction_confidence_factors', {})
                        if factors:
                            st.caption(
                                f"ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦: {factors.get('base', 0):.2f} / "
                                f"ãƒãƒƒãƒå“è³ª: {factors.get('match_quality', 0):.2f} / "
                                f"SPOF: {'Yes' if factors.get('is_spof') else 'No'} / "
                                f"å†—é•·æ€§: {'Yes' if factors.get('has_redundancy') else 'No'}"
                            )
        
        st.markdown("---")
    
    # å€™è£œãƒ†ãƒ¼ãƒ–ãƒ«
    selected_incident_candidate = None
    target_device_id = None
    
    if root_cause_candidates:
        # ã‚¢ãƒ©ãƒ¼ãƒ ã‹ã‚‰severityã¨is_silent_suspectã‚’å–å¾—ã™ã‚‹ãƒãƒƒãƒ—ã‚’ä½œæˆ
        alarm_info_map = {}
        for a in alarms:
            if a.device_id not in alarm_info_map:
                alarm_info_map[a.device_id] = {'severity': 'INFO', 'is_silent': False}
            if a.severity == 'CRITICAL':
                alarm_info_map[a.device_id]['severity'] = 'CRITICAL'
            elif a.severity == 'WARNING' and alarm_info_map[a.device_id]['severity'] != 'CRITICAL':
                alarm_info_map[a.device_id]['severity'] = 'WARNING'
            if a.is_silent_suspect:
                alarm_info_map[a.device_id]['is_silent'] = True
        
        df_data = []
        for rank, cand in enumerate(root_cause_candidates, 1):
            prob = cand.get('prob', 0)
            cand_type = cand.get('type', 'UNKNOWN')
            device_id = cand['id']
            
            # ã‚¢ãƒ©ãƒ¼ãƒ æƒ…å ±ã‹ã‚‰ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’åˆ¤å®š
            alarm_info = alarm_info_map.get(device_id, {'severity': 'INFO', 'is_silent': False})
            
            # â˜… Digital Twin äºˆå…†æ¤œçŸ¥ (is_prediction ã‚’æœ€å„ªå…ˆã§ãƒã‚§ãƒƒã‚¯)
            if cand.get('is_prediction'):
                status_text = "ğŸ”® äºˆå…†æ¤œçŸ¥"
                timeline = cand.get('prediction_timeline', '')
                affected = cand.get('prediction_affected_count', 0)
                early_hours = cand.get('prediction_early_warning_hours', 0)
                if early_hours >= 24:
                    early_str = f"(äºˆå…†: {early_hours // 24}æ—¥å‰ã€œ)"
                elif early_hours > 0:
                    early_str = f"(äºˆå…†: {early_hours}æ™‚é–“å‰ã€œ)"
                else:
                    early_str = ""
                if timeline and affected:
                    action = f"âš¡ æ€¥æ€§æœŸ{timeline}ä»¥å†… {early_str} ({affected}å°å½±éŸ¿)"
                else:
                    action = f"âš¡ äºˆé˜²çš„å¯¾å‡¦ã‚’æ¨å¥¨ {early_str}"
            elif alarm_info['is_silent'] or "Silent" in cand_type:
                status_text = "ğŸŸ£ ã‚µã‚¤ãƒ¬ãƒ³ãƒˆç–‘ã„"
                action = "ğŸ” ä¸Šä½ç¢ºèª"
            elif alarm_info['severity'] == 'CRITICAL':
                status_text = "ğŸ”´ å±é™º (æ ¹æœ¬åŸå› )"
                action = "ğŸš€ è‡ªå‹•ä¿®å¾©ãŒå¯èƒ½"
            elif alarm_info['severity'] == 'WARNING':
                status_text = "ğŸŸ¡ è­¦å‘Š"
                action = "ğŸ” è©³ç´°èª¿æŸ»"
            elif prob > 0.6:
                status_text = "ğŸŸ¡ è¢«ç–‘ç®‡æ‰€"
                action = "ğŸ” è©³ç´°èª¿æŸ»"
            else:
                status_text = "âšª ç›£è¦–ä¸­"
                action = "ğŸ‘ï¸ é™è¦³"
            
            df_data.append({
                "é †ä½": rank,
                "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": status_text,
                "ãƒ‡ãƒã‚¤ã‚¹": device_id,
                "åŸå› ": cand.get('label', ''),
                "ç¢ºä¿¡åº¦": f"{prob*100:.0f}%",
                "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³": action,
                "_id": device_id,
                "_prob": prob
            })
        
        df = pd.DataFrame(df_data)
        
        st.markdown("#### ğŸ¯ æ ¹æœ¬åŸå› å€™è£œ")
        event = st.dataframe(
            df[["é †ä½", "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "ãƒ‡ãƒã‚¤ã‚¹", "åŸå› ", "ç¢ºä¿¡åº¦", "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"]],
            use_container_width=True,
            hide_index=True,
            selection_mode="single-row",
            on_select="rerun"
        )
        
        if event.selection and len(event.selection.rows) > 0:
            sel_row = df.iloc[event.selection.rows[0]]
            for cand in root_cause_candidates:
                if cand['id'] == sel_row['_id']:
                    selected_incident_candidate = cand
                    target_device_id = cand['id']
                    break
        elif root_cause_candidates:
            selected_incident_candidate = root_cause_candidates[0]
            target_device_id = root_cause_candidates[0]['id']
        
        # ä¸‹æµãƒ‡ãƒã‚¤ã‚¹ï¼ˆ10å°ä»¥ä¸Šã®å ´åˆã¯ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«è¡¨ç¤ºï¼‰
        if downstream_devices:
            with st.expander(f"â–¼ å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹æ©Ÿå™¨ ({len(downstream_devices)}å°) - ä¸Šæµå¾©æ—§å¾…ã¡", expanded=False):
                dd_df = pd.DataFrame([
                    {"No": i+1, "ãƒ‡ãƒã‚¤ã‚¹": d['id'], "çŠ¶æ…‹": "âš« å¿œç­”ãªã—", "å‚™è€ƒ": "ä¸Šæµå¾©æ—§å¾…ã¡"}
                    for i, d in enumerate(downstream_devices)
                ])
                # 10å°ä»¥ä¸Šã®å ´åˆã¯ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å¯èƒ½ãªã‚³ãƒ³ãƒ†ãƒŠå†…ã«è¡¨ç¤º
                if len(downstream_devices) >= 10:
                    with st.container(height=300):
                        st.dataframe(dd_df, use_container_width=True, hide_index=True)
                else:
                    st.dataframe(dd_df, use_container_width=True, hide_index=True)
    
    # ========================================
    # 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼ˆå‰å›ã®UXã‚’å¾©å…ƒï¼‰
    # ========================================
    col_map, col_chat = st.columns([1.2, 1])
    
    # === å·¦ã‚«ãƒ©ãƒ : ãƒˆãƒãƒ­ã‚¸ãƒ¼ & Auto-Diagnostics ===
    with col_map:
        st.subheader("ğŸŒ Network Topology")
        graph = render_topology_graph(topology, alarms, analysis_results)
        st.graphviz_chart(graph, use_container_width=True)
        
        st.markdown("---")
        st.subheader("ğŸ› ï¸ Auto-Diagnostics")
        
        if st.button("ğŸš€ è¨ºæ–­å®Ÿè¡Œ (Run Diagnostics)", type="primary"):
            if not api_key:
                st.error("API Key Required")
            else:
                with st.status("Agent Operating...", expanded=True) as status_widget:
                    st.write("ğŸ”Œ Connecting to device...")
                    target_node_obj = topology.get(target_device_id) if target_device_id else None
                    
                    res = run_diagnostic_simulation_no_llm(scenario, target_node_obj)
                    st.session_state.live_result = res
                    
                    if res["status"] == "SUCCESS":
                        st.write("âœ… Log Acquired & Sanitized.")
                        status_widget.update(label="Diagnostics Complete!", state="complete", expanded=False)
                        log_content = res.get('sanitized_log', "")
                        verification = verify_log_content(log_content)
                        st.session_state.verification_result = verification
                        st.session_state.trigger_analysis = True
                    else:
                        st.write("âŒ Connection Failed.")
                        status_widget.update(label="Diagnostics Failed", state="error")
                st.rerun()
        
        if st.session_state.live_result:
            res = st.session_state.live_result
            if res["status"] == "SUCCESS":
                st.markdown("#### ğŸ“„ Diagnostic Results")
                with st.container(border=True):
                    if st.session_state.verification_result:
                        v = st.session_state.verification_result
                        c1, c2, c3 = st.columns(3)
                        c1.metric("Ping Status", v.get('ping_status'))
                        c2.metric("Interface", v.get('interface_status'))
                        c3.metric("Hardware", v.get('hardware_status'))
                    
                    st.divider()
                    st.caption("ğŸ”’ Raw Logs (Sanitized)")
                    st.code(res["sanitized_log"], language="text")
    
    # === å³ã‚«ãƒ©ãƒ : AI Analyst Report & Remediation & Chat ===
    with col_chat:
        st.subheader("ğŸ“ AI Analyst Report")
        
        if selected_incident_candidate:
            cand = selected_incident_candidate
            
            # --- A. åŸå› åˆ†æãƒ¬ãƒãƒ¼ãƒˆ ---
            if st.session_state.generated_report is None:
                st.info(f"ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆé¸æŠä¸­: **{cand['id']}** ({cand['label']})")
                
                if api_key and (scenario != "æ­£å¸¸ç¨¼åƒ" or cand.get('is_prediction')):
                    # â˜… äºˆå…†ã®å ´åˆã¯ãƒœã‚¿ãƒ³ãƒ©ãƒ™ãƒ«ã¨ã‚·ãƒŠãƒªã‚ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å¤‰æ›´
                    is_pred = cand.get('is_prediction')
                    btn_label = "ğŸ”® äºˆå…†ã®ç¢ºèªæ‰‹é †ã‚’ç”Ÿæˆ (Predictive Analysis)" if is_pred else "ğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ (Generate Report)"
                    
                    if st.button(btn_label):
                        report_container = st.empty()
                        target_conf = load_config_by_id(cand['id'])
                        verification_context = cand.get("verification_log", "ç‰¹ã«ãªã—")
                        
                        t_node = topology.get(cand["id"])
                        t_node_dict = {
                            "id": getattr(t_node, "id", None) if t_node else None,
                            "type": getattr(t_node, "type", None) if t_node else None,
                            "layer": getattr(t_node, "layer", None) if t_node else None,
                            "metadata": (getattr(t_node, "metadata", {}) or {}) if t_node else {},
                        }
                        
                        parent_id = t_node.parent_id if t_node and hasattr(t_node, 'parent_id') else None
                        children_ids = [
                            nid for nid, n in topology.items()
                            if (getattr(n, "parent_id", None) if hasattr(n, 'parent_id') else n.get('parent_id')) == cand["id"]
                        ]
                        topology_context = {"node": t_node_dict, "parent_id": parent_id, "children_ids": children_ids}
                        
                        cache_key_analyst = "|".join([
                            "analyst",
                            site_id,
                            scenario,
                            str(cand.get("id")),
                            _hash_text(json.dumps(topology_context, ensure_ascii=False, sort_keys=True)),
                        ])
                        
                        if cache_key_analyst in st.session_state.report_cache:
                            full_text = st.session_state.report_cache[cache_key_analyst]
                            report_container.markdown(full_text)
                        else:
                            try:
                                report_container.write("ğŸ¤– AI åˆ†æä¸­...")
                                placeholder = report_container.empty()
                                full_text = ""
                                
                                # â˜… äºˆå…†ã®å ´åˆã€AI ã«äºˆå…†ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¸¡ã™
                                report_scenario = scenario
                                if is_pred:
                                    pred_reason = cand.get('reason', '')
                                    pred_timeline = cand.get('prediction_timeline', 'ä¸æ˜')
                                    pred_affected = cand.get('prediction_affected_count', 0)
                                    signal_count = cand.get('prediction_signal_count', 1)
                                    pred_early_hours = cand.get('prediction_early_warning_hours', 0)
                                    pred_time_critical = cand.get('prediction_time_to_critical_min', 0)
                                    if pred_early_hours >= 24:
                                        early_ctx = f"{pred_early_hours // 24}æ—¥å‰ã‹ã‚‰æ¤œçŸ¥å¯èƒ½ãªãƒ‘ã‚¿ãƒ¼ãƒ³"
                                    elif pred_early_hours > 0:
                                        early_ctx = f"{pred_early_hours}æ™‚é–“å‰ã‹ã‚‰æ¤œçŸ¥å¯èƒ½ãªãƒ‘ã‚¿ãƒ¼ãƒ³"
                                    else:
                                        early_ctx = "æ—©æœŸæ¤œçŸ¥ãƒ‘ã‚¿ãƒ¼ãƒ³"
                                    report_scenario = (
                                        f"[äºˆå…†æ¤œçŸ¥ - Predictive Maintenance] Digital TwinãŒ{cand['id']}ã§éšœå®³ã®å‰å…†ã‚’æ¤œå‡ºã€‚\n"
                                        f"ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã¯ã€Œæ­£å¸¸ã€ã ãŒã€{signal_count}ä»¶ã®å¾®å¼±ã‚·ã‚°ãƒŠãƒ«ã‚’æ¤œå‡ºã€‚\n"
                                        f"ãƒ»æ—©æœŸäºˆå…†: {early_ctx}\n"
                                        f"ãƒ»æ€¥æ€§æœŸé€²è¡Œ: ç™ºç—‡å¾Œ{pred_time_critical}åˆ†ã§æ·±åˆ»åŒ–ã®æã‚Œ\n"
                                        f"ãƒ»å½±éŸ¿ç¯„å›²: é…ä¸‹{pred_affected}å°ã«å½±éŸ¿ã®æã‚Œ\n\n"
                                        f"æ¤œå‡ºã•ã‚ŒãŸã‚·ã‚°ãƒŠãƒ«:\n{pred_reason}\n\n"
                                        f"ä»¥ä¸‹ã®æ§‹æˆã§ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„:\n"
                                        f"1. æ¤œå‡ºã•ã‚ŒãŸäºˆå…†ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è§£èª¬ï¼ˆä½•ãŒèµ·ãã¦ã„ã‚‹ã‹ï¼‰\n"
                                        f"2. æ‰‹å‹•ç¢ºèªæ‰‹é †ï¼ˆshow ã‚³ãƒãƒ³ãƒ‰ç­‰ã€å®Ÿæ©Ÿã§ç¢ºèªã™ã¹ãé …ç›®ï¼‰\n"
                                        f"3. äºˆå…†ãŒéšœå®³ã«ç™ºå±•ã™ã‚‹ã‹åˆ¤å®šã™ã‚‹ãŸã‚ã®åŸºæº–\n"
                                        f"4. æ¨å¥¨ã•ã‚Œã‚‹äºˆé˜²æªç½®ã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹è¨ˆç”»\n"
                                        f"5. ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸºæº–ï¼ˆã©ã®æ®µéšã§ä¸Šä½å ±å‘Šã™ã¹ãã‹ï¼‰"
                                    )
                                
                                for chunk in generate_analyst_report_streaming(
                                    scenario=report_scenario,
                                    target_node=t_node,
                                    topology_context=topology_context,
                                    target_conf=target_conf or "ãªã—",
                                    verification_context=verification_context,
                                    api_key=api_key,
                                    max_retries=2,
                                    backoff=3
                                ):
                                    full_text += chunk
                                    placeholder.markdown(full_text)
                                
                                if not full_text or full_text.startswith("Error"):
                                    full_text = f"âš ï¸ åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {full_text}"
                                    placeholder.markdown(full_text)
                                
                                st.session_state.report_cache[cache_key_analyst] = full_text
                            except Exception as e:
                                full_text = f"âš ï¸ åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {type(e).__name__}: {e}"
                                report_container.markdown(full_text)
                        
                        st.session_state.generated_report = full_text
            else:
                with st.container(height=400, border=True):
                    st.markdown(st.session_state.generated_report)
                if st.button("ğŸ”„ ãƒ¬ãƒãƒ¼ãƒˆå†ä½œæˆ"):
                    st.session_state.generated_report = None
                    st.rerun()
        
        # --- B. è‡ªå‹•ä¿®å¾© & ãƒãƒ£ãƒƒãƒˆ ---
        st.markdown("---")
        st.subheader("ğŸ¤– Remediation & Chat")
        
        if selected_incident_candidate and selected_incident_candidate["prob"] > 0.6:
            # â˜… äºˆå…†ã¨ç¢ºå®šã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã§è¡¨ç¤ºã‚’åˆ†ã‘ã‚‹
            if selected_incident_candidate.get('is_prediction'):
                timeline = selected_incident_candidate.get('prediction_timeline', 'ä¸æ˜')
                affected = selected_incident_candidate.get('prediction_affected_count', 0)
                early_hours = selected_incident_candidate.get('prediction_early_warning_hours', 0)
                if early_hours >= 24:
                    early_display = f"æœ€å¤§ <b>{early_hours // 24}æ—¥å‰</b> ã‹ã‚‰æ¤œçŸ¥å¯èƒ½"
                elif early_hours > 0:
                    early_display = f"æœ€å¤§ <b>{early_hours}æ™‚é–“å‰</b> ã‹ã‚‰æ¤œçŸ¥å¯èƒ½"
                else:
                    early_display = "ä¸æ˜"
                st.markdown(f"""
                <div style="background-color:#fff3e0;padding:10px;border-radius:5px;border:1px solid #ff9800;color:#e65100;margin-bottom:10px;">
                    <strong>ğŸ”® Digital Twin æœªæ¥äºˆæ¸¬ (Predictive Maintenance)</strong><br>
                    <b>{selected_incident_candidate['id']}</b> ã§éšœå®³ã®å…†å€™ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚<br>
                    ãƒ»æ—©æœŸäºˆå…†: {early_display}<br>
                    ãƒ»æ€¥æ€§æœŸé€²è¡Œ: ç™ºç—‡å¾Œ <b>{timeline}</b> ã«æ·±åˆ»åŒ–ã®æã‚Œ<br>
                    ãƒ»å½±éŸ¿ç¯„å›²: <b>{affected}å°</b> ã®ãƒ‡ãƒã‚¤ã‚¹ã«å½±éŸ¿ã®å¯èƒ½æ€§<br>
                    ãƒ»æ¨å¥¨: ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã®äºˆé˜²äº¤æ›/å¯¾å¿œ<br>
                    (ä¿¡é ¼åº¦: <span style="font-size:1.2em;font-weight:bold;">{selected_incident_candidate['prob']*100:.0f}%</span>)
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div style="background-color:#e8f5e9;padding:10px;border-radius:5px;border:1px solid #4caf50;color:#2e7d32;margin-bottom:10px;">
                    <strong>âœ… AI Analysis Completed</strong><br>
                    ç‰¹å®šã•ã‚ŒãŸåŸå›  <b>{selected_incident_candidate['id']}</b> ã«å¯¾ã™ã‚‹å¾©æ—§æ‰‹é †ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚<br>
                    (ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: <span style="font-size:1.2em;font-weight:bold;">{selected_incident_candidate['prob']*100:.0f}</span>)
                </div>
                """, unsafe_allow_html=True)
            
            if st.session_state.remediation_plan is None:
                # â˜… äºˆå…†æ™‚ã¯ãƒœã‚¿ãƒ³ãƒ©ãƒ™ãƒ«ã‚’å¤‰æ›´
                is_pred_rem = selected_incident_candidate.get('is_prediction')
                fix_label = "ğŸ”® äºˆé˜²æªç½®ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆ" if is_pred_rem else "âœ¨ ä¿®å¾©ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆ (Generate Fix)"
                report_prereq = "ã€ŒğŸ”® äºˆå…†ã®ç¢ºèªæ‰‹é †ã‚’ç”Ÿæˆã€" if is_pred_rem else "ã€ŒğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ (Generate Report)ã€"
                
                if st.button(fix_label):
                    if st.session_state.generated_report is None:
                        st.warning(f"å…ˆã«{report_prereq}ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                    else:
                        remediation_container = st.empty()
                        t_node = topology.get(selected_incident_candidate["id"])
                        
                        # â˜… äºˆå…†æ™‚ã®ã‚·ãƒŠãƒªã‚ªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
                        rem_scenario = scenario
                        if is_pred_rem:
                            pred_timeline = selected_incident_candidate.get('prediction_timeline', 'ä¸æ˜')
                            pred_affected = selected_incident_candidate.get('prediction_affected_count', 0)
                            pred_early_hours = selected_incident_candidate.get('prediction_early_warning_hours', 0)
                            pred_time_critical = selected_incident_candidate.get('prediction_time_to_critical_min', 0)
                            if pred_early_hours >= 24:
                                early_ctx = f"æœ€å¤§{pred_early_hours // 24}æ—¥å‰ã‹ã‚‰æ¤œçŸ¥å¯èƒ½"
                            elif pred_early_hours > 0:
                                early_ctx = f"æœ€å¤§{pred_early_hours}æ™‚é–“å‰ã‹ã‚‰æ¤œçŸ¥å¯èƒ½"
                            else:
                                early_ctx = "æ—©æœŸæ¤œçŸ¥ãƒ‘ã‚¿ãƒ¼ãƒ³"
                            rem_scenario = (
                                f"[äºˆå…†å¯¾å¿œ - Predictive Maintenance] {selected_incident_candidate['id']}ã§éšœå®³ã®å‰å…†ã‚’æ¤œå‡ºã€‚\n"
                                f"ãƒ»æ—©æœŸäºˆå…†: {early_ctx}\n"
                                f"ãƒ»æ€¥æ€§æœŸ: ç™ºç—‡å¾Œ{pred_time_critical}åˆ†ã«æ·±åˆ»åŒ–ã®æã‚Œï¼ˆå½±éŸ¿{pred_affected}å°ï¼‰\n\n"
                                f"ã€Œå¾©æ—§ã€ã§ã¯ãªãã€Œäºˆé˜²æªç½®ã€ã¨ã—ã¦ã€éšœå®³ã‚’æœªç„¶ã«é˜²ããŸã‚ã®æ‰‹é †ã‚’æç¤ºã—ã¦ãã ã•ã„:\n"
                                f"1. äºˆé˜²çš„ç¢ºèªã‚³ãƒãƒ³ãƒ‰ï¼ˆshowç³»ã‚³ãƒãƒ³ãƒ‰ã§ç¾çŠ¶æŠŠæ¡ï¼‰\n"
                                f"2. äºˆé˜²æªç½®ã®å®Ÿæ–½æ‰‹é †ï¼ˆéƒ¨å“äº¤æ›ã€è¨­å®šå¤‰æ›´ç­‰ï¼‰\n"
                                f"3. ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã®ä½œæ¥­è¨ˆç”»\n"
                                f"4. åˆ‡ã‚Šæˆ»ã—æ‰‹é †ï¼ˆäºˆé˜²æªç½®ã§å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆï¼‰\n"
                                f"5. æ­£å¸¸æ€§ç¢ºèªã‚³ãƒãƒ³ãƒ‰ï¼ˆå¯¾å¿œå®Œäº†å¾Œã®ç¢ºèªé …ç›®ï¼‰\n"
                                f"6. ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸºæº–ï¼ˆå¯¾å¿œãŒé–“ã«åˆã‚ãªã„å ´åˆã®åˆ¤æ–­åŸºæº–ï¼‰"
                            )
                        
                        cache_key_remediation = "|".join([
                            "remediation",
                            site_id,
                            scenario,
                            str(selected_incident_candidate.get("id")),
                            _hash_text(st.session_state.generated_report or ""),
                        ])
                        
                        if cache_key_remediation in st.session_state.report_cache:
                            remediation_text = st.session_state.report_cache[cache_key_remediation]
                            remediation_container.markdown(remediation_text)
                        else:
                            try:
                                loading_msg = "ğŸ”® äºˆé˜²æªç½®ãƒ—ãƒ©ãƒ³ç”Ÿæˆä¸­..." if is_pred_rem else "ğŸ¤– å¾©æ—§ãƒ—ãƒ©ãƒ³ç”Ÿæˆä¸­..."
                                remediation_container.write(loading_msg)
                                placeholder = remediation_container.empty()
                                remediation_text = ""
                                
                                for chunk in generate_remediation_commands_streaming(
                                    scenario=rem_scenario,
                                    analysis_result=st.session_state.generated_report or "",
                                    target_node=t_node,
                                    api_key=api_key,
                                    max_retries=2,
                                    backoff=3
                                ):
                                    remediation_text += chunk
                                    placeholder.markdown(remediation_text)
                                
                                if not remediation_text or remediation_text.startswith("Error"):
                                    remediation_text = f"âš ï¸ å¾©æ—§ãƒ—ãƒ©ãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {remediation_text}"
                                    placeholder.markdown(remediation_text)
                                
                                st.session_state.report_cache[cache_key_remediation] = remediation_text
                            except Exception as e:
                                remediation_text = f"âš ï¸ å¾©æ—§ãƒ—ãƒ©ãƒ³ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {type(e).__name__}: {e}"
                                remediation_container.markdown(remediation_text)
                        
                        st.session_state.remediation_plan = remediation_text
                        st.rerun()
            
            if st.session_state.remediation_plan is not None:
                with st.container(height=400, border=True):
                    st.info("AI Generated Recovery Procedureï¼ˆå¾©æ—§æ‰‹é †ï¼‰")
                    st.markdown(st.session_state.remediation_plan)
                
                col_exec1, col_exec2 = st.columns(2)
                
                with col_exec1:
                    if st.button("ğŸš€ ä¿®å¾©å®Ÿè¡Œ (Execute)", type="primary"):
                        if not api_key:
                            st.error("API Key Required")
                        else:
                            with st.status("Autonomic Remediation in progress...", expanded=True) as status_widget:
                                target_node_obj = topology.get(selected_incident_candidate["id"])
                                device_info = target_node_obj.metadata if target_node_obj and hasattr(target_node_obj, 'metadata') else {}
                                
                                st.write("ğŸ”„ Executing remediation steps in parallel...")
                                
                                results = run_remediation_parallel_v2(
                                    device_id=selected_incident_candidate["id"],
                                    device_info=device_info,
                                    scenario=scenario,
                                    environment=RemediationEnvironment.DEMO,
                                    timeout_per_step=30
                                )
                                
                                st.write("ğŸ“‹ Remediation steps result:")
                                
                                all_success = True
                                remediation_summary = []
                                
                                for step_name in ["Backup", "Apply", "Verify"]:
                                    result = results.get(step_name)
                                    if result:
                                        st.write(str(result))
                                        remediation_summary.append(str(result))
                                        if result.status != "success":
                                            all_success = False
                                
                                verification_log = "\n".join(remediation_summary)
                                st.session_state.verification_log = verification_log
                                
                                if all_success:
                                    st.write("âœ… All remediation steps completed successfully.")
                                    status_widget.update(label="Process Finished", state="complete", expanded=False)
                                    
                                    # å¾©æ—§æˆåŠŸãƒ•ãƒ©ã‚°ã‚’è¨­å®š
                                    st.session_state.recovered_devices[selected_incident_candidate["id"]] = True
                                    st.session_state.recovered_scenario_map[selected_incident_candidate["id"]] = scenario
                                    
                                    if not st.session_state.balloons_shown:
                                        st.balloons()
                                        st.session_state.balloons_shown = True
                                    
                                    st.success("âœ… System Recovered Successfully!")
                                else:
                                    st.write("âš ï¸ Some remediation steps failed. Please review.")
                                    status_widget.update(label="Process Finished - With Errors", state="error", expanded=True)
                
                with col_exec2:
                    if st.button("ã‚­ãƒ£ãƒ³ã‚»ãƒ«"):
                        st.session_state.remediation_plan = None
                        st.session_state.verification_log = None
                        st.rerun()
                
                if st.session_state.get("verification_log"):
                    st.markdown("#### ğŸ” Post-Fix Verification Logs")
                    st.code(st.session_state.verification_log, language="text")
        else:
            if selected_incident_candidate:
                device_id = selected_incident_candidate.get('id', '')
                score = selected_incident_candidate['prob'] * 100
                
                if device_id == "SYSTEM" and score == 0:
                    st.markdown("""
                    <div style="background-color:#e8f5e9;padding:10px;border-radius:5px;border:1px solid #4caf50;color:#2e7d32;margin-bottom:10px;">
                        <strong>âœ… æ­£å¸¸ç¨¼åƒä¸­</strong><br>
                        ç¾åœ¨ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯æ­£å¸¸ã«ç¨¼åƒã—ã¦ã„ã¾ã™ã€‚å¯¾å¿œãŒå¿…è¦ãªã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                    <div style="background-color:#fff3e0;padding:10px;border-radius:5px;border:1px solid #ff9800;color:#e65100;margin-bottom:10px;">
                        <strong>âš ï¸ ç›£è¦–ä¸­</strong><br>
                        å¯¾è±¡: <b>{device_id}</b><br>
                        (ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: {score:.0f} - 60ä»¥ä¸Šã§è‡ªå‹•ä¿®å¾©ã‚’æ¨å¥¨)
                    </div>
                    """, unsafe_allow_html=True)
        
        # --- C. Chat with AI Agent ---
        with st.expander("ğŸ’¬ Chat with AI Agent", expanded=False):
            _chat_target_id = ""
            if selected_incident_candidate:
                _chat_target_id = selected_incident_candidate.get("id", "") or ""
            if not _chat_target_id and target_device_id:
                _chat_target_id = target_device_id
            
            _chat_ci = _build_ci_context_for_chat(topology, _chat_target_id) if _chat_target_id else {}
            if _chat_ci:
                _vendor = _chat_ci.get("vendor", "") or "Unknown"
                _os = _chat_ci.get("os", "") or "Unknown"
                _model = _chat_ci.get("model", "") or "Unknown"
                st.caption(f"å¯¾è±¡æ©Ÿå™¨: {_chat_target_id}   Vendor: {_vendor}   OS: {_os}   Model: {_model}")
            
            # ã‚¯ã‚¤ãƒƒã‚¯è³ªå•ãƒœã‚¿ãƒ³
            q1, q2, q3 = st.columns(3)
            
            with q1:
                if st.button("è¨­å®šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—", use_container_width=True):
                    st.session_state.chat_quick_text = "ã“ã®æ©Ÿå™¨ã§ã€ç¾åœ¨ã®è¨­å®šã‚’å®‰å…¨ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã™ã‚‹æ‰‹é †ã¨ã‚³ãƒãƒ³ãƒ‰ä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
            with q2:
                if st.button("ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯", use_container_width=True):
                    st.session_state.chat_quick_text = "ã“ã®æ©Ÿå™¨ã§ã€å¤‰æ›´ã‚’ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹ä»£è¡¨çš„ãªæ‰‹é †ï¼ˆå€™è£œï¼‰ã¨æ³¨æ„ç‚¹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
            with q3:
                if st.button("ç¢ºèªã‚³ãƒãƒ³ãƒ‰", use_container_width=True):
                    st.session_state.chat_quick_text = "ä»Šå›ã®ç—‡çŠ¶ã‚’åˆ‡ã‚Šåˆ†ã‘ã‚‹ãŸã‚ã«ã€ã¾ãšå®Ÿè¡Œã™ã¹ãç¢ºèªã‚³ãƒãƒ³ãƒ‰ï¼ˆshow/diagnosticï¼‰ã‚’å„ªå…ˆåº¦é †ã«æ•™ãˆã¦ãã ã•ã„ã€‚"
            
            if st.session_state.chat_quick_text:
                st.info("ã‚¯ã‚¤ãƒƒã‚¯è³ªå•ï¼ˆã‚³ãƒ”ãƒ¼ã—ã¦è²¼ã‚Šä»˜ã‘ï¼‰")
                st.code(st.session_state.chat_quick_text)
            
            if st.session_state.chat_session is None and api_key and GENAI_AVAILABLE:
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel("gemma-3-12b-it")
                st.session_state.chat_session = model.start_chat(history=[])
            
            # ã‚¿ãƒ–ã§ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
            tab1, tab2 = st.tabs(["ğŸ’¬ ä¼šè©±", "ğŸ“ å±¥æ­´"])
            
            with tab1:
                if st.session_state.messages:
                    last_msg = st.session_state.messages[-1]
                    if last_msg["role"] == "assistant":
                        st.info("ğŸ¤– æœ€æ–°ã®å›ç­”")
                        with st.container(height=300):
                            st.markdown(last_msg["content"])
                
                st.markdown("---")
                prompt = st.text_area(
                    "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
                    height=70,
                    placeholder="Ctrl+Enter ã¾ãŸã¯ é€ä¿¡ãƒœã‚¿ãƒ³ã§é€ä¿¡",
                    key="chat_textarea"
                )
                
                col1, col2, col3 = st.columns([3, 1, 1])
                with col2:
                    send_button = st.button("é€ä¿¡", type="primary", use_container_width=True)
                with col3:
                    if st.button("ã‚¯ãƒªã‚¢"):
                        st.session_state.messages = []
                        st.rerun()
                
                if send_button and prompt:
                    st.session_state.messages.append({"role": "user", "content": prompt})
                    
                    if st.session_state.chat_session:
                        ci = _build_ci_context_for_chat(topology, _chat_target_id) if _chat_target_id else {}
                        ci_prompt = f"""ã‚ãªãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é‹ç”¨ï¼ˆNOC/SREï¼‰ã®å®Ÿå‹™è€…ã§ã™ã€‚
æ¬¡ã® CI æƒ…å ±ã¨ Config æŠœç²‹ã‚’å¿…ãšå‚ç…§ã—ã¦ã€å…·ä½“çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚ä¸€èˆ¬è«–ã ã‘ã§çµ‚ã‚ã‚‰ã›ãªã„ã§ãã ã•ã„ã€‚

ã€CI (JSON)ã€‘
{json.dumps(ci, ensure_ascii=False, indent=2)}

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
{prompt}

å›ç­”ãƒ«ãƒ¼ãƒ«:
- CI/Config ã«åŸºã¥ãå…·ä½“æ‰‹é †ãƒ»ã‚³ãƒãƒ³ãƒ‰ä¾‹ã‚’æç¤ºã™ã‚‹
- è¿½åŠ ç¢ºèªãŒå¿…è¦ãªã‚‰ã€è³ªå•ã¯æœ€å°é™ï¼ˆ1ã€œ2ç‚¹ï¼‰ã«çµã‚‹
- ä¸æ˜ãªå‰æã¯æ¨æ¸¬ã›ãšã€ŒCIã«ç„¡ã„ã®ã§ç¢ºèªãŒå¿…è¦ã€ã¨æ˜è¨˜ã™ã‚‹
"""
                        
                        with st.spinner("AI ãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                            try:
                                response = generate_content_with_retry(st.session_state.chat_session.model, ci_prompt, stream=False)
                                if response:
                                    full_response = response.text if hasattr(response, "text") else str(response)
                                    if not full_response.strip():
                                        full_response = "AIå¿œç­”ãŒç©ºã§ã—ãŸã€‚"
                                    st.session_state.messages.append({"role": "assistant", "content": full_response})
                                else:
                                    st.error("AIã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                            except Exception as e:
                                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        st.rerun()
            
            with tab2:
                if st.session_state.messages:
                    history_container = st.container(height=400)
                    with history_container:
                        for i, msg in enumerate(st.session_state.messages):
                            icon = "ğŸ¤–" if msg["role"] == "assistant" else "ğŸ‘¤"
                            with st.container(border=True):
                                st.markdown(f"{icon} **{msg['role'].upper()}** (ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ {i+1})")
                                st.markdown(msg["content"])
                else:
                    st.info("ä¼šè©±å±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")


# =====================================================
# ãƒ¡ã‚¤ãƒ³
# =====================================================
def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    api_key = render_sidebar()
    
    st.title("ğŸ›¡ï¸ AIOps ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆ")
    st.caption("è¤‡æ•°æ‹ ç‚¹ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯éšœå®³ã‚’çµ±åˆç®¡ç†ãƒ»åˆ†æ")
    
    active_site = st.session_state.get("active_site")
    
    if active_site:
        render_incident_cockpit(active_site, api_key)
    else:
        tab1, tab2 = st.tabs(["ğŸ“Š æ‹ ç‚¹çŠ¶æ…‹ãƒœãƒ¼ãƒ‰", "ğŸš¨ ãƒˆãƒªã‚¢ãƒ¼ã‚¸ãƒ»ã‚³ãƒãƒ³ãƒ‰ã‚»ãƒ³ã‚¿ãƒ¼"])
        
        with tab1:
            render_site_status_board()
        
        with tab2:
            render_triage_center()


if __name__ == "__main__":
    main()
