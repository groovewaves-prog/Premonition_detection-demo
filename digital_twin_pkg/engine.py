# digital_twin_pkg/engine.py  â€•  DigitalTwinEngine ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆPhase1 Predict API + RULäºˆæ¸¬ï¼‰
import logging
import time
import json
import uuid
import re
import os
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import asdict
import traceback

from .config import *
from .rules import EscalationRule, DEFAULT_RULES, MAINTENANCE_SIGNATURES
from .storage import StorageManager
from .audit import AuditBuilder
from .tuning import AutoTuner
from .bayesian import BayesianInferenceEngine
from .gnn import create_gnn_engine

try:
    from sentence_transformers import SentenceTransformer
    HAS_BERT = True
except ImportError:
    HAS_BERT = False

logger = logging.getLogger(__name__)



# ==============================================================
# Phase1: Predict API + Forecast Ledger  (digital_twin_pkg)
# ==============================================================

import traceback
from dataclasses import asdict as _asdict

# DTO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from dataclasses import dataclass as _dc, field as _field
from typing import Optional as _Opt

@_dc
class PredictRequest:
    tenant_id:  str
    device_id:  str
    msg:        str
    timestamp:  float
    attrs:      dict = _field(default_factory=dict)

    def to_dict(self):
        return {"tenant_id": self.tenant_id, "device_id": self.device_id,
                "msg": self.msg, "timestamp": self.timestamp, "attrs": self.attrs or {}}

@_dc
class PredictResult:
    predicted_state:      str
    confidence:           float
    rule_pattern:         str
    category:             str
    reasons:              list = _field(default_factory=list)
    recommended_actions:  list = _field(default_factory=list)
    runbook_url:          str  = ""
    criticality:          str  = "standard"
    time_to_critical_min: int  = 60
    early_warning_hours:  int  = 24
    time_to_failure_hours: int = 336  # â˜… RUL: ä»Šã‹ã‚‰å®Œå…¨æ•…éšœã¾ã§ï¼ˆæ™‚é–“ï¼‰
    predicted_failure_datetime: str = ""  # â˜… æ•…éšœç™ºç”Ÿäºˆæ¸¬æ—¥æ™‚ï¼ˆISOå½¢å¼ï¼‰

    def to_dict(self, affected_count: int = 0, source: str = "real"):
        return {
            "predicted_state":      self.predicted_state,
            "confidence":           float(self.confidence),
            "rule_pattern":         self.rule_pattern,
            "category":             self.category,
            "reasons":              self.reasons or [],
            "recommended_actions":  self.recommended_actions or [],
            "runbook_url":          self.runbook_url or "",
            "criticality":          self.criticality or "standard",
            "time_to_critical_min": int(self.time_to_critical_min),
            "early_warning_hours":  int(self.early_warning_hours),
            "time_to_failure_hours": int(self.time_to_failure_hours),
            "predicted_failure_datetime": self.predicted_failure_datetime,
            # â”€â”€ cockpit.py äº’æ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            "is_prediction":        True,
            "source":               source,
            "prob":                 float(self.confidence),
            "label":                f"ğŸ”® [äºˆå…†] {self.predicted_state}",
            "type":                 f"Predictive/{self.category}",
            "tier":                 1,
            "prediction_timeline":  f"{self.time_to_critical_min}åˆ†å¾Œ",
            "prediction_time_to_critical_min": int(self.time_to_critical_min),
            "prediction_early_warning_hours":  int(self.early_warning_hours),
            "prediction_affected_count":       int(affected_count),
            "prediction_time_to_failure_hours": int(self.time_to_failure_hours),
            "prediction_failure_datetime":      self.predicted_failure_datetime,
        }


class DigitalTwinEngine:
    def __init__(self, topology: Dict[str, Any], children_map: Optional[Dict[str, List[str]]] = None, tenant_id: str = "default"):
        if not tenant_id or len(tenant_id) > 64: raise ValueError("Invalid tenant_id")
        self.tenant_id = tenant_id.lower()
        self.topology = topology
        self.children_map = children_map or {}
        self.storage = StorageManager(self.tenant_id, BASE_DIR)
        self.tuner = AutoTuner(self)
        self.bayesian = BayesianInferenceEngine(self.storage)  # â˜… ãƒ™ã‚¤ã‚ºæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³
        self.gnn = create_gnn_engine(topology, children_map)  # â˜… GNNäºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³
        self.rules: List[EscalationRule] = []
        self._metric_rules: List[EscalationRule] = []
        self.history: List[Dict] = []
        self.outcomes: List[Dict] = []
        self.incident_register: List[Dict] = []
        self.maintenance_windows: List[Dict] = []
        self.evaluation_state: Dict = {}
        self.shadow_eval_state: Dict = {}
        self._model = None
        self._rule_embeddings = None
        self._model_loaded = False
        self._rules_sot = (os.environ.get(ENV_RULES_SOT, "json") or "json").strip().lower()
        self.reload_all()
        self._ensure_model_loaded()

    def reload_all(self):
        self._load_rules()
        self.history = self.storage.load_json("history", [])
        self.outcomes = self.storage.load_json("outcomes", [])
        self.incident_register = self.storage.load_json("incident_register", [])
        self.maintenance_windows = self.storage.load_json("maintenance_windows", [])
        self.evaluation_state = self.storage.load_json("evaluation_state", {})
        self.shadow_eval_state = self.storage.load_json("shadow_eval_state", {})
        self._init_forecast_ledger()

    def _sanitize_rule_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        return {k: v for k, v in data.items() if not k.startswith('_')}

    def _load_rules(self):
        loaded_from_db = False
        if self._rules_sot == "db":
            db_rules_json = self.storage.rule_config_get_all_json_strs()
            if db_rules_json:
                try:
                    self.rules = [EscalationRule(**self._sanitize_rule_data(json.loads(s))) for s in db_rules_json]
                    loaded_from_db = True
                except: pass
        if not loaded_from_db:
            path = self.storage.paths["rules"]
            if not os.path.exists(path):
                self.rules = [EscalationRule(**self._sanitize_rule_data(asdict(r))) for r in DEFAULT_RULES]
                self.storage.save_json_atomic("rules", [self._sanitize_rule_data(asdict(r)) for r in self.rules])
            else:
                try:
                    with open(path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    self.rules = [EscalationRule(**self._sanitize_rule_data(item)) for item in data]
                except Exception as e:
                    self.rules = [EscalationRule(**self._sanitize_rule_data(asdict(r))) for r in DEFAULT_RULES]
            self.storage._seed_rule_config_from_rules_json([self._sanitize_rule_data(asdict(r)) for r in self.rules])
        self._metric_rules = [r for r in self.rules if (r.requires_trend or r.requires_volatility) and r.trend_metric_regex]

    def _ensure_model_loaded(self):
        if self._model_loaded: return
        if not HAS_BERT:
            self._model_loaded = True
            return
        try:
            self._model = SentenceTransformer('all-MiniLM-L6-v2')
            phrases = []
            indices = []
            for idx, r in enumerate(self.rules):
                for p in r.semantic_phrases:
                    phrases.append(p)
                    indices.append(idx)
            if phrases:
                embeddings = self._model.encode(phrases, convert_to_numpy=True)
                self._rule_embeddings = {"vectors": embeddings, "indices": indices}
            self._model_loaded = True
        except: self._model_loaded = True

    def _match_rule(self, alarm_text: str) -> Tuple[Optional[EscalationRule], float]:
        text_lower = alarm_text.lower()
        for rule in self.rules:
            if rule._compiled_regex and rule._compiled_regex.search(alarm_text):
                return rule, 1.0
            if rule.pattern in text_lower:
                return rule, 1.0
        if self._model and self._rule_embeddings:
            try:
                query_vec = self._model.encode([alarm_text], convert_to_numpy=True)
                rule_vecs = self._rule_embeddings["vectors"]
                similarities = np.dot(rule_vecs, query_vec.T).flatten()
                norms = np.linalg.norm(rule_vecs, axis=1) * np.linalg.norm(query_vec)
                cosine_sim = similarities / np.where(norms==0, 1e-10, norms)
                best_idx = np.argmax(cosine_sim)
                best_score = float(cosine_sim[best_idx])
                rule_idx = self._rule_embeddings["indices"][best_idx]
                rule = self.rules[rule_idx]
                if best_score >= (rule.embedding_threshold or 0.40):
                    return rule, best_score
            except Exception: pass
        return None, 0.0

    def _calculate_confidence(self, rule: EscalationRule, device_id: str, match_quality: float) -> float:
        attrs = self.topology.get(device_id, {})
        if not isinstance(attrs, dict):
            try: attrs = vars(attrs)
            except: attrs = {}
        rg = attrs.get('redundancy_group')
        has_redundancy = bool(rg)
        children = self.children_map.get(device_id, [])
        is_spof = bool(children and not has_redundancy)
        confidence = rule.base_confidence
        confidence *= (0.8 + 0.2 * match_quality)
        if has_redundancy: confidence *= (1.0 - ROI_CONSERVATIVE_FACTOR * 0.2)
        if is_spof: confidence *= 1.1
        return min(0.99, max(0.1, confidence))

    def _sanitize_for_llm(self, text: str) -> str:
        """
        LLMé€ä¿¡å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚µãƒ‹ã‚¿ã‚¤ã‚º
        
        - IPã‚¢ãƒ‰ãƒ¬ã‚¹ã®ãƒã‚¹ã‚­ãƒ³ã‚°
        - ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆæƒ…å ±ã®é™¤å»
        - æ©Ÿå¯†æƒ…å ±ã®åŒ¿ååŒ–
        """
        import re
        
        sanitized = text
        
        # IPv4ã‚¢ãƒ‰ãƒ¬ã‚¹ã®ãƒã‚¹ã‚­ãƒ³ã‚°
        sanitized = re.sub(
            r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b',
            'IP_MASKED',
            sanitized
        )
        
        # IPv6ã‚¢ãƒ‰ãƒ¬ã‚¹ã®ãƒã‚¹ã‚­ãƒ³ã‚°
        sanitized = re.sub(
            r'\b(?:[0-9a-fA-F]{1,4}:){7}[0-9a-fA-F]{1,4}\b',
            'IPV6_MASKED',
            sanitized
        )
        
        # MACã‚¢ãƒ‰ãƒ¬ã‚¹ã®ãƒã‚¹ã‚­ãƒ³ã‚°
        sanitized = re.sub(
            r'\b(?:[0-9a-fA-F]{2}[:-]){5}[0-9a-fA-F]{2}\b',
            'MAC_MASKED',
            sanitized
        )
        
        # ãƒ›ã‚¹ãƒˆåã®ä¸€èˆ¬åŒ–ï¼ˆprod-, dev-, test-ãªã©ã‚’é™¤å»ï¼‰
        sanitized = re.sub(
            r'\b(prod|dev|test|stage|staging)-[\w-]+',
            'HOSTNAME_MASKED',
            sanitized,
            flags=re.IGNORECASE
        )
        
        # ASN (ASç•ªå·)ã®ãƒã‚¹ã‚­ãƒ³ã‚°
        sanitized = re.sub(
            r'\bAS\d+\b',
            'AS_MASKED',
            sanitized
        )
        
        # VLAN IDã®ãƒã‚¹ã‚­ãƒ³ã‚°
        sanitized = re.sub(
            r'\bVLAN\s*\d+\b',
            'VLAN_MASKED',
            sanitized,
            flags=re.IGNORECASE
        )
        
        return sanitized


    def _generate_smart_recommendations(
        self,
        rule_pattern: str,
        affected_count: int,
        base_actions: list,
    ) -> list:
        """
        ã‚·ã‚°ãƒŠãƒ«ä»¶æ•°ï¼ˆaffected_countï¼‰ã«åŸºã¥ã„ã¦é™çš„ãƒ«ãƒ¼ãƒ«ã§æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®šã™ã‚‹ã€‚
        å¤–éƒ¨LLMã¯ä½¿ç”¨ã—ãªã„ï¼ˆå³æ™‚ãƒ»æ±ºå®šè«–çš„ãƒ»å„ªå…ˆé †åºã‚’æ˜ç¤ºåˆ¶å¾¡ï¼‰ã€‚

        é–¾å€¤:
          1ã€œ2ä»¶ : å€‹åˆ¥éƒ¨å“æ•…éšœ â†’ å˜ä½“SFP/ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å¯¾å¿œ
          3ã€œ4ä»¶ : ãƒ©ã‚¤ãƒ³ã‚«ãƒ¼ãƒ‰/ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å˜ä½ã®å•é¡Œ
          5ä»¶ä»¥ä¸Š: ç­ä½“ãƒ¬ãƒ™ãƒ«ï¼ˆé›»æºãƒ»ãƒ•ã‚¡ãƒ¼ãƒ ã‚¦ã‚§ã‚¢ãƒ»åŸºæ¿ï¼‰ã®å•é¡Œ
        """
        WIDE_RANGE_THRESHOLD = 5
        MID_RANGE_THRESHOLD  = 3

        if "optical" in rule_pattern:
            if affected_count >= WIDE_RANGE_THRESHOLD:
                return [
                    {
                        "title": "ç­ä½“é›»æºç³»çµ±ã®ç¢ºèªï¼ˆPSUå†—é•·ãƒ»è² è·çŠ¶æ³ï¼‰",
                        "effect": f"{affected_count}å€‹ã®å…‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒæ™‚åŠ£åŒ–ã®ä¸»å› ã‚’æ’é™¤",
                        "priority": "high",
                        "rationale": f"{affected_count}å€‹ãŒåŒæ™‚åŠ£åŒ– â†’ å˜ç™ºSFPæ•…éšœã§ã¯èª¬æ˜å›°é›£ã€‚é›»æºé›»åœ§ä¸å®‰å®šã‚’æœ€åˆã«ç–‘ã†ã€‚",
                        "steps": "1. show environment power\n2. show platform\n3. å„PSUã®å‡ºåŠ›é›»åœ§/è² è·ç‡ã‚’ç¢ºèª"
                    },
                    {
                        "title": "ç­ä½“å†…æ¸©åº¦ãƒ»å†·å´ãƒ•ã‚¡ãƒ³ã®ç¢ºèª",
                        "effect": "éç†±ã«ã‚ˆã‚‹å…‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç‰¹æ€§åŠ£åŒ–ã‚’è§£æ¶ˆ",
                        "priority": "high",
                        "rationale": "åºƒç¯„å›²ã®å…‰ä¿¡å·åŠ£åŒ–ã¯ç­ä½“å†…éç†±ã§ã‚‚ç™ºç”Ÿã™ã‚‹ã€‚",
                        "steps": "1. show environment temperature\n2. show environment fan\n3. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ç©ºèª¿çŠ¶æ³ã‚‚ç¢ºèª"
                    },
                    {
                        "title": "IOS/ãƒ•ã‚¡ãƒ¼ãƒ ã‚¦ã‚§ã‚¢ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ç¢ºèª",
                        "effect": "ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢èµ·å› ã®èª¤æ¤œçŸ¥ãƒ»å…‰åˆ¶å¾¡ç•°å¸¸ã‚’è§£æ¶ˆ",
                        "priority": "medium",
                        "rationale": "æ—¢çŸ¥ã®ãƒã‚°ã§å…‰ãƒ‘ãƒ¯ãƒ¼èª­ã¿å€¤ãŒç•°å¸¸ã«ãªã‚‹ã‚±ãƒ¼ã‚¹ã‚ã‚Šã€‚ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆç¢ºèªã€‚",
                        "steps": "1. show version\n2. ãƒ™ãƒ³ãƒ€ãƒ¼ã®æ—¢çŸ¥éšœå®³æƒ…å ±ã‚’ç…§åˆ\n3. è©²å½“ãƒã‚°ãŒã‚ã‚Œã°ãƒ‘ãƒƒãƒé©ç”¨ã‚’æ¤œè¨"
                    },
                    {
                        "title": "SFPãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å€‹åˆ¥ç¢ºèªï¼ˆæœ€çµ‚æ‰‹æ®µï¼‰",
                        "effect": "æ®‹ç•™ã™ã‚‹å€‹åˆ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ•…éšœã‚’è§£æ¶ˆ",
                        "priority": "low",
                        "rationale": f"ä¸Šè¨˜ã§è§£æ¶ˆã—ãªã„å ´åˆã®ã¿ã€‚{affected_count}å€‹å…¨äº¤æ›ã¯è²»ç”¨å¯¾åŠ¹æœãŒä½ã„ã€‚",
                        "steps": "1. show interfaces transceiver\n2. Rx/Tx PowerãŒé–¾å€¤å¤–ã®ãƒãƒ¼ãƒˆã‚’ç‰¹å®š\n3. è©²å½“SFPã®ã¿äº¤æ›"
                    },
                ]
            elif affected_count >= MID_RANGE_THRESHOLD:
                return [
                    {
                        "title": "è©²å½“ãƒ©ã‚¤ãƒ³ã‚«ãƒ¼ãƒ‰ï¼ã‚¹ãƒ­ãƒƒãƒˆã®ç¢ºèª",
                        "effect": f"{affected_count}å€‹ãŒåŒä¸€ã‚«ãƒ¼ãƒ‰ã«é›†ä¸­ã—ã¦ã„ã‚‹å ´åˆã€ã‚«ãƒ¼ãƒ‰äº¤æ›ã§è§£æ±º",
                        "priority": "high",
                        "rationale": "è¤‡æ•°ãƒãƒ¼ãƒˆãŒåŒã˜ãƒ©ã‚¤ãƒ³ã‚«ãƒ¼ãƒ‰ã«å±ã—ã¦ã„ã‚‹å ´åˆã¯ã‚«ãƒ¼ãƒ‰éšœå®³ãŒä¸»å› ã€‚",
                        "steps": "1. show interfaces transceiver ã§å½±éŸ¿ãƒãƒ¼ãƒˆã®ã‚¹ãƒ­ãƒƒãƒˆã‚’ç¢ºèª\n2. show platform slot ã§è©²å½“ã‚¹ãƒ­ãƒƒãƒˆã®çŠ¶æ…‹ã‚’ç¢ºèª\n3. åŒã‚¹ãƒ­ãƒƒãƒˆé›†ä¸­ãªã‚‰äºˆå‚™ã‚«ãƒ¼ãƒ‰ã¨äº¤æ›"
                    },
                    {
                        "title": "å…‰ãƒ•ã‚¡ã‚¤ãƒãƒ¼ã®æ¥ç¶šçŠ¶æ…‹ãƒ»æ¸…æƒ",
                        "effect": "ã‚³ãƒã‚¯ã‚¿æ±šã‚Œãƒ»æ›²ã’ã«ã‚ˆã‚‹å…‰æå¤±ã‚’å›å¾©",
                        "priority": "medium",
                        "rationale": "è¤‡æ•°ãƒãƒ¼ãƒˆã§åŒæ™‚ã«å…‰æå¤± â†’ ãƒ‘ãƒƒãƒãƒ‘ãƒãƒ«å´ã®å…±é€šéšœå®³ã‚‚ç–‘ã†ã€‚",
                        "steps": "1. å…‰ã‚³ãƒã‚¯ã‚¿ã‚’é¡•å¾®é¡æ¤œæŸ»\n2. ã‚¢ãƒ«ã‚³ãƒ¼ãƒ«ç¶¿æ£’ã§æ¸…æƒ\n3. Rx Powerã‚’å†æ¸¬å®š"
                    },
                    {
                        "title": "SFPãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å€‹åˆ¥ç¢ºèª",
                        "effect": "æ•…éšœãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç‰¹å®šãƒ»äº¤æ›",
                        "priority": "low",
                        "rationale": "ä¸Šè¨˜ã§æ”¹å–„ã—ãªã„å ´åˆã«å€‹åˆ¥SFPã‚’äº¤æ›ã€‚",
                        "steps": "1. show interfaces transceiver detail\n2. Rx Poweræœ€ä½å€¤ã®ãƒãƒ¼ãƒˆã‹ã‚‰é †ã«äº¤æ›"
                    },
                ]
            else:
                return base_actions

        elif "microburst" in rule_pattern:
            if affected_count >= WIDE_RANGE_THRESHOLD:
                return [
                    {
                        "title": "ASICï¼ãƒãƒƒãƒ—ã‚»ãƒƒãƒˆã®è¨ºæ–­",
                        "effect": f"{affected_count}å€‹ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ã®ãƒãƒƒãƒ•ã‚¡å•é¡Œã‚’æ ¹æœ¬è§£æ¶ˆ",
                        "priority": "high",
                        "rationale": "åºƒç¯„å›²ã®queue dropsã¯ASICã®ãƒã‚°ãƒ»æ•…éšœã®å¯èƒ½æ€§ãŒé«˜ã„ã€‚",
                        "steps": "1. show platform resources\n2. show platform hardware\n3. ãƒ™ãƒ³ãƒ€ãƒ¼ã®ASICæ—¢çŸ¥ãƒã‚°ã‚’ç…§åˆ"
                    },
                    {
                        "title": "IOS/ãƒ•ã‚¡ãƒ¼ãƒ ã‚¦ã‚§ã‚¢ã®ãƒã‚°ç¢ºèª",
                        "effect": "QoSå‡¦ç†ã®ç•°å¸¸ã‚’è§£æ¶ˆ",
                        "priority": "high",
                        "rationale": "è¤‡æ•°ãƒãƒ¼ãƒˆåŒæ™‚ç™ºç”Ÿã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãƒã‚°ã®å¯èƒ½æ€§ã€‚",
                        "steps": "1. show version\n2. ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã§QoSé–¢é€£ã®ãƒã‚°ã‚’ç¢ºèª\n3. ä¿®æ­£æ¸ˆã¿ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¸ã®ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰"
                    },
                    {
                        "title": "ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ",
                        "effect": "ç•°å¸¸ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ç™ºç”Ÿæºã®ç‰¹å®šãƒ»é®æ–­",
                        "priority": "medium",
                        "rationale": "DDoSãƒ»ç•°å¸¸ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚‹å…¨ãƒãƒ¼ãƒˆåŒæ™‚è¼»è¼³ã®å¯èƒ½æ€§ã€‚",
                        "steps": "1. show interfaces | include drops\n2. NetFlow/sFlowã§ç•°å¸¸ãƒ•ãƒ­ãƒ¼ã‚’ç‰¹å®š\n3. ACLã§é®æ–­"
                    },
                    {
                        "title": "QoSãƒãƒªã‚·ãƒ¼ã®æœ€é©åŒ–",
                        "effect": "ãƒãƒƒãƒ•ã‚¡å‰²ã‚Šå½“ã¦ã‚’æ”¹å–„ã—ä¸€æ™‚çš„ãªè¼»è¼³ã‚’ç·©å’Œ",
                        "priority": "low",
                        "rationale": "æ ¹æœ¬è§£æ±ºå¾Œã®æœ€é©åŒ–ã¨ã—ã¦å®Ÿæ–½ã€‚",
                        "steps": "1. show policy-map interface\n2. ã‚­ãƒ¥ãƒ¼æ·±åº¦ãƒ»é‡ã¿ä»˜ã‘ã‚’èª¿æ•´"
                    },
                ]
            else:
                return base_actions

        elif "route_instability" in rule_pattern or "bgp" in rule_pattern:
            if affected_count >= MID_RANGE_THRESHOLD:
                return [
                    {
                        "title": "BGPè¨­å®šã®åŒ…æ‹¬çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼",
                        "effect": f"{affected_count}å€‹ã®ãƒ”ã‚¢ã®ä¸å®‰å®šã•ã‚’è§£æ¶ˆ",
                        "priority": "high",
                        "rationale": "è¤‡æ•°ãƒ”ã‚¢åŒæ™‚ä¸å®‰å®š â†’ è¨­å®šãƒŸã‚¹ or ä¸ŠæµISPå´ã®å•é¡Œã‚’æœ€åˆã«ç¢ºèªã€‚",
                        "steps": "1. show bgp summary\n2. å„ãƒ”ã‚¢ã®hold-timer/keepaliveè¨­å®šã‚’ç¢ºèª\n3. ä¸ŠæµISPã«NOCå•ã„åˆã‚ã›"
                    },
                    {
                        "title": "IOS/ãƒ•ã‚¡ãƒ¼ãƒ ã‚¦ã‚§ã‚¢ã®BGPå®Ÿè£…ç¢ºèª",
                        "effect": "BGPå‡¦ç†ãƒã‚°ã«ã‚ˆã‚‹çµŒè·¯ä¸å®‰å®šã‚’å›é¿",
                        "priority": "medium",
                        "rationale": "æ—¢çŸ¥ã®BGPå®Ÿè£…ãƒã‚°ã§è¤‡æ•°ãƒ”ã‚¢åŒæ™‚ãƒ•ãƒ©ãƒƒãƒ—ãŒç™ºç”Ÿã™ã‚‹ã‚±ãƒ¼ã‚¹ã‚ã‚Šã€‚",
                        "steps": "1. show version\n2. ãƒ™ãƒ³ãƒ€ãƒ¼ã®æ—¢çŸ¥BGPãƒã‚°ã‚’ç…§åˆ\n3. ä¿®æ­£ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¸ã®ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚’æ¤œè¨"
                    },
                    {
                        "title": "BGPãƒ•ãƒ©ãƒƒãƒ—ãƒ€ãƒ³ãƒ”ãƒ³ã‚°ã®è¨­å®š",
                        "effect": "ä¸å®‰å®šãªãƒ”ã‚¢ã®çµŒè·¯åºƒå ±ã‚’æŠ‘åˆ¶",
                        "priority": "low",
                        "rationale": "æ ¹æœ¬è§£æ±ºãŒé›£ã—ã„å ´åˆã®ç·©å’Œç­–ã€‚",
                        "steps": "1. bgp dampening ã‚³ãƒãƒ³ãƒ‰ã‚’è¨­å®š\n2. show bgp dampened-paths ã§æŠ‘åˆ¶çŠ¶æ³ã‚’ç¢ºèª"
                    },
                ]
            else:
                return base_actions

        else:
            if affected_count >= WIDE_RANGE_THRESHOLD:
                return base_actions + [
                    {
                        "title": "ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®å¥å…¨æ€§ç¢ºèª",
                        "effect": f"{affected_count}ä»¶ã®ã‚·ã‚°ãƒŠãƒ«ã®æ ¹æœ¬åŸå› ã‚’ç‰¹å®š",
                        "priority": "high",
                        "rationale": "åºƒç¯„å›²ã®ã‚·ã‚°ãƒŠãƒ«ç™ºç”Ÿã¯é›»æºãƒ»ãƒ•ã‚¡ãƒ¼ãƒ ã‚¦ã‚§ã‚¢ãƒ»ç’°å¢ƒå•é¡Œã‚’ç–‘ã†ã€‚",
                        "steps": "1. show environment all\n2. show version\n3. ãƒ™ãƒ³ãƒ€ãƒ¼ã‚µãƒãƒ¼ãƒˆã¸ã®ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¤œè¨"
                    }
                ]
            return base_actions


    def predict(self, analysis_results: List[Dict], msg_map: Dict[str, List[str]], alarms: Optional[List] = None) -> List[Dict]:
        self.reload_all()
        predictions = []
        critical_ids = {r["id"] for r in analysis_results if r.get("status") in ["RED", "CRITICAL"] or r.get("severity") == "CRITICAL" or float(r.get("prob", 0)) >= 0.85}
        warning_ids = {r["id"] for r in analysis_results if 0.45 <= float(r.get("prob", 0)) <= 0.85}
        active_ids = set(msg_map.keys())
        candidates = (warning_ids.union(active_ids)) - critical_ids
        processed_devices = set()
        multi_signal_boost = 0.05
        
        for dev_id in candidates:
            if dev_id in processed_devices: continue
            messages = msg_map.get(dev_id, [])
            if not messages: continue
            matched_signals = []
            for msg in messages:
                rule, quality = self._match_rule(msg)
                if rule and quality >= 0.30 and rule.pattern != "generic_error":
                    matched_signals.append((rule, quality, msg))
            if not matched_signals:
                rule, quality = self._match_rule(messages[0])
                if not rule: continue
                matched_signals = [(rule, quality, messages[0])]

            matched_signals.sort(key=lambda x: x[1], reverse=True)
            primary_rule, primary_quality, primary_msg = matched_signals[0]
            confidence = self._calculate_confidence(primary_rule, dev_id, primary_quality)
            extra_signals = len(matched_signals) - 1
            if extra_signals > 0:
                boost = min(extra_signals * multi_signal_boost, 0.20)
                confidence = min(0.99, confidence + boost)
            
            # â˜… ãƒ™ã‚¤ã‚ºæ¨è«–ã«ã‚ˆã‚‹ä¿¡é ¼åº¦ã®æ›´æ–°
            confidence, bayesian_debug = self.bayesian.calculate_posterior_confidence(
                device_id=dev_id,
                rule_pattern=primary_rule.pattern,
                current_confidence=confidence,
                time_window_hours=168  # éå»7æ—¥é–“
            )
            
            # â˜… GNNäºˆæ¸¬ã«ã‚ˆã‚‹ä¿¡é ¼åº¦ã®è£œæ­£ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if self.gnn and self._model:
                try:
                    # ç¾åœ¨ã®ã‚¢ãƒ©ãƒ¼ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’BERTåŸ‹ã‚è¾¼ã¿ã«å¤‰æ›
                    alarm_embeddings = {}
                    for msg_dev_id, msg_list in msg_map.items():
                        if msg_list:
                            # è¤‡æ•°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å¹³å‡åŸ‹ã‚è¾¼ã¿
                            embeddings = self._model.encode(msg_list, convert_to_numpy=True)
                            alarm_embeddings[msg_dev_id] = embeddings.mean(axis=0)
                    
                    # GNNã§äºˆæ¸¬
                    gnn_confidence, gnn_ttf = self.gnn.predict_with_gnn(
                        alarm_embeddings, dev_id
                    )
                    
                    # ãƒ™ã‚¤ã‚ºæ¨è«–ã¨GNNäºˆæ¸¬ã®åŠ é‡å¹³å‡ï¼ˆGNNã®é‡ã¿ã¯æ§ãˆã‚ï¼‰
                    confidence = 0.7 * confidence + 0.3 * gnn_confidence
                    confidence = min(0.99, max(0.1, confidence))
                    
                except Exception as e:
                    logger.warning(f"GNN prediction failed: {e}")

            threshold = MIN_PREDICTION_CONFIDENCE
            if primary_rule.paging_threshold is not None:
                threshold = primary_rule.paging_threshold
            if confidence < threshold: continue

            impact_count = 0
            if dev_id in self.children_map:
                impact_count = len(self.children_map[dev_id])
            
            # â˜… ã‚·ã‚°ãƒŠãƒ«ä»¶æ•°ï¼ˆmatched_signalsæ•°ï¼‰ã‚’ affected_count ã¨ã—ã¦ä½¿ç”¨
            # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹åã®æœ‰ç„¡ã«é–¢ã‚ã‚‰ãšã‚·ã‚°ãƒŠãƒ«æ•°ãŒå®Ÿæ…‹ã‚’æœ€ã‚‚æ­£ç¢ºã«è¡¨ã™
            import re as _re_comp
            unique_components = set()
            for _, _, _m in matched_signals:
                unique_components.update(
                    _re_comp.findall(r'\b(?:Gi|Te|Fa|Et)\d+/\d+/\d+|\b(?:Gi|Te|Fa|Et)\d+/\d+', _m))
            # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹åãŒæŠ½å‡ºã§ããŸå ´åˆã¯ãã‚Œã‚’ã€ã§ããªã„å ´åˆã¯ã‚·ã‚°ãƒŠãƒ«ä»¶æ•°ã‚’ä½¿ç”¨
            component_count = len(unique_components) if unique_components else len(matched_signals)

            smart_actions = self._generate_smart_recommendations(
                rule_pattern=primary_rule.pattern,
                affected_count=component_count,
                base_actions=primary_rule.recommended_actions,
            )
            
            pred = {
                "id": dev_id,
                "label": f"ğŸ”® [äºˆå…†] {primary_rule.escalated_state}",
                "severity": "CRITICAL",
                "status": "CRITICAL",
                "prob": round(confidence, 2),
                "type": f"Predictive/{primary_rule.category}",
                "tier": 1,
                "reason": f"Digital Twin Prediction: {primary_rule.time_to_critical_min}min to critical. Root: {primary_msg}",
                "is_prediction": True,
                "prediction_timeline": f"{primary_rule.time_to_critical_min}åˆ†å¾Œ",
                "prediction_time_to_critical_min": primary_rule.time_to_critical_min,
                "prediction_early_warning_hours": primary_rule.early_warning_hours,
                "prediction_affected_count": impact_count,
                "prediction_signal_count": len(matched_signals),
                "prediction_confidence_factors": {"base": primary_rule.base_confidence, "match_quality": primary_quality},
                "recommended_actions": smart_actions,  # LLMãƒ™ãƒ¼ã‚¹ã®å‹•çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
                "base_recommended_actions": primary_rule.recommended_actions,  # å…ƒã®å›ºå®šã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆå‚è€ƒç”¨ï¼‰
                "runbook_url": primary_rule.runbook_url
            }
            pid = str(uuid.uuid4())
            self.history.append({"prediction_id": pid, "device_id": dev_id, "rule_pattern": primary_rule.pattern, "timestamp": time.time(), "prob": confidence, "anchor_event_time": time.time(), "raw_msg": primary_msg})
            self.storage.save_json_atomic("history", self.history)
            predictions.append(pred)
            processed_devices.add(dev_id)
        return predictions

    def generate_tuning_report(self, days: int = 30) -> Dict[str, Any]:
        return self.tuner.generate_report(days)

    def apply_tuning_proposals_if_auto(self, proposals: List[Dict]) -> Dict:
        applied = []
        skipped = []
        with self.storage.global_lock(timeout_sec=30.0):
            for p in proposals:
                rp = p.get("rule_pattern")
                rec = p.get("apply_recommendation", {})
                if rec.get("apply_mode") != "auto":
                    skipped.append({"rule": rp, "reason": "not_auto"})
                    continue
                prop = p.get("proposal", {})
                pt = float(prop.get("paging_threshold", 0.0))
                lt = float(prop.get("logging_threshold", 0.0))
                old_json_str = self.storage.rule_config_get_json_str(rp)
                rj_str = old_json_str
                if rj_str:
                    d = json.loads(rj_str)
                    d["paging_threshold"] = pt
                    d["logging_threshold"] = lt
                    rj_str = json.dumps(d, ensure_ascii=False)
                success = self.storage.rule_config_upsert(rp, pt, lt, rj_str)
                if success:
                    applied.append({"rule": rp, "paging": pt})
                else:
                    skipped.append({"rule": rp, "reason": "db_write_fail"})
        return {"applied": applied, "skipped": skipped}

    def repair_db_from_rules_json(self) -> bool:
        try:
            path = self.storage.paths["rules"]
            if not os.path.exists(path): return False
            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            sanitized = [self._sanitize_rule_data(item) for item in data]
            self.storage._seed_rule_config_from_rules_json(sanitized)
            return True
        except Exception: return False
    # ==============================================================
    # Phase1: Predict API helpers
    # ==============================================================

    def _parse_timestamp(self, ts) -> float:
        if ts is None:
            return time.time()
        if isinstance(ts, (int, float)):
            return float(ts)
        s = str(ts).strip()
        try:
            return float(s)
        except Exception:
            pass
        try:
            from datetime import datetime as _dt
            return _dt.fromisoformat(s.replace("Z", "+00:00")).timestamp()
        except Exception:
            return time.time()

    def _should_ignore(self, msg: str) -> bool:
        m = (msg or "").lower()
        ignore = ["dry-run", "test message", "synthetic-monitor", "healthcheck"]
        return any(ph in m for ph in ignore)

    def _rule_match_simple(self, rule, msg: str):
        """regex + semantic phrase ãƒãƒƒãƒã€‚(hit, reasons) ã‚’è¿”ã™"""
        reasons = []
        hit = False
        try:
            if rule._compiled_regex and rule._compiled_regex.search(msg or ""):
                hit = True
                reasons.append(f"pattern matched: {rule.pattern}")
        except Exception:
            pass
        if not hit:
            low = (msg or "").lower()
            for sp in (rule.semantic_phrases or []):
                if sp and sp.lower() in low:
                    hit = True
                    reasons.append(f"semantic hit: {sp}")
                    break
        return hit, reasons

    def predict(self, device_id: str, msg: str, timestamp: float,
                attrs: Optional[Dict[str, Any]] = None,
                degradation_level: int = 1,
                source: str = "real") -> List[Dict[str, Any]]:
        """
        EscalationRule ãƒ™ãƒ¼ã‚¹ã®äºˆå…†äºˆæ¸¬ã€‚
        degradation_level (1-5): Level ã«å¿œã˜ã¦ confidence ã‚’ãƒ–ãƒ¼ã‚¹ãƒˆã€
                                  time_to_critical ã‚’çŸ­ç¸®ã€early_warning ã‚’å»¶é•·ã€‚
        source: "simulation" | "real"
        æˆ»ã‚Šå€¤ã¯ PredictResult.to_dict() ã®ãƒªã‚¹ãƒˆï¼ˆconfidence é™é †ï¼‰ã€‚
        """
        try:
            msg_n = self._normalize_msg(msg or "")
        except AttributeError:
            msg_n = (msg or "").strip()
        except Exception:
            msg_n = (msg or "").strip()

        if self._should_ignore(msg_n):
            return []

        _min_conf = float(MIN_PREDICTION_CONFIDENCE)

        # Level ãƒ–ãƒ¼ã‚¹ãƒˆä¿‚æ•°ï¼ˆLevel1=0.0 â†’ Level5=0.20ï¼‰
        _level = max(1, min(5, int(degradation_level or 1)))
        _conf_boost    = (_level - 1) * 0.05          # +0.00ã€œ+0.20
        _ttc_factor    = 1.0 - (_level - 1) * 0.12   # Ã—1.0ã€œÃ—0.52ï¼ˆçŸ­ç¸®ï¼‰
        _early_factor  = 1.0 + (_level - 1) * 0.20   # Ã—1.0ã€œÃ—1.80ï¼ˆå»¶é•·ï¼‰
        
        # â˜… RUL (Remaining Useful Life) äºˆæ¸¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Temporal GNNè«–æ–‡: time_to_failure = f(degradation_level)
        # Levelâ†‘ â†’ æ•…éšœãŒè¿‘ã„ â†’ RULâ†“
        _ttf_scale = (6 - _level) / 5  # L1=1.0(åˆæœŸ), L5=0.2(æœ«æœŸ)
        # L1=100%, L2=80%, L3=60%, L4=40%, L5=20%

        # å½±éŸ¿ç¯„å›²: children_map ã‹ã‚‰å†å¸°çš„ã«é…ä¸‹ãƒ‡ãƒã‚¤ã‚¹æ•°ã‚’ç®—å‡º
        def _count_children(dev_id: str, visited=None) -> int:
            if visited is None: visited = set()
            if dev_id in visited: return 0
            visited.add(dev_id)
            children = (self.children_map or {}).get(dev_id, [])
            return len(children) + sum(_count_children(c, visited) for c in children)

        _affected_count = _count_children(device_id)

        results = []
        for rule in (self.rules or []):
            try:
                hit, reasons = self._rule_match_simple(rule, msg_n)
                if not hit:
                    continue
                base_conf = float(getattr(rule, "base_confidence", 0.5) or 0.5)
                conf = min(0.99, base_conf + _conf_boost)
                if conf < _min_conf:
                    continue
                _base_ttc   = int(getattr(rule, "time_to_critical_min", 60) or 60)
                _base_early = int(getattr(rule, "early_warning_hours", 24) or 24)
                _ttc   = max(5,  int(_base_ttc   * _ttc_factor))
                _early = max(1,  int(_base_early * _early_factor))
                
                # â˜… RULè¨ˆç®—: early_warning_hours ã‚’ãƒ™ãƒ¼ã‚¹ã«æ•…éšœã¾ã§ã®æ™‚é–“ã‚’ç®—å‡º
                _base_ttf_hours = int(getattr(rule, "early_warning_hours", 336) or 336)
                _ttf_hours = max(1, int(_base_ttf_hours * _ttf_scale))
                # L1=336h(14æ—¥), L2=269h(11æ—¥), L3=202h(8æ—¥), L4=134h(6æ—¥), L5=67h(3æ—¥)
                
                # æ•…éšœäºˆæ¸¬æ—¥æ™‚ã‚’ç®—å‡º
                from datetime import datetime, timedelta
                _failure_dt = datetime.now() + timedelta(hours=_ttf_hours)
                _failure_dt_str = _failure_dt.strftime("%Y-%m-%d %H:%M")
                
                pr = PredictResult(
                    predicted_state      = str(getattr(rule, "escalated_state", "unknown")),
                    confidence           = conf,
                    rule_pattern         = str(getattr(rule, "pattern", "unknown")),
                    category             = str(getattr(rule, "category", "Generic")),
                    reasons              = reasons,
                    recommended_actions  = list(getattr(rule, "recommended_actions", []) or []),
                    runbook_url          = str(getattr(rule, "runbook_url", "") or ""),
                    criticality          = str(getattr(rule, "criticality", "standard") or "standard"),
                    time_to_critical_min = _ttc,
                    early_warning_hours  = _early,
                    time_to_failure_hours = _ttf_hours,
                    predicted_failure_datetime = _failure_dt_str,
                )
                # â˜… ã‚·ã‚°ãƒŠãƒ«ä»¶æ•°ãƒ™ãƒ¼ã‚¹ã®é™çš„ãƒ«ãƒ¼ãƒ«ã§æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®šï¼ˆå¤–éƒ¨LLMä¸ä½¿ç”¨ï¼‰
                import re as _re_comp
                _all_messages: List[str] = (attrs or {}).get("all_messages", [])
                if not _all_messages:
                    _all_messages = [msg]

                # affected_count: å…¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æŠ½å‡ºã—ãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹æ•° or ã‚·ã‚°ãƒŠãƒ«ä»¶æ•°
                # â€» deg_level * 2 ã«ã‚ˆã‚‹éå¤§è©•ä¾¡ã¯è¡Œã‚ãªã„
                _all_components: set = set()
                for _am in _all_messages:
                    _all_components.update(
                        _re_comp.findall(
                            r'\b(?:Gi|Te|Fa|Et)\d+/\d+/\d+|\b(?:Gi|Te|Fa|Et)\d+/\d+', _am or ""))
                _affected_est = len(_all_components) if _all_components else len(_all_messages)

                _rule_pat  = str(getattr(rule, "pattern", "unknown"))
                _base_acts = list(getattr(rule, "recommended_actions", []) or [])

                _smart_acts = self._generate_smart_recommendations(
                    rule_pattern   = _rule_pat,
                    affected_count = _affected_est,
                    base_actions   = _base_acts,
                )
                if _smart_acts != _base_acts:
                    pr.recommended_actions = _smart_acts
                    logger.debug(f"[Static] smart actions applied for {device_id} "
                                 f"(pattern={_rule_pat}, affected={_affected_est})")

                results.append(pr)
            except Exception:
                continue
        results.sort(key=lambda x: x.confidence, reverse=True)
        return [r.to_dict(affected_count=_affected_count, source=source) for r in results]

    def predict_api(self, request: Dict[str, Any]) -> Dict[str, Any]:
        """
        Cockpit / Simulator å…±é€šã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã€‚
        record_forecast=True (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ) ã®ã¨ã forecast_ledger ã«ç™»éŒ²ã™ã‚‹ã€‚

        â˜… ãƒãƒƒãƒå¯¾å¿œ: request ã« "messages" (List[str]) ã‚’å«ã‚ã‚‹ã¨
           å…¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½¿ã£ã¦LLMæ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã€‚
           "msg" ã¯å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã«æ®‹ã™ã€‚
        """
        try:
            tenant_id = (request.get("tenant_id") or self.tenant_id or "default").strip().lower()
            device_id = str(request.get("device_id") or "").strip()
            ts        = self._parse_timestamp(request.get("timestamp"))
            if not device_id:
                raise ValueError("device_id is required")

            # â˜… "messages" (è¤‡æ•°) ã‚’å„ªå…ˆã€ãªã‘ã‚Œã° "msg" (å˜ä¸€) ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            messages_list: List[str] = []
            _raw_messages = request.get("messages")
            if isinstance(_raw_messages, list) and _raw_messages:
                messages_list = [str(m) for m in _raw_messages if m]
            if not messages_list:
                _single = str(request.get("msg") or "").strip()
                if _single:
                    messages_list = [_single]
            if not messages_list:
                raise ValueError("msg or messages is required")

            # å¾Œæ–¹äº’æ›: å…ˆé ­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ "msg" ã¨ã—ã¦æ‰±ã†
            msg = messages_list[0]

            attrs = request.get("attrs") or {}
            if not isinstance(attrs, dict):
                attrs = {"raw_attrs": str(attrs)}

            # â˜… å…¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ attrs çµŒç”±ã§ predict() ã«ä¼æ¬ï¼ˆã‚·ã‚°ãƒŠãƒ«ä»¶æ•°é›†è¨ˆç”¨ï¼‰
            attrs = dict(attrs)
            attrs["all_messages"] = messages_list

            req   = PredictRequest(tenant_id=tenant_id, device_id=device_id,
                                   msg=msg, timestamp=ts, attrs=attrs)
            _level  = int((attrs or {}).get("degradation_level", 1))
            _source = str((attrs or {}).get("source", "real"))
            preds = self.predict(device_id=device_id, msg=msg, timestamp=ts,
                                 attrs=attrs, degradation_level=_level, source=_source)

            # â˜… forecast_ledger ã¸ã®ç™»éŒ²ã¯ãƒ‡ãƒã‚¤ã‚¹ã”ã¨ã«1å›ã ã‘è¡Œã†
            # (è¤‡æ•°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã‚‚é‡è¤‡ç™»éŒ²ã—ãªã„)
            record_forecast = bool(request.get("record_forecast", True))
            forecast_ids: List[str] = []
            if record_forecast and preds:
                fid = self._forecast_record(req=req.to_dict(), top_prediction=preds[0])
                if fid:
                    forecast_ids.append(fid)

            return {"ok": True, "input": req.to_dict(),
                    "predictions": preds, "forecast_ids": forecast_ids}
        except Exception as e:
            return {"ok": False, "error": f"{type(e).__name__}: {e}",
                    "trace": traceback.format_exc()}

    # ==============================================================
    # Phase1: Forecast Ledger DDLï¼ˆ_init_sqlite ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ï¼‰
    # ==============================================================

    def _init_forecast_ledger(self):
        """forecast_ledger ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ migration ã‚’å®Ÿæ–½"""
        if not self.storage._conn:
            return
        try:
            with self.storage._db_lock:
                self.storage._conn.execute("""
                    CREATE TABLE IF NOT EXISTS forecast_ledger (
                        forecast_id      TEXT PRIMARY KEY,
                        created_at       REAL,
                        tenant_id        TEXT,
                        device_id        TEXT,
                        rule_pattern     TEXT,
                        predicted_state  TEXT,
                        confidence       REAL,
                        horizon_sec      INTEGER,
                        eval_deadline_ts REAL,
                        source           TEXT,
                        status           TEXT,
                        outcome_type     TEXT,
                        outcome_ts       REAL,
                        outcome_note     TEXT,
                        input_json       TEXT,
                        prediction_json  TEXT
                    )
                """)
                self.storage._conn.execute(
                    "CREATE INDEX IF NOT EXISTS idx_fl_open "
                    "ON forecast_ledger (status, eval_deadline_ts)")
                self.storage._conn.execute(
                    "CREATE INDEX IF NOT EXISTS idx_fl_device "
                    "ON forecast_ledger (device_id, created_at)")
                # migration: add source column if missing
                cur = self.storage._conn.cursor()
                cur.execute("PRAGMA table_info(forecast_ledger)")
                cols = [r[1] for r in cur.fetchall()]
                if "source" not in cols:
                    self.storage._conn.execute(
                        "ALTER TABLE forecast_ledger ADD COLUMN source TEXT")
                self.storage._conn.commit()
        except Exception as e:
            logger.warning(f"_init_forecast_ledger: {e}")

    def _forecast_horizon_sec(self, rule_pattern: str) -> int:
        for r in (self.rules or []):
            if (getattr(r, "pattern", "") or "").lower() == (rule_pattern or "").lower():
                ttc = getattr(r, "time_to_critical_min", None)
                if isinstance(ttc, int) and ttc > 0:
                    return max(1800, ttc * 60)
        return 3600

    def _forecast_record(self, req: Dict[str, Any], top_prediction: Dict[str, Any],
                         source: str = "real") -> Optional[str]:
        """
        forecast_ledger ã« UPSERTï¼ˆåŒä¸€ device_id + rule_pattern ã® open è¡Œã‚’æ›´æ–°ï¼‰ã€‚
        æ–°è¦ã®å ´åˆã¯ INSERTã€æ—¢å­˜ open ã®å ´åˆã¯ prediction_json / confidence ã®ã¿æ›´æ–°ã€‚
        forecast_id ã‚’è¿”ã™ã€‚
        """
        if not self.storage._conn:
            return None
        try:
            tenant_id       = str(req.get("tenant_id") or self.tenant_id)
            device_id       = str(req.get("device_id") or "")
            rule_pattern    = str(top_prediction.get("rule_pattern") or "unknown")
            predicted_state = str(top_prediction.get("predicted_state") or "unknown")
            confidence      = float(top_prediction.get("confidence") or 0.0)
            horizon_sec     = self._forecast_horizon_sec(rule_pattern)
            event_ts        = float(req.get("timestamp") or time.time())
            eval_deadline_ts = event_ts + horizon_sec
            input_json      = json.dumps(req, ensure_ascii=False)
            prediction_json = json.dumps(top_prediction, ensure_ascii=False)

            with self.storage._db_lock:
                cur = self.storage._conn.cursor()

                # â˜… åŒä¸€ device_id + rule_pattern ã® open ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ¤œç´¢
                cur.execute("""
                    SELECT forecast_id FROM forecast_ledger
                    WHERE device_id=? AND rule_pattern=? AND status='open'
                    ORDER BY created_at DESC LIMIT 1
                """, (device_id, rule_pattern))
                existing = cur.fetchone()

                if existing:
                    # â˜… æ—¢å­˜ open ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ›´æ–°ï¼ˆæ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ»ä¿¡é ¼åº¦ã‚’æœ€æ–°ã«ï¼‰
                    fid = existing[0]
                    self.storage._conn.execute("""
                        UPDATE forecast_ledger
                        SET confidence=?, prediction_json=?, input_json=?,
                            eval_deadline_ts=?, predicted_state=?
                        WHERE forecast_id=?
                    """, (confidence, prediction_json, input_json,
                          eval_deadline_ts, predicted_state, fid))
                else:
                    # â˜… æ–°è¦ INSERT
                    fid = "f_" + uuid.uuid4().hex[:12]
                    created_at = time.time()
                    self.storage._conn.execute("""
                        INSERT INTO forecast_ledger
                        (forecast_id, created_at, tenant_id, device_id, rule_pattern, predicted_state,
                         confidence, horizon_sec, eval_deadline_ts, source, status,
                         outcome_type, outcome_ts, outcome_note, input_json, prediction_json)
                        VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
                    """, (fid, created_at, tenant_id, device_id, rule_pattern, predicted_state,
                          confidence, horizon_sec, eval_deadline_ts, source, "open",
                          None, None, None, input_json, prediction_json))

                self.storage._conn.commit()
            return fid
        except Exception as e:
            logger.warning(f"_forecast_record: {e}")
            return None

    def forecast_get(self, forecast_id: str) -> Optional[Dict[str, Any]]:
        if not self.storage._conn:
            return None
        try:
            with self.storage._db_lock:
                cur = self.storage._conn.cursor()
                cur.execute("""
                    SELECT forecast_id, created_at, tenant_id, device_id, rule_pattern,
                           predicted_state, confidence, horizon_sec, eval_deadline_ts,
                           source, status, outcome_type, outcome_ts, outcome_note
                    FROM forecast_ledger WHERE forecast_id=?""", (forecast_id,))
                row = cur.fetchone()
            if not row:
                return None
            keys = ["forecast_id","created_at","tenant_id","device_id","rule_pattern",
                    "predicted_state","confidence","horizon_sec","eval_deadline_ts",
                    "source","status","outcome_type","outcome_ts","outcome_note"]
            return dict(zip(keys, row))
        except Exception:
            return None

    def forecast_register_outcome(self, forecast_id: str, outcome_type: str,
                                  outcome_ts=None, note: str = "",
                                  auto: bool = False) -> Dict[str, Any]:
        """
        äºˆè¦‹æˆåŠŸåˆ¤å®š:
          deadline ä»¥å†…ã« OUTCOME_CONFIRMED â†’ status=confirmed, success=True
          deadline è¶…éå¾Œ   â†’ status=confirmed_late, success=False
          è‡ªå‹•ç™»éŒ² (auto=True) ã¯ audit_log ã« actor="auto" ã§è¨˜éŒ²
        """
        if not self.storage._conn:
            return {"ok": False, "reason": "sqlite_disabled"}
        fid = str(forecast_id or "").strip()
        if not fid:
            return {"ok": False, "reason": "missing_forecast_id"}

        ts  = time.time() if outcome_ts is None else self._parse_timestamp(outcome_ts)
        rec = self.forecast_get(fid)
        if not rec:
            return {"ok": False, "reason": "not_found"}
        if rec.get("status") not in ["open"]:
            return {"ok": False, "reason": "not_open", "status": rec.get("status")}

        deadline = float(rec.get("eval_deadline_ts") or 0.0)
        success  = bool(ts <= deadline) if deadline > 0 else False

        if outcome_type == "confirmed_incident":
            new_status = "confirmed" if success else "confirmed_late"
        elif outcome_type == "mitigated":
            new_status = "mitigated"
            success = True
        elif outcome_type == "false_alarm":
            new_status = "false_alarm"
            success = False
        else:
            new_status = "closed"
            success = False

        actor     = "auto" if auto else "operator"
        note_s    = (note or "")[:512]
        rule_pat  = str(rec.get("rule_pattern") or "")

        try:
            with self.storage._db_lock:
                self.storage._conn.execute("""
                    UPDATE forecast_ledger
                    SET status=?, outcome_type=?, outcome_ts=?, outcome_note=?
                    WHERE forecast_id=?""",
                    (new_status, outcome_type, ts, note_s, fid))
                # audit_log ã«è¨˜éŒ²
                self.storage.audit_log_generic({
                    "event_id":    str(uuid.uuid4()),
                    "timestamp":   ts,
                    "event_type":  "forecast_outcome",
                    "actor":       actor,
                    "rule_pattern": rule_pat,
                    "details": {"forecast_id": fid, "outcome_type": outcome_type,
                                "success": success, "status": new_status, "auto": auto}
                })
                self.storage._conn.commit()
        except Exception as e:
            return {"ok": False, "reason": str(e)}

        return {"ok": True, "forecast_id": fid, "success": success, "status": new_status}

    def forecast_expire_open(self, now_ts: Optional[float] = None,
                             limit: int = 200) -> Dict[str, Any]:
        """æœŸé™åˆ‡ã‚Œã® open äºˆå…†ã‚’ expired ã«æ›´æ–°"""
        if not self.storage._conn:
            return {"ok": False}
        now = float(now_ts or time.time())
        expired = 0
        try:
            with self.storage._db_lock:
                cur = self.storage._conn.cursor()
                cur.execute("""
                    SELECT forecast_id, rule_pattern FROM forecast_ledger
                    WHERE status='open' AND eval_deadline_ts < ?
                    ORDER BY eval_deadline_ts ASC LIMIT ?""", (now, limit))
                rows = cur.fetchall() or []
                for fid, rp in rows:
                    self.storage._conn.execute(
                        "UPDATE forecast_ledger SET status='expired', outcome_type='false_alarm', outcome_ts=? "
                        "WHERE forecast_id=?", (now, fid))
                    expired += 1
                if expired:
                    self.storage._conn.commit()
        except Exception as e:
            logger.warning(f"forecast_expire_open: {e}")
        return {"ok": True, "expired": expired}

    def forecast_auto_resolve(self, device_id: str, outcome_type: str,
                              note: str = "") -> int:
        """
        device_id ã® open äºˆå…†ã‚’è‡ªå‹• outcome ç™»éŒ²ã€‚
        cockpit ã® Execute æˆåŠŸæ™‚ãƒ»ã‚¢ãƒ©ãƒ¼ãƒ ç¢ºå®šæ™‚ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ã€‚
        è§£æ±ºã—ãŸä»¶æ•°ã‚’è¿”ã™ã€‚
        """
        if not self.storage._conn:
            return 0
        resolved = 0
        try:
            with self.storage._db_lock:
                cur = self.storage._conn.cursor()
                cur.execute("""
                    SELECT forecast_id FROM forecast_ledger
                    WHERE device_id=? AND status='open'
                    ORDER BY created_at DESC""", (device_id,))
                rows = cur.fetchall() or []
            for (fid,) in rows:
                r = self.forecast_register_outcome(
                    fid, outcome_type, note=note, auto=True)
                if r.get("ok"):
                    resolved += 1
        except Exception as e:
            logger.warning(f"forecast_auto_resolve: {e}")
        return resolved

    def forecast_auto_confirm_on_incident(self, device_id: str, scenario: str = "",
                                          note: str = "") -> int:
        """
        éšœå®³ç™ºç”Ÿæ™‚ã«è©²å½“ãƒ‡ãƒã‚¤ã‚¹ã® open äºˆå…†ã‚’è‡ªå‹•çš„ã« confirmed_incident ã«æ›´æ–°
        
        é‹ç”¨å®Ÿæ…‹ã«å³ã—ãŸè¨­è¨ˆ:
        - é‹ç”¨è€…ãŒã€Œéšœå®³ç¢ºèªæ¸ˆã¿ã€ã‚’æ‰‹å‹•ç™»éŒ²ã™ã‚‹ã®ã¯éç¾å®Ÿçš„
        - éšœå®³ã‚·ãƒŠãƒªã‚ªç™ºç”Ÿæ™‚ã«è‡ªå‹•åˆ¤å®šã™ã‚‹æ–¹ãŒæ­£ç¢º
        
        Args:
            device_id: éšœå®³ãŒç™ºç”Ÿã—ãŸãƒ‡ãƒã‚¤ã‚¹ID
            scenario: ç™ºç”Ÿã—ãŸéšœå®³ã‚·ãƒŠãƒªã‚ªåï¼ˆãƒ­ã‚°ç”¨ï¼‰
            note: è¿½åŠ ãƒ¡ãƒ¢
        
        Returns:
            confirmed ã«æ›´æ–°ã—ãŸäºˆå…†ã®ä»¶æ•°
        """
        if not self.storage._conn:
            return 0
        confirmed = 0
        auto_note = f"Auto-confirmed on incident: {scenario}" if scenario else "Auto-confirmed on incident"
        if note:
            auto_note += f" | {note}"
        
        try:
            with self.storage._db_lock:
                cur = self.storage._conn.cursor()
                cur.execute("""
                    SELECT forecast_id FROM forecast_ledger
                    WHERE device_id=? AND status='open'
                    ORDER BY created_at DESC""", (device_id,))
                rows = cur.fetchall() or []
            
            for (fid,) in rows:
                r = self.forecast_register_outcome(
                    fid, "confirmed_incident", note=auto_note, auto=True)
                if r.get("ok"):
                    confirmed += 1
                    logger.info(f"Auto-confirmed forecast {fid[:12]} on incident: {scenario}")
        except Exception as e:
            logger.warning(f"forecast_auto_confirm_on_incident: {e}")
        
        return confirmed

    def forecast_list_open(self, device_id: Optional[str] = None,
                           limit: int = 50) -> List[Dict[str, Any]]:
        """open ä¸­ã®äºˆå…†ãƒªã‚¹ãƒˆã‚’è¿”ã™ï¼ˆUIè¡¨ç¤ºç”¨ï¼‰
        
        prediction_json ã‹ã‚‰æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–å¾—ã—ã¦è¿”ã™ï¼ˆæœ€æ–°ã®LLMå¼·åŒ–æ¸ˆã¿ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å«ã‚€ï¼‰ã€‚
        """
        if not self.storage._conn:
            return []
        try:
            with self.storage._db_lock:
                cur = self.storage._conn.cursor()
                if device_id:
                    cur.execute("""
                        SELECT forecast_id, created_at, device_id, rule_pattern,
                               predicted_state, confidence, eval_deadline_ts, source,
                               input_json, prediction_json
                        FROM forecast_ledger
                        WHERE status='open' AND device_id=?
                        ORDER BY created_at DESC LIMIT ?""", (device_id, limit))
                else:
                    cur.execute("""
                        SELECT forecast_id, created_at, device_id, rule_pattern,
                               predicted_state, confidence, eval_deadline_ts, source,
                               input_json, prediction_json
                        FROM forecast_ledger
                        WHERE status='open'
                        ORDER BY confidence DESC, created_at DESC LIMIT ?""", (limit,))
                rows = cur.fetchall() or []
            keys = ["forecast_id","created_at","device_id","rule_pattern",
                    "predicted_state","confidence","eval_deadline_ts","source",
                    "input_json","prediction_json"]
            result = []
            for r in rows:
                d = dict(zip(keys, r))
                # input_json ã‹ã‚‰ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ½å‡º
                try:
                    if d.get("input_json"):
                        input_data = json.loads(d["input_json"])
                        d["message"] = input_data.get("msg", "")
                except Exception:
                    d["message"] = ""
                # â˜… prediction_json ã‹ã‚‰æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ»æ ¹æ‹ ã‚’æŠ½å‡ºï¼ˆæœ€æ–°LLMå¼·åŒ–æ¸ˆã¿ï¼‰
                try:
                    if d.get("prediction_json"):
                        pred_data = json.loads(d["prediction_json"])
                        d["recommended_actions"] = pred_data.get("recommended_actions", [])
                        d["reasons"] = pred_data.get("reasons", [])
                        d["criticality"] = pred_data.get("criticality", "standard")
                        d["time_to_critical_min"] = pred_data.get(
                            "time_to_critical_min",
                            pred_data.get("prediction_time_to_critical_min", 0))
                        d["time_to_failure_hours"] = pred_data.get(
                            "time_to_failure_hours",
                            pred_data.get("prediction_time_to_failure_hours", 0))
                        d["predicted_failure_datetime"] = pred_data.get(
                            "predicted_failure_datetime",
                            pred_data.get("prediction_failure_datetime", ""))
                except Exception:
                    d["recommended_actions"] = []
                    d["reasons"] = []
                # prediction_json ã¯è¿”å´ä¸è¦ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰
                d.pop("prediction_json", None)
                result.append(d)
            return result
        except Exception:
            return []
